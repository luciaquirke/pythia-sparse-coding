{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mchorse/miniconda3/envs/logan/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "import numpy as np \n",
    "from torch import nn\n",
    "import pickle\n",
    "\n",
    "# Define the autoencoder so pickle knows how to serialize it. \n",
    "# Later, we should actually save as a state_dict instead of a dumb pickle\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, activation_size, n_dict_components, t_type=torch.float32, l1_coef=0.0):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        # Only defining the decoder layer, encoder will share its weights\n",
    "        self.decoder = nn.Linear(n_dict_components, activation_size, bias=True)\n",
    "        # Create a bias layer\n",
    "        self.encoder_bias= nn.Parameter(torch.zeros(n_dict_components))\n",
    "\n",
    "        \n",
    "        # Initialize the decoder weights orthogonally\n",
    "        nn.init.orthogonal_(self.decoder.weight)\n",
    "        self.decoder = self.decoder.to(t_type)\n",
    "\n",
    "        # Encoder is a Sequential with the ReLU activation\n",
    "        # No need to define a Linear layer for the encoder as its weights are tied with the decoder\n",
    "        self.encoder = nn.Sequential(nn.ReLU()).to(t_type)\n",
    "\n",
    "        self.l1_coef = l1_coef\n",
    "        self.activation_size = activation_size\n",
    "        self.n_dict_components = n_dict_components\n",
    "\n",
    "    def forward(self, x):\n",
    "        c = self.encoder(x @ self.decoder.weight + self.encoder_bias)\n",
    "        # Apply unit norm constraint to the decoder weights\n",
    "        self.decoder.weight.data = nn.functional.normalize(self.decoder.weight.data, dim=0)\n",
    "\n",
    "        # Decoding step as before\n",
    "        x_hat = self.decoder(c)\n",
    "        return x_hat, c\n",
    "\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "torch.Size([6144, 768])\n",
      "torch.Size([12288, 768])\n",
      "len of autoencoders:  6\n"
     ]
    }
   ],
   "source": [
    "#Change these settings to load the correct autoencoder\n",
    "# filename = \"/home/mchorse/logan_sparse_coding/sparse_coding/layer-2-autoencoder.pkl\"\n",
    "# filename = \"outputs/20230720-192301-EleutherAI/pythia-70m-deduped-2/minirun9/autoencoders.pkl\"\n",
    "# filename = \"outputs/20230720-192301-EleutherAI/pythia-70m-deduped-2/minirun5/autoencoders.pkl\"\n",
    "# filename = \"outputs/20230721-161919-EleutherAI/pythia-70m-deduped-2/minirun9/autoencoders.pkl\"\n",
    "# filename = \"outputs/20230721-161919-EleutherAI/pythia-70m-deduped-2/minirun3/autoencoders.pkl\"\n",
    "# filename = \"outputs/20230804-205842-EleutherAI/pythia-70m-deduped-2/minirun4/autoencoders.pkl\"\n",
    "\n",
    "# filename = \"outputs/20230805-205314-EleutherAI/pythia-70m-deduped-2/minirun14/autoencoders.pkl\"\n",
    "filename = \"outputs/20230806-181211-gpt2-8/minirun9/autoencoders.pkl\"\n",
    "layer = 8\n",
    "setting = \"residual\"\n",
    "# model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "model_name = \"gpt2\"\n",
    "\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HookedTransformer.from_pretrained(model_name, device=device)\n",
    "\n",
    "if setting == \"residual\":\n",
    "    cache_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "    neurons = model.cfg.d_model\n",
    "elif setting == \"mlp\":\n",
    "    cache_name = f\"blocks.{layer}.mlp.hook_post\"\n",
    "    neurons = model.cfg.d_mlp\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "# Load the pickle file\n",
    "with open(filename, 'rb') as file:\n",
    "    autoencoders = pickle.load(file)\n",
    "\n",
    "# Index for l1 value, usually only 1 value is available\n",
    "l1_index = 3\n",
    "dictionaries = [autoencoder.decoder.weight.data.T for autoencoder in autoencoders[l1_index]]\n",
    "for d in dictionaries:\n",
    "    print(d.shape)\n",
    "print(\"len of autoencoders: \", len(autoencoders))\n",
    "dict_index = 0\n",
    "smaller_dict, larger_dict = dictionaries[dict_index], dictionaries[dict_index+1]\n",
    "smaller_auto_encoder, larger_auto_encoder = autoencoders[l1_index][dict_index], autoencoders[l1_index][dict_index+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m-deduped into HookedTransformer\n",
      "torch.Size([2048, 512])\n",
      "torch.Size([4096, 512])\n",
      "torch.Size([8192, 512])\n",
      "len of autoencoders:  3\n"
     ]
    }
   ],
   "source": [
    "#Change these settings to load the correct autoencoder\n",
    "# filename = \"/home/mchorse/logan_sparse_coding/sparse_coding/layer-2-autoencoder.pkl\"\n",
    "filename = \"outputs/20230720-192301-EleutherAI/pythia-70m-deduped-2/minirun9/autoencoders.pkl\"\n",
    "# filename = \"outputs/20230720-192301-EleutherAI/pythia-70m-deduped-2/minirun5/autoencoders.pkl\"\n",
    "filename2 = \"outputs/20230721-161919-EleutherAI/pythia-70m-deduped-2/minirun9/autoencoders.pkl\"\n",
    "# filename = \"outputs/20230721-161919-EleutherAI/pythia-70m-deduped-2/minirun3/autoencoders.pkl\"\n",
    "layer = 2\n",
    "setting = \"residual\"\n",
    "model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HookedTransformer.from_pretrained(model_name, device=device)\n",
    "\n",
    "if setting == \"residual\":\n",
    "    cache_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "    neurons = model.cfg.d_model\n",
    "elif setting == \"mlp\":\n",
    "    cache_name = f\"blocks.{layer}.mlp.hook_post\"\n",
    "    neurons = model.cfg.d_mlp\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "# Load the pickle file\n",
    "with open(filename, 'rb') as file:\n",
    "    autoencoders = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open(filename2, 'rb') as file:\n",
    "    autoencoders2 = pickle.load(file)\n",
    "\n",
    "# Index for l1 value, usually only 1 value is available\n",
    "l1_index = 1\n",
    "dictionaries = [autoencoder.decoder.weight.data.T for autoencoder in autoencoders[l1_index]]\n",
    "dictionaries2 = [autoencoder.decoder.weight.data.T for autoencoder in autoencoders2[l1_index]]\n",
    "for d in dictionaries:\n",
    "    print(d.shape)\n",
    "print(\"len of autoencoders: \", len(autoencoders))\n",
    "dict_index = 1\n",
    "smaller_dict, larger_dict = dictionaries[dict_index], dictionaries2[dict_index]\n",
    "smaller_auto_encoder, larger_auto_encoder = autoencoders[l1_index][dict_index], autoencoders2[l1_index][dict_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:49<00:49, 16.62s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m j \u001b[39m>\u001b[39m i:\n\u001b[1;32m     33\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m max_cosine_similarities, max_indices \u001b[39m=\u001b[39m mcs(combined_dicts[i], combined_dicts[j])\n\u001b[1;32m     35\u001b[0m adjancy_matrix[i, j] \u001b[39m=\u001b[39m max_cosine_similarities\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     36\u001b[0m adjancy_matrix[j, i] \u001b[39m=\u001b[39m max_cosine_similarities\u001b[39m.\u001b[39mmean()\n",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m, in \u001b[0;36mmcs\u001b[0;34m(dict1, dict2)\u001b[0m\n\u001b[1;32m     14\u001b[0m cos_sims \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m cos_sims\n\u001b[1;32m     15\u001b[0m \u001b[39m# Use the Hungarian algorithm to solve the assignment problem\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m row_ind, col_ind \u001b[39m=\u001b[39m linear_sum_assignment(cos_sims)\n\u001b[1;32m     17\u001b[0m \u001b[39m# Retrieve the max cosine similarities and corresponding indices\u001b[39;00m\n\u001b[1;32m     18\u001b[0m max_cosine_similarities \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m cos_sims[row_ind, col_ind]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "from tqdm import tqdm\n",
    "# DO THE MCS across all dictionaries\n",
    "def mcs(dict1, dict2):\n",
    "    dict1_features, _ = dict1.shape\n",
    "    dict2_features, _ = dict2.shape\n",
    "    dict2 = dict2.to(device)\n",
    "    # Hungary algorithm\n",
    "    # Calculate all cosine similarities and store in a 2D array\n",
    "    cos_sims = np.zeros((dict1_features, dict2_features))\n",
    "    for idx, vector in enumerate(dict1):\n",
    "        cos_sims[idx] = torch.nn.functional.cosine_similarity(vector.to(device), dict2, dim=1).cpu().numpy()\n",
    "    # Convert to a minimization problem\n",
    "    cos_sims = 1 - cos_sims\n",
    "    # Use the Hungarian algorithm to solve the assignment problem\n",
    "    row_ind, col_ind = linear_sum_assignment(cos_sims)\n",
    "    # Retrieve the max cosine similarities and corresponding indices\n",
    "    max_cosine_similarities = 1 - cos_sims[row_ind, col_ind]\n",
    "    max_indices = np.argsort(max_cosine_similarities)[::-1].copy()\n",
    "    return max_cosine_similarities, max_indices\n",
    "\n",
    "\n",
    "l1_index = 3\n",
    "# dictionaries = [autoencoder.decoder.weight.data.T for autoencoder in autoencoders[l1_index]]\n",
    "# dictionaries2 = [autoencoder.decoder.weight.data.T for autoencoder in autoencoders2[l1_index]]\n",
    "dictionaries = [autoencoder[0].decoder.weight.data.T for autoencoder in autoencoders]\n",
    "# combined_dicts = dictionaries + dictionaries2\n",
    "combined_dicts = dictionaries\n",
    "adjancy_matrix = np.zeros((len(combined_dicts), len(combined_dicts)))\n",
    "for i in tqdm(range(len(combined_dicts))):\n",
    "    for j in range(len(combined_dicts)):\n",
    "        if j > i:\n",
    "            break\n",
    "        max_cosine_similarities, max_indices = mcs(combined_dicts[i], combined_dicts[j])\n",
    "        adjancy_matrix[i, j] = max_cosine_similarities.mean()\n",
    "        adjancy_matrix[j, i] = max_cosine_similarities.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the adjancy matrix\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(adjancy_matrix, cmap='hot', interpolation='nearest')\n",
    "plt.title(\"MCS for dict_size=4k\")\n",
    "# sparsities = [28,69,94,95,113,115,126,205,393]\n",
    "sparsities = [28, 69, 97, 107, 114, 119, 123, 205, 402]\n",
    "# sparsities are x-axis\n",
    "plt.xticks(range(len(sparsities)), sparsities)\n",
    "plt.xlabel(\"Features/Tokens\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAv8AAAMeCAYAAACKlGuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+8UlEQVR4nO3df5hWdZ0//udAMmgyYyY/RFH8URqaoKgs/kjdUFJjtd020wokdcvF/Wp82gxTsWyjz2WxuBv523D96Iq6abtpkNGqlx81FWM/WmmaJlQMSK0zwOagM/P9o5wamCHmZob7Pp7H47rOde19OPc5r7nvxV7z4nnep66jo6MjAADAm96AahcAAABsG5p/AAAoCc0/AACUhOYfAABKQvMPAAAlofkHAICS0PwDAEBJaP4BAKAkNP8AAFASmn8AACgJzT8AAGxjDz74YKZMmZKRI0emrq4ud9999598z/33359DDjkk9fX12XfffbNgwYJeX1fzDwAA29j69eszduzYzJ8/f4uOf/HFF3PyySfnuOOOy7Jly3LBBRfk7LPPzuLFi3t13bqOjo6OSgoGAAC2Xl1dXe66666ceuqpPR5z4YUX5p577snTTz/due/DH/5wXnnllSxatGiLr/WWrSkUAAC2pVdffTUbNmyodhnd6ujoSF1dXZd99fX1qa+v3+pzP/LII5k0aVKXfZMnT84FF1zQq/No/gEAKIRXX301e+21V5qamqpdSrd23HHHrFu3rsu+2bNn57LLLtvqczc1NWX48OFd9g0fPjwtLS357W9/m+23336LzqP5BwCgEDZs2JCmpqasWLEiDQ0N1S6ni5aWlowaNWqT2vpi6t+XNP8AABRKQ0NDzTX/b+iv2kaMGJFVq1Z12bdq1ao0NDRs8dQ/0fwDAFA4r/9+qyX9W8/EiRNz7733dtl33333ZeLEib06j6U+AQBgG1u3bl2WLVuWZcuWJfndUp7Lli3L8uXLkySzZs3K1KlTO4//5Cc/mRdeeCGf+cxn8swzz+TrX/96br/99nzqU5/q1XU1/wAAsI098cQTOfjgg3PwwQcnSWbOnJmDDz44l156aZJk5cqVnb8IJMlee+2Ve+65J/fdd1/Gjh2br371q7n++uszefLkXl3XOv8AABRCS0tLGhsb09y8quYy/7+rbXiam5trrrY/ZvIPAAAlofkHAICSsNoPAAAFU77VfvqKyT8AAJSE5h8AAEpC7AcAgIIR+6mUyT8AAJSE5h8AAEpC7AcAgIJpS+3FbNqqXcAWMfkHAICS0PwDAEBJiP0AAFAwVvuplMk/AACUhOYfAABKQuwHAICCEfuplMk/AACUhOYfAABKQuwHAICCEfuplMk/AACUhOYfAABKQuwHAICCafv9VktqrZ7umfwDAEBJaP4BAKAkxH4AACiYttTe6jpiPwAAQA3R/AMAQEmI/QAAUDAe8lUpk38AACgJzT8AAJSE2A8AAAUj9lMpk38AACgJzT8AAJSE2A8AAAUj9lMpk38AACgJzT8AAJSE2A8AAAXTltqL2bRVu4AtYvIPAAAlofkHAICSEPsBAKBgrPZTKZN/AAAoCc0/AACUhNgPAAAFI/ZTKZN/AAAoCc0/AACUhNgPAAAFI/ZTKZN/AAAoCc0/8KZ3xRVXZO+9987AgQMzbty4fr3WmWeemdGjR9f8OQEoJ80/UJEFCxakrq4udXV1eeihhzb5846OjowaNSp1dXV5//vfv8mfv/rqq/nHf/zHTJgwIY2NjRk8eHDe+c535rzzzstPf/rTLsc+9NBDOfHEE7Pbbrtl8ODB2WOPPTJlypTceuutf7LO7373u/nMZz6TI488Mt/4xjfypS99qfIfmiTJVVddlb/+67/OHnvskbq6upx55pnVLgkonddrdKt9Mv/AVhk8eHBuvfXWHHXUUV32P/DAA/nFL36R+vr6Td6zZs2avO9978vSpUvz/ve/P2eccUZ23HHHPPvss7ntttty7bXXZsOGDUmSO+64I6eddlrGjRuX888/P29729vy4osv5sEHH8x1112XM844Y7P1ff/738+AAQNyww03ZNCgQX33g/fguuuuS3t7e79fp5r+9//+31m7dm0OP/zwrFy5strlANALmn9gq5x00km544478k//9E95y1v+8J+UW2+9NePHj8+aNWs2ec+ZZ56ZH/7wh7nzzjvzV3/1V13+7PLLL8/nPve5zteXXXZZxowZk0cffXST5n316tV/sr7Vq1dn++2377PGv6OjI6+++mq23377bv98u+2265Pr1LIHHnigc+q/4447VrscAHpB7AfYKqeffnp+/etf57777uvct2HDhtx5553dTuV/8IMf5J577slZZ521SeOfJPX19fnKV77S+fpnP/tZDjvssG6b92HDhm22trq6unzjG9/I+vXrOyNKCxYsSJK8/vrrufzyy7PPPvukvr4+o0ePzkUXXZTW1tYu5xg9enTe//73Z/HixTn00EOz/fbb55prrunxmhvn83/+85+nrq4uX/nKV3Lttdd2Xu+www7L448/vsn777777hx44IEZPHhwDjzwwNx1113dXqe9vT3z5s3LAQcckMGDB2f48OH5xCc+kf/+7//uPGb27NkZMGBAlixZ0uW9f/M3f5NBgwblv/7rvzr3LV++PM8880yPP9cf23PPPVNXV7dFxwL0j7ZUP+Kz8dbWrz9xX9H8A1tl9OjRmThxYv71X/+1c993vvOdNDc358Mf/vAmx//7v/97kuRjH/vYFp1/zz33zJIlS/KLX/yi17XdfPPNOfroo1NfX5+bb745N998c97znvckSc4+++xceumlOeSQQ/KP//iPOeaYYzJnzpxua3722Wdz+umn5/jjj8+VV15Z0U3Dt956a6644op84hOfyBe/+MX8/Oc/z1/+5V/mtdde6zzmu9/9bv7qr/4qdXV1mTNnTk499dRMnz49TzzxxCbn+8QnPpG///u/z5FHHpkrr7wy06dPzy233JLJkyd3nvPiiy/OuHHjctZZZ2Xt2rVJksWLF+e6667LpZdemrFjx3aeb+rUqXnXu97V658LgGIR+wG22hlnnJFZs2blt7/9bbbffvvccsstOeaYYzJy5MhNjv3JT36SJHn3u9+9Ree+8MILc9ZZZ2WfffbJkUcemaOOOionnHBCjjjiiAwYsPn5xUc/+tF873vfy5NPPpmPfvSjnfv/67/+KzfddFPOPvvsXHfddUmSv/3bv82wYcPyla98Jf/5n/+Z4447rvP4559/PosWLcrkyZO3qObuLF++PM8991ze9ra3JUn222+/nHLKKVm8eHHnDdEXXnhhhg8fnoceeiiNjY1JkmOOOSYnnHBC9txzz85zPfTQQ7n++utzyy23dPnXleOOOy7ve9/7cscdd+SMM87Idtttl3/5l3/J+PHjM3PmzFxxxRU566yzcuihh+azn/1sxT8LAMVl8g9stQ996EP57W9/m29/+9tZu3Ztvv3tb/d4I25LS0uSZMiQIVt07o9//ONZtGhRjj322Dz00EO5/PLLc/TRR+cd73hHHn744Yrqvffee5MkM2fO7LL/f/2v/5Ukueeee7rs32uvvbaq8U+S0047rbPxT5Kjjz46SfLCCy8kSVauXJlly5Zl2rRpnY1/khx//PEZM2ZMl3PdcccdaWxszPHHH581a9Z0buPHj8+OO+6Y//zP/+w89sADD8znP//5XH/99Zk8eXLWrFmTm266qcv9GUly//33p6OjY6t+RoBtp9oRn+Ku9qP5B7ba0KFDM2nSpNx666355je/mba2tnzwgx/s9tiGhoYk6YyhbInJkydn8eLFeeWVV/Lggw9mxowZeemll/L+979/i2763dhLL72UAQMGZN999+2yf8SIEdlpp53y0ksvddm/11579foaG9tjjz26vH7jF4E3MvpvXPMd73jHJu/db7/9urx+7rnn0tzcnGHDhmXo0KFdtnXr1m3ymfz93/99xo4dm8ceeyyzZ8/e5JcJAMpD7AfoE2eccUbOOeecNDU15cQTT8xOO+3U7XH7779/kuSpp57qnH5vqR122CFHH310jj766Oyyyy75/Oc/n+985zuZNm1aRTVv6U2rPa3s0xsDBw7sdn8l0/b29vYMGzYst9xyS7d/PnTo0C6vX3jhhTz33HNJfve5A1BeJv9An/jABz6QAQMG5NFHH93s2vtTpkxJkvyf//N/tup6hx56aJJUtM78nnvumfb29s6G+A2rVq3KK6+80iVfv628cc2Na0p+d8PxH9tnn33y61//OkceeWQmTZq0yfbHN/K2t7fnzDPPTENDQy666KL867/+a775zW/27w8D0O+qHe8R+wFKbscdd8xVV12Vyy67rLPB787EiRPzvve9L9dff33uvvvuTf58w4YN+fSnP935euNlKt/wRm5/40jMljjppJOSJPPmzeuyf+7cuUmSk08+udfn3Fq77rprxo0bl5tuuinNzc2d+++77778+Mc/7nLshz70obS1teXyyy/f5Dyvv/56Xnnllc7Xc+fOzcMPP5xrr702l19+eY444oice+65mzx/oTdLfQJQXGI/QJ/Z0vjNv/zLv+SEE07IX/7lX2bKlCl573vfm7e+9a157rnnctttt2XlypWda/2fcsop2WuvvTJlypTss88+Wb9+fb73ve/lP/7jP3LYYYdt9heNnowdOzbTpk3Ltddem1deeSXHHHNMHnvssdx000059dRTu6z0sy3NmTMnJ598co466qh8/OMfz29+85v88z//cw444ICsW7eu87hjjjkmn/jEJzJnzpwsW7YsJ5xwQrbbbrs899xzueOOO3LllVfmgx/8YH7yk5/kkksuyZlnntn5OS1YsCDjxo3L3/7t3+b222/vPOfUqVPzwAMPbFEM6T/+4z86nxHw2muv5f/9v/+XL37xi0mSv/iLv8hBBx3Ulx8LAH1I8w9sc0OHDs3DDz+cr3/961m4cGE+97nPZcOGDdlzzz3zF3/xFzn//PM7j73++uvzrW99K7fffnt+9atfpaOjI3vvvXc+97nP5cILL9xk1Zotdf3112fvvffOggULctddd2XEiBGZNWtWZs+e3Vc/Zq+9sUznxRdfnFmzZmWfffbJN77xjXzrW9/K/fff3+XYq6++OuPHj88111yTiy66KG95y1syevTofPSjH82RRx6Ztra2TJs2LbvsskuXf+F4xzvekTlz5uT888/P7bffng996EO9rvPf/u3fctNNN3W+/uEPf5gf/vCHSZLdd99d8w9sA7UYs6m1erpX12FtNwAACqClpSWNjY1pbr4xDQ07VLucLlpa/ieNjR9Pc3Nz58p2tUjmHwAASkLsBwCAghH7qZTJPwAAlITmHwAASkLsBwCAgmlL7cVs2qpdwBYx+QcAgJLY5pP/9vb2/OpXv8qQIUNSV1e3rS8PAMCf0NHRkbVr12bkyJEZMMCs+M1kmzf/v/rVrzJq1KhtfVkAAHppxYoV2X333atdRjfaUnsxm1qrp3vbvPkfMmRIkt/9P1MtPwChtO5srHYFbM7Pq10APRlxebUrYHO+W+0C6NE7ql0A3Vqb3303b/RtvHls8+b/jahPQ0OD5r8W1dbD8tjY4GoXQE+EGGvbjtUugB7pBGqbiPabj9V+AAAoGA/5qpQ7OAAAoCQ0/wAAUBJiPwAAFIzYT6VM/gEAoCQ0/wAAUBJiPwAAFExbai9mU4yHfJn8AwBASWj+AQCgJMR+AAAoGKv9VMrkHwAASkLzDwAAJSH2AwBAwYj9VMrkHwAASkLzDwAAJSH2AwBAwYj9VMrkHwAASkLzDwAAJSH2AwBAwYj9VMrkHwAASkLzDwAAJSH2AwBAwbSl9mI2bdUuYIuY/AMAQElo/gEAoCTEfgAAKJjXkwysdhEbqbUYUvdM/gEAoCQ0/wAAUBJiPwAAFIzYT6VM/gEAoCQ0/wAAUBJiPwAAFIzYT6VM/gEAoCQ0/wAAUBJiPwAAFExbai9m01btAraIyT8AAJSE5h8AAEpC7AcAgIJ5PbU3w661GFL3au1TAwAA+onmHwAASkLsBwCAghH7qVStfWoAAEA/0fwDAEBJiP0AAFAwYj+VqrVPDQAA6CeafwAAKImKmv/58+dn9OjRGTx4cCZMmJDHHnusr+sCAIAetNXoVvt63fwvXLgwM2fOzOzZs/Pkk09m7NixmTx5clavXt0f9QEAAH2k183/3Llzc84552T69OkZM2ZMrr766uywww658cYb+6M+AACgj/RqtZ8NGzZk6dKlmTVrVue+AQMGZNKkSXnkkUe6fU9ra2taW1s7X7e0tFRYKgAAJL+L2NTa6jpvwtjPmjVr0tbWluHDh3fZP3z48DQ1NXX7njlz5qSxsbFzGzVqVOXVAgAAFev31X5mzZqV5ubmzm3FihX9fUkAAKAbvYr97LLLLhk4cGBWrVrVZf+qVasyYsSIbt9TX1+f+vr6yisEAIAuXk9SV+0iNlJrMaTu9WryP2jQoIwfPz5Llizp3Nfe3p4lS5Zk4sSJfV4cAADQd3o1+U+SmTNnZtq0aTn00ENz+OGHZ968eVm/fn2mT5/eH/UBAAB9pNfN/2mnnZaXX345l156aZqamjJu3LgsWrRok5uAAQCgf4j9VKrXzX+SnHfeeTnvvPP6uhYAAKAf9ftqPwAAQG2oaPIPAADVI/ZTKZN/AAAoCc0/AACUhNgPAAAFI/ZTKZN/AAAoCc0/AACUhNgPAAAF05bai/20VbuALWLyDwAAJaH5BwCAkhD7AQCgYGpxZZ1arGlTJv8AAFASmn8AACgJsR8AAAqmFiM2tVjTpkz+AQCgJDT/AABQBfPnz8/o0aMzePDgTJgwIY899liPx7722mv5whe+kH322SeDBw/O2LFjs2jRol5fU/MPAEDBvF6j25ZbuHBhZs6cmdmzZ+fJJ5/M2LFjM3ny5Kxevbrb4y+++OJcc801+ed//uf8+Mc/zic/+cl84AMfyA9/+MNeXVfzDwAA29jcuXNzzjnnZPr06RkzZkyuvvrq7LDDDrnxxhu7Pf7mm2/ORRddlJNOOil77713zj333Jx00kn56le/2qvrav4BAKCPtLS0dNlaW1s3OWbDhg1ZunRpJk2a1LlvwIABmTRpUh555JFuz9va2prBgwd32bf99tvnoYce6lV9mn8AAAqmLdWP+Gy8tSVJRo0alcbGxs5tzpw5m1S/Zs2atLW1Zfjw4V32Dx8+PE1NTd3+xJMnT87cuXPz3HPPpb29Pffdd1+++c1vZuXKlb365Cz1CQAAfWTFihVpaGjofF1fX98n573yyitzzjnnZP/9909dXV322WefTJ8+vceYUE9M/gEAoI80NDR02bpr/nfZZZcMHDgwq1at6rJ/1apVGTFiRLfnHTp0aO6+++6sX78+L730Up555pnsuOOO2XvvvXtVn+YfAICCqXbEZ+tW+xk0aFDGjx+fJUuWdO5rb2/PkiVLMnHixM2+d/Dgwdltt93y+uuv59/+7d9yyimnbPF1E7EfAADY5mbOnJlp06bl0EMPzeGHH5558+Zl/fr1mT59epJk6tSp2W233TrvGfjBD36QX/7ylxk3blx++ctf5rLLLkt7e3s+85nP9Oq6mn8AANjGTjvttLz88su59NJL09TUlHHjxmXRokWdNwEvX748Awb8IaTz6quv5uKLL84LL7yQHXfcMSeddFJuvvnm7LTTTr26bl1HR0dHX/4gf0pLS0saGxvT3Nzc5WYIasRtddWugM15odoF0JO3fq7aFbA5/7faBdCj/apdAN1qSTIiqbl+7Q995AFpaBhY7XK6aGlpS2Pjj2ruM9uYzD8AAJSE5h8AAEpC5h8AgIJ5Pck2Ta5vgbZqF7BFTP4BAKAkNP8AAFASYj8AABSM2E+lTP4BAKAkNP8AAFASYj8AABRMW2ov9tNe7QK2iMk/AACUhOYfAABKQuwHAICCEfuplMk/AACUhOYfAABKQuwHAICCeT21N8MW+wEAAGqI5h8AAEpC7AcAgIIR+6lU9Zr/OxuTHap2dXry4VpbNosuFtRVuwJ6MLLaBbBZH6t2AfRoVrULoFv/U+0C6De19isTAADQT8R+AAAoGLGfStXapwYAAPQTzT8AAJSE2A8AAAXTltqL2RRj0RSTfwAAKAnNPwAAlITYDwAABfN6klp79o3YDwAAUEM0/wAAUBJiPwAAFIzYT6VM/gEAoCQ0/wAAUBJiPwAAFIzYT6VM/gEAoCQ0/wAAUBJiPwAAFEtHe+2lbGqtnh6Y/AMAQElo/gEAoCTEfgAAKJb232+1pNbq6YHJPwAAlITmHwAASkLsBwCAYmn7/VZLaq2eHpj8AwBASWj+AQCgJMR+AAAoFrGfipn8AwBASWj+AQCgJMR+AAAoFg/5qpjJPwAAlITmHwAASkLsBwCAYrHaT8VM/gEAoCQ0/wAAUBKafwAAKAmZfwAAisVSnxUz+QcAgJLQ/AMAQEmI/QAAUCztqb2lNcV+AACAWqL5BwCAkhD7AQCgWDzht2Im/wAAUBKafwAAKAmxHwAAisVDvipm8g8AACWh+QcAgJLodfP/4IMPZsqUKRk5cmTq6upy991390NZAADQg7Ya3Qqg183/+vXrM3bs2MyfP78/6gEAAPpJr2/4PfHEE3PiiSf2Ry0AAEA/6vfVflpbW9Pa2tr5uqWlpb8vCQDAm1ktxmxqrZ4e9PsNv3PmzEljY2PnNmrUqP6+JAAA0I1+b/5nzZqV5ubmzm3FihX9fUkAAKAb/R77qa+vT319fX9fBgCAsvCQr4pZ5x8AAEqi15P/devW5fnnn+98/eKLL2bZsmXZeeeds8cee/RpcQAAQN/pdfP/xBNP5Ljjjut8PXPmzCTJtGnTsmDBgj4rDAAAumW1n4r1uvk/9thj09HR0R+1AAAA/UjmHwAASqLfV/sBAIA+1ZHaW12nIMEYk38AACgJzT8AAJSE2A8AAMVitZ+KmfwDAEBJaP4BAKAkxH4AACgWsZ+KmfwDAEBJaP4BAKAkxH4AACiW9tTeQ75qrZ4emPwDAEBJaP4BAKAkxH4AACgWq/1UzOQfAABKQvMPAAAlIfYDAECxiP1UzOQfAABKQvMPAAAlIfYDAECxeMhXxUz+AQCgJDT/AABQEmI/AAAUS3tqb3UdsR8AAKCWaP4BAKAkxH4AACgWq/1UzOQfAABKQvMPAAAlIfYDAECxtKX2VvuptXp6YPIPAAAlofkHAICSEPsBAKBYxH4qZvIPAAAlofkHAICSEPsBAKBYPOSrYib/AABQEpp/AAAoCbEfAACKxWo/FTP5BwCAktD8AwBASYj9AABQLGI/FTP5BwCAktD8AwBASYj9AABQLB2pvYdqdVS7gC1Tveb/50kGV+3q9GRBXbUrYHPOLMh/WUroten+7tSyydUugB7dVO0C6Nbr1S6AfiP2AwAAJSH2AwBAsVjtp2Im/wAAUBKafwAAKAmxHwAAiqU9tbfaT63V0wOTfwAAKAnNPwAAlITYDwAAxWK1n4qZ/AMAQElo/gEAoCTEfgAAKBaxn4qZ/AMAQElo/gEAoCTEfgAAKBYP+aqYyT8AAJSE5h8AAEpC7AcAgGKx2k/FTP4BAKAkNP8AAFASYj8AABRLe2ovZmO1HwAAoCfz58/P6NGjM3jw4EyYMCGPPfbYZo+fN29e9ttvv2y//fYZNWpUPvWpT+XVV1/t1TU1/wAAsI0tXLgwM2fOzOzZs/Pkk09m7NixmTx5clavXt3t8bfeems++9nPZvbs2fnJT36SG264IQsXLsxFF13Uq+tq/gEAKJb2Gt16Ye7cuTnnnHMyffr0jBkzJldffXV22GGH3Hjjjd0e//DDD+fII4/MGWeckdGjR+eEE07I6aef/if/tWBjmn8AAOgjLS0tXbbW1tZNjtmwYUOWLl2aSZMmde4bMGBAJk2alEceeaTb8x5xxBFZunRpZ7P/wgsv5N57781JJ53Uq/o0/wAA0EdGjRqVxsbGzm3OnDmbHLNmzZq0tbVl+PDhXfYPHz48TU1N3Z73jDPOyBe+8IUcddRR2W677bLPPvvk2GOP7XXsx2o/AAAUSw0/5GvFihVpaGjo3F1fX98np7///vvzpS99KV//+tczYcKEPP/88zn//PNz+eWX55JLLtni82j+AQCgjzQ0NHRp/ruzyy67ZODAgVm1alWX/atWrcqIESO6fc8ll1ySj33sYzn77LOTJO9+97uzfv36/M3f/E0+97nPZcCALQv0iP0AAMA2NGjQoIwfPz5Llizp3Nfe3p4lS5Zk4sSJ3b7nf/7nfzZp8AcOHJgk6ejo2OJrm/wDAFAsFayu0+96Wc/MmTMzbdq0HHrooTn88MMzb968rF+/PtOnT0+STJ06NbvttlvnPQNTpkzJ3Llzc/DBB3fGfi655JJMmTKl85eALaH5BwCAbey0007Lyy+/nEsvvTRNTU0ZN25cFi1a1HkT8PLly7tM+i+++OLU1dXl4osvzi9/+csMHTo0U6ZMyT/8wz/06rp1Hb35d4I+0NLSksbGxjRfkjQM3pZXZouMrHYBbNaZ2/SvK70wuq6u2iWwGe+vdgH06LlqF0C3Xk/y/STNzc1/Mr++LXX2kf+UNGxf7Wq6avlt0vj/1d5ntjGTfwAAiqWGV/updW74BQCAktD8AwBASYj9AABQLGI/FTP5BwCAktD8AwBASYj9AABQLG+Ch3xVi8k/AACUhOYfAABKQuwHAIBiaU/tra4j9gMAANQSzT8AAJSE2A8AAMVitZ+KmfwDAEBJaP4BAKAkxH4AACiWttTeaj+1Vk8PejX5nzNnTg477LAMGTIkw4YNy6mnnppnn322v2oDAAD6UK+a/wceeCAzZszIo48+mvvuuy+vvfZaTjjhhKxfv76/6gMAAPpIr2I/ixYt6vJ6wYIFGTZsWJYuXZr3vOc9fVoYAAB0S+ynYluV+W9ubk6S7Lzzzj0e09ramtbW1s7XLS0tW3NJAACgQhWv9tPe3p4LLrggRx55ZA488MAej5szZ04aGxs7t1GjRlV6SQAAYCtU3PzPmDEjTz/9dG677bbNHjdr1qw0Nzd3bitWrKj0kgAA8IeHfNXaVgAVxX7OO++8fPvb386DDz6Y3XfffbPH1tfXp76+vqLiAACAvtOr5r+joyN/93d/l7vuuiv3339/9tprr/6qCwAA6GO9av5nzJiRW2+9Nd/61rcyZMiQNDU1JUkaGxuz/fbb90uBAADQhdV+KtarzP9VV12V5ubmHHvssdl11107t4ULF/ZXfQAAQB/pdewHAAAopq1a5x8AALY5sZ+KVbzUJwAAUCyafwAAKAmxHwAAiqUjtfdQrYLcGmvyDwAAJaH5BwCAkhD7AQCgWKz2UzGTfwAAKAnNPwAAlITYDwAAxdKe2lvtp9bq6YHJPwAAlITmHwAASkLsBwCAYrHaT8VM/gEAoCQ0/wAAUBJiPwAAFIvYT8VM/gEAoCQ0/wAAUBJiPwAAFIuHfFXM5B8AAEpC8w8AACUh9gMAQLFY7adiJv8AAFASmn8AACgJsR8AAIqlPbUXs7HaDwAAUEs0/wAAUBJiPwAAFIuHfFXM5B8AAEpC8w8AACUh9gMAQLF4yFfFTP4BAKAkNP8AAFASYj8AABSL1X4qZvIPAAAlofkHAICSEPsBAKBYrPZTMZN/AAAoCc0/AACUhNgPAADFIvZTMZN/AAAoCc0/AACUhNgPAADF4iFfFTP5BwCAktD8AwBASVQt9jPi8qSuWhenRyOrXQCb9dp0f2tq1c87OqpdAptxd52/O7VqbLULoFu/TfL9ahexOe2pvdV1xH4AAIBaovkHAICSsNoPAADF0pbaG2HXWgypB7X2sQEAAP1E8w8AACUh9gMAQLF4yFfFTP4BAKAkNP8AAFASYj8AABSL1X4qVmsfGwAA0E80/wAAUBJiPwAAFIvVfipm8g8AACWh+QcAgJIQ+wEAoFis9lOxWvvYAACAfqL5BwCAkhD7AQCgWMR+KlZrHxsAANBPNP8AAFASYj8AABRLR2rvoVod1S5gy5j8AwBASWj+AQCgJMR+AAAolrYkddUuYiNW+wEAAGqJ5h8AAEpC7AcAgGIR+6mYyT8AAJSE5h8AAEpC7AcAgGJpT+095KvW6umByT8AAJSE5h8AAEpC7AcAgGKx2k/FTP4BAKAkNP8AAFASYj8AABSL1X4qZvIPAAAlofkHAICSEPsBAKBYrPZTMZN/AAAoCc0/AACUhNgPAADF0p7ai9lY7QcAAKglmn8AACgJsR8AAIqlPbW32o/YDwAAUEs0/wAAUBK9av6vuuqqHHTQQWloaEhDQ0MmTpyY73znO/1VGwAAbKqtRrcC6FXzv/vuu+fLX/5yli5dmieeeCJ//ud/nlNOOSU/+tGP+qs+AACgj/Tqht8pU6Z0ef0P//APueqqq/Loo4/mgAMO6NPCAACAvlXxaj9tbW254447sn79+kycOLHH41pbW9Pa2tr5uqWlpdJLAgBAbUZsarGmbvT6ht+nnnoqO+64Y+rr6/PJT34yd911V8aMGdPj8XPmzEljY2PnNmrUqK0qGAAAqEyvm//99tsvy5Ytyw9+8IOce+65mTZtWn784x/3ePysWbPS3Nzcua1YsWKrCgYAACrT69jPoEGDsu+++yZJxo8fn8cffzxXXnllrrnmmm6Pr6+vT319/dZVCQAAb/CQr4pt9Tr/7e3tXTL9AABAberV5H/WrFk58cQTs8cee2Tt2rW59dZbc//992fx4sX9VR8AANBHetX8r169OlOnTs3KlSvT2NiYgw46KIsXL87xxx/fX/UBAEBXtbiyTi3W1I1eNf833HBDf9UBAAD0s63O/AMAAMVQ8UO+AACgKqz2UzGTfwAAKAnNPwAAlITYDwAAxVKLEZtarKkbJv8AAFASmn8AACgJsR8AAIqlLUlHtYvYiNgPAABQSzT/AABQEmI/AAAUSy1GbGqxpm6Y/AMAQBXMnz8/o0ePzuDBgzNhwoQ89thjPR577LHHpq6ubpPt5JNP7tU1Nf8AALCNLVy4MDNnzszs2bPz5JNPZuzYsZk8eXJWr17d7fHf/OY3s3Llys7t6aefzsCBA/PXf/3Xvbqu5h8AgGJpq9GtF+bOnZtzzjkn06dPz5gxY3L11Vdnhx12yI033tjt8TvvvHNGjBjRud13333ZYYcdNP8AAFAtLS0tXbbW1tZNjtmwYUOWLl2aSZMmde4bMGBAJk2alEceeWSLrnPDDTfkwx/+cN761rf2qj7NPwAA9JFRo0alsbGxc5szZ84mx6xZsyZtbW0ZPnx4l/3Dhw9PU1PTn7zGY489lqeffjpnn312r+uz2g8AAMVSww/5WrFiRRoaGjp319fX9/mlbrjhhrz73e/O4Ycf3uv3av4BAKCPNDQ0dGn+u7PLLrtk4MCBWbVqVZf9q1atyogRIzb73vXr1+e2227LF77whYrqE/sBAIBtaNCgQRk/fnyWLFnSua+9vT1LlizJxIkTN/veO+64I62trfnoRz9a0bVN/gEAKJZafKBWL2uaOXNmpk2blkMPPTSHH3545s2bl/Xr12f69OlJkqlTp2a33Xbb5J6BG264Iaeeemre/va3V1Sm5h8AALax0047LS+//HIuvfTSNDU1Zdy4cVm0aFHnTcDLly/PgAFdQzrPPvtsHnrooXz3u9+t+Lp1HR0d2/R2iZaWljQ2Nmb7JHXb8sJskZHVLoDNeq3aBdCjn2/b/5TSS3fX+V+cWvVytQugW79Ncn6S5ubmP5lf35be6COb35401Fh4vaU9afx17X1mGzP5BwCgWNpTe6v91Fo9Paix35kAAID+ovkHAICSEPsBAKBY2lN7N4+K/QAAALVE8w8AACUh9gMAQLG0ReynQib/AABQEpp/AAAoCbEfAACKReynYib/AABQEpp/AAAoCbEfAACKxUO+KmbyDwAAJaH5BwCAkhD7AQCgWKz2UzGTfwAAKAnNPwAAlITYDwAAxSL2UzGTfwAAKAnNPwAAlITYDwAAxdKRwsRsak3Vmv/vJtmxWhenRx+rdgFs1uRqF0CP7q6rtfApf+zUDl1CrXrK352atK7aBdBvxH4AAKAkxH4AACiUtt9vtaTW6umJyT8AAJSE5h8AAEpC7AcAgEIR+6mcyT8AAJSE5h8AAEpC7AcAgEJp//1WS2qtnp6Y/AMAQElo/gEAoCTEfgAAKBSr/VTO5B8AAEpC8w8AACUh9gMAQKFY7adyJv8AAFASmn8AACgJsR8AAArFaj+VM/kHAICS0PwDAEBJiP0AAFAo7am9mI3VfgAAgJqi+QcAgJIQ+wEAoFA85KtyJv8AAFASmn8AACgJsR8AAArFQ74qZ/IPAAAlofkHAICSEPsBAKBQxH4qZ/IPAAAlofkHAICSEPsBAKBQPOSrcib/AABQEpp/AAAoCbEfAAAKxWo/lTP5BwCAktD8AwBASYj9AABQKFb7qZzJPwAAlITmHwAASkLsBwCAQmlP7a2uI/YDAADUFM0/AACUhNgPAACF4iFflTP5BwCAktD8AwBASYj9AABQKB7yVbmtmvx/+ctfTl1dXS644II+KgcAAOgvFTf/jz/+eK655pocdNBBfVkPAADQTypq/tetW5ePfOQjue666/K2t72tr2sCAIAetdXoVgQVNf8zZszIySefnEmTJv3JY1tbW9PS0tJlAwAAtr1e3/B722235cknn8zjjz++RcfPmTMnn//853tdGAAA0Ld6NflfsWJFzj///Nxyyy0ZPHjwFr1n1qxZaW5u7txWrFhRUaEAAJBUP95T5NhPryb/S5cuzerVq3PIIYd07mtra8uDDz6Yr33ta2ltbc3AgQO7vKe+vj719fV9Uy0AAFCxXjX/733ve/PUU0912Td9+vTsv//+ufDCCzdp/AEAgNrRq+Z/yJAhOfDAA7vse+tb35q3v/3tm+wHAID+4CFflduqh3wBAADF0evVfjZ2//3390EZAABAf9vq5h8AALalWlxdp9bq6YnYDwAAlITmHwAASkLsBwCAQulI7a2u01HtAraQyT8AAJSE5h8AAEpC7AcAgEKx2k/lTP4BAKAkNP8AAFASYj8AABSK2E/lTP4BAKAkNP8AAFASYj8AABRKe2rvIV+1Vk9PTP4BAKAkNP8AAFASYj8AABSK1X4qZ/IPAAAlofkHAICSEPsBAKBQxH4qZ/IPAAAlofkHAICSEPsBAKBQPOSrcib/AABQEpp/AAAoCbEfAAAKpT21t7qO2A8AAFBTNP8AAFASYj8AABSK1X4qZ/IPAAAlofkHAICSEPsBAKBQ2lJ7q/3UWj09MfkHAICS0PwDAEBJiP0AAFAoYj+VM/kHAICS0PwDAEBJiP0AAFAoHvJVOZN/AAAoCc0/AACUhNgPAACFYrWfypn8AwBASWj+AQCgJMR+AAAoFLGfypn8AwBASVRt8v+OJA3Vujg9mlXtAtism6pdAD0aW+0C2Kyn6uqqXQI9eHdHR7VLoBstLS1JY2O1y6AfiP0AAFAoHam9h2oV5ddYsR8AACgJzT8AAJSE2A8AAIVitZ/KmfwDAEBJaP4BAKAkNP8AAFASMv8AABRKe2pvqc9aq6cnJv8AAFASmn8AACgJsR8AAArFUp+VM/kHAICS0PwDAEBJiP0AAFAoYj+VM/kHAICS0PwDAEBJaP4BACiU9hrdemv+/PkZPXp0Bg8enAkTJuSxxx7b7PGvvPJKZsyYkV133TX19fV55zvfmXvvvbdX15T5BwCAbWzhwoWZOXNmrr766kyYMCHz5s3L5MmT8+yzz2bYsGGbHL9hw4Ycf/zxGTZsWO68887stttueemll7LTTjv16rqafwAA2Mbmzp2bc845J9OnT0+SXH311bnnnnty44035rOf/ewmx9944435zW9+k4cffjjbbbddkmT06NG9vq7YDwAAhdJWo1uStLS0dNlaW1s3qX/Dhg1ZunRpJk2a1LlvwIABmTRpUh555JFuf+Z///d/z8SJEzNjxowMHz48Bx54YL70pS+lra136wxp/gEAoI+MGjUqjY2NnducOXM2OWbNmjVpa2vL8OHDu+wfPnx4mpqauj3vCy+8kDvvvDNtbW259957c8kll+SrX/1qvvjFL/aqPrEfAADoIytWrEhDQ0Pn6/r6+j45b3t7e4YNG5Zrr702AwcOzPjx4/PLX/4yV1xxRWbPnr3F59H8AwBQKO2pvYdqvbHaT0NDQ5fmvzu77LJLBg4cmFWrVnXZv2rVqowYMaLb9+y6667ZbrvtMnDgwM5973rXu9LU1JQNGzZk0KBBW1Sn2A8AAGxDgwYNyvjx47NkyZLOfe3t7VmyZEkmTpzY7XuOPPLIPP/882lv/8Oioj/96U+z6667bnHjn2j+AQBgm5s5c2auu+663HTTTfnJT36Sc889N+vXr+9c/Wfq1KmZNWtW5/HnnntufvOb3+T888/PT3/609xzzz350pe+lBkzZvTqumI/AAAUSqUP1epPva3ntNNOy8svv5xLL700TU1NGTduXBYtWtR5E/Dy5cszYMAf5vSjRo3K4sWL86lPfSoHHXRQdtttt5x//vm58MILe3Xduo6Ojo5e1rpVWlpa0tjYmKYkm09DUQ13VbsANuumahdAjz5Y7QLYrD+rdgH06N3btg1hC73RrzU3N//J/Pq29EZdX0oyuNrFbOTVJBclNfeZbUzsBwAASkLsBwCAQvnjh2rVilqrpycm/wAAUBKafwAAKAmxHwAACuXNsNpPtZj8AwBASWj+AQCgJMR+AAAoFKv9VM7kHwAASkLzDwAAJSH2AwBAoYj9VM7kHwAASkLzDwAAJSH2AwBAoXjIV+VM/gEAoCQ0/wAAUBJiPwAAFEp7am91HbEfAACgpmj+AQCgJMR+AAAoFA/5qlyvJv+XXXZZ6urqumz7779/f9UGAAD0oV5P/g844IB873vf+8MJ3uIfDwAAoAh63bm/5S1vyYgRI/qjFgAA+JM85Ktyvb7h97nnnsvIkSOz99575yMf+UiWL1++2eNbW1vT0tLSZQMAALa9XjX/EyZMyIIFC7Jo0aJcddVVefHFF3P00Udn7dq1Pb5nzpw5aWxs7NxGjRq11UUDAAC9V9fR0dFR6ZtfeeWV7Lnnnpk7d27OOuusbo9pbW1Na2tr5+uWlpaMGjUqTUkaKr0w/eauahfAZt1U7QLo0QerXQCb9WfVLoAevbvyNoR+1NLSksbGxjQ3N6ehoXY6tjfqOj9JfbWL2UhrkiuTmvvMNrZVd+vutNNOeec735nnn3++x2Pq6+tTX19rXw8AAJTPVj3ka926dfnZz36WXXfdta/qAQAA+kmvmv9Pf/rTeeCBB/Lzn/88Dz/8cD7wgQ9k4MCBOf300/urPgAA6KK9Rrci6FXs5xe/+EVOP/30/PrXv87QoUNz1FFH5dFHH83QoUP7qz4AAKCP9Kr5v+222/qrDgAAoJ95PC8AAIXS9vutltRaPT3Zqht+AQCA4tD8AwBASYj9AABQKGI/lTP5BwCAktD8AwBASYj9AABQKB2pvYdqdVS7gC1k8g8AACWh+QcAgJIQ+wEAoFCs9lM5k38AACgJzT8AAJSE2A8AAIUi9lM5k38AACgJzT8AAJSE2A8AAIXSntp7yFet1dMTk38AACgJzT8AAJSE2A8AAIVitZ/KmfwDAEBJaP4BAKAkxH4AACgUq/1UzuQfAABKQvMPAAAlIfYDAEChWO2ncib/AABQEpp/AAAoCbEfAAAKpT21F7Ox2g8AAFBTNP8AAFASYj8AABSKh3xVzuQfAABKQvMPAAAlIfYDAEChtKX2Jti1tvpQT2rtcwMAAPqJ5h8AAEpC7AcAgEIR+6lcrX1uAABAP9H8AwBASYj9AABQKB7yVTmTfwAAKAnNPwAAlITYDwAAhWK1n8rV2ucGAAD0k20++e/o6EiSrN3WF2aL/E+1C2CzXq92AfTot9UugM1aV+0C6FFLS0u1S6Abb3wvb/RtvHls8+Z/7drftf3v2NYXBuhH3692AVBUjY3VroDNWLt2bRpr8Duy2k/ltnnzP3LkyKxYsSJDhgxJXV3dtr58n2ppacmoUaOyYsWKNDQ0VLscNuL7qV2+m9rlu6ltvp/a9Wb7bjo6OrJ27dqMHDmy2qXQx7Z58z9gwIDsvvvu2/qy/aqhoeFN8Rf9zcr3U7t8N7XLd1PbfD+168303dTixJ+tZ7UfAAAKpT21t7pOUWI/VvsBAICS0Pxvhfr6+syePTv19fXVLoVu+H5ql++mdvluapvvp3b5biiKug5rOAEAUAAtLS1pbGzMsam97PrrSe5P0tzcXNP3fZj8AwBASWj+AQCgJGrtX0wAAGCzPOSrcib/AABQEpr/rTB//vyMHj06gwcPzoQJE/LYY49VuySSPPjgg5kyZUpGjhyZurq63H333dUuid+bM2dODjvssAwZMiTDhg3LqaeemmeffbbaZZHkqquuykEHHdT5gKKJEyfmO9/5TrXLohtf/vKXU1dXlwsuuKDapZDksssuS11dXZdt//33r3ZZ0CPNf4UWLlyYmTNnZvbs2XnyySczduzYTJ48OatXr652aaW3fv36jB07NvPnz692KWzkgQceyIwZM/Loo4/mvvvuy2uvvZYTTjgh69evr3Zppbf77rvny1/+cpYuXZonnngif/7nf55TTjklP/rRj6pdGn/k8ccfzzXXXJODDjqo2qXwRw444ICsXLmyc3vooYeqXdKbXluNbkVgqc8KTZgwIYcddli+9rWvJUna29szatSo/N3f/V0++9nPVrk63lBXV5e77rorp556arVLoRsvv/xyhg0blgceeCDvec97ql0OG9l5551zxRVX5Kyzzqp2KSRZt25dDjnkkHz961/PF7/4xYwbNy7z5s2rdlmld9lll+Xuu+/OsmXLql1KKbyx1OeRqb0bV19P8n9jqc83pQ0bNmTp0qWZNGlS574BAwZk0qRJeeSRR6pYGRRLc3Nzkt81mdSOtra23HbbbVm/fn0mTpxY7XL4vRkzZuTkk0/u8r891IbnnnsuI0eOzN57752PfOQjWb58ebVLgh7V2i9NhbBmzZq0tbVl+PDhXfYPHz48zzzzTJWqgmJpb2/PBRdckCOPPDIHHnhgtcshyVNPPZWJEyfm1VdfzY477pi77rorY8aMqXZZJLntttvy5JNP5vHHH692KWxkwoQJWbBgQfbbb7+sXLkyn//853P00Ufn6aefzpAhQ6pd3ptWW5K6ahexkaLEfjT/QFXMmDEjTz/9tGxsDdlvv/2ybNmyNDc3584778y0adPywAMP+AWgylasWJHzzz8/9913XwYPHlztctjIiSee2Pl/H3TQQZkwYUL23HPP3H777SJz1CTNfwV22WWXDBw4MKtWreqyf9WqVRkxYkSVqoLiOO+88/Ltb387Dz74YHbfffdql8PvDRo0KPvuu2+SZPz48Xn88cdz5ZVX5pprrqlyZeW2dOnSrF69Ooccckjnvra2tjz44IP52te+ltbW1gwcOLCKFfLHdtppp7zzne/M888/X+1SoFsy/xUYNGhQxo8fnyVLlnTua29vz5IlS+RjYTM6Ojpy3nnn5a677sr3v//97LXXXtUuic1ob29Pa2trtcsovfe+97156qmnsmzZss7t0EMPzUc+8pEsW7ZM419j1q1bl5/97GfZddddq13Km1p7jW5FYPJfoZkzZ2batGk59NBDc/jhh2fevHlZv359pk+fXu3SSm/dunVdJi4vvvhili1blp133jl77LFHFStjxowZufXWW/Otb30rQ4YMSVNTU5KksbEx22+/fZWrK7dZs2blxBNPzB577JG1a9fm1ltvzf3335/FixdXu7TSGzJkyCb3xbz1rW/N29/+dvfL1IBPf/rTmTJlSvbcc8/86le/yuzZszNw4MCcfvrp1S4NuqX5r9Bpp52Wl19+OZdeemmampoybty4LFq0aJObgNn2nnjiiRx33HGdr2fOnJkkmTZtWhYsWFClqkh+9yCpJDn22GO77P/GN76RM888c9sXRKfVq1dn6tSpWblyZRobG3PQQQdl8eLFOf7446tdGtS0X/ziFzn99NPz61//OkOHDs1RRx2VRx99NEOHDq12adAt6/wDAFAIb6zzPz61N8F+PcnSWOcfAACoEZp/AAAoiVr7FxMAANisjtTe6jpFydGb/AMAQElo/gEAoCTEfgAAKJS2ahfQjVqsqTsm/wAAUBKafwAAKAmxHwAACqUWIza1WFN3TP4BAKAkNP8AAFASYj8AABRKe5K6ahexkVp76FhPTP4BAKAkNP8AAFASYj8AABRKLa6sU4s1dcfkHwAASkLzDwAAJSH2AwBAodRixKYWa+qOyT8AAJSE5h8AAEpC7AcAgELxkK/KmfwDAEBJaP4BAKAkxH4AACiUWozY1GJN3TH5BwCAktD8AwBASYj9AABQKLUYsanFmrpj8g8AACWh+QcAgJIQ+wEAoFDaknRUu4iNiP0AAAA1RfMPAAAlIfYDAEChiP1UzuQfAABKQvMPAAAlIfYDAECh1GLEphZr6o7JPwAAlITmHwAASkLsBwCAQrHaT+VM/gEAoCQ0/wAAUBJiPwAAFEp7ai/2U2v19MTkHwAASkLzDwAAJaH5BwCgUNprdOut+fPnZ/To0Rk8eHAmTJiQxx57rMdjFyxYkLq6ui7b4MGDe31NzT8AAGxjCxcuzMyZMzN79uw8+eSTGTt2bCZPnpzVq1f3+J6GhoasXLmyc3vppZd6fV3NPwAA9JGWlpYuW2tra7fHzZ07N+ecc06mT5+eMWPG5Oqrr84OO+yQG2+8scdz19XVZcSIEZ3b8OHDe12f5h8AgEJpq9EtSUaNGpXGxsbObc6cOZvUv2HDhixdujSTJk3q3DdgwIBMmjQpjzzySI8/97p167Lnnntm1KhROeWUU/KjH/2oF5/a71jqEwAA+siKFSvS0NDQ+bq+vn6TY9asWZO2trZNJvfDhw/PM8880+1599tvv9x444056KCD0tzcnK985Ss54ogj8qMf/Si77777Ften+QcAgD7S0NDQpfnvKxMnTszEiRM7Xx9xxBF517velWuuuSaXX375Fp9H8w8AQKG0J6mrdhEb6c1DvnbZZZcMHDgwq1at6rJ/1apVGTFixBadY7vttsvBBx+c559/vhdXlvkHAIBtatCgQRk/fnyWLFnSua+9vT1LlizpMt3fnLa2tjz11FPZdddde3Vtk38AAAqlN1P2baW3Nc2cOTPTpk3LoYcemsMPPzzz5s3L+vXrM3369CTJ1KlTs9tuu3XeMPyFL3whf/Znf5Z99903r7zySq644oq89NJLOfvss3t1Xc0/AACFMGjQoIwYMSJNTU3VLqVbI0aMyKBBg7bo2NNOOy0vv/xyLr300jQ1NWXcuHFZtGhR503Ay5cvz4ABfwjp/Pd//3fOOeecNDU15W1ve1vGjx+fhx9+OGPGjOlVjXUdHR21+MsTAABs4tVXX82GDRuqXUa3Bg0aVNFTd7clzT8AAJSEG34BAKAkNP8AAFASmn8AACgJzT8AAJSE5h8AAEpC8w8AACWh+QcAgJLQ/AMAQElo/gEAoCQ0/wAAUBL/P5dpVbQI2/9kAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the adjancy matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(adjancy_matrix, cmap='hot', interpolation='nearest')\n",
    "plt.title(\"MCS for index: \" + str(l1_index))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the adjancy matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(adjancy_matrix, cmap='hot', interpolation='nearest')\n",
    "plt.title(\"MCS for index: \" + str(l1_index))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4964340803012419"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_cosine_similarities.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCS\n",
    "Max cosine similarity between one dictionary & another one. If they learned the same feature, then they'll have high cosine similarity. \n",
    "\n",
    "If two dictionaries learned it, it's probably a real feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# of features above 0.9:', 2768)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqu0lEQVR4nO3dfXRU9Z3H8c+EkAkiMyHQzDDb8KC1QpRiSzSOj7XmECRiqXGVNUvT3SxsNaErUSRZBcGnYHR9wEayuNZwtri67hFWEaNpEFIlBgxmwQhRKxgsnURPzAzBkgdy949u7jqASnCG5Bfer3PuOc79fe+d7/UK8/E3995xWJZlCQAAwCAx/d0AAABAXxFgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGie3vBqKlp6dH+/fv14gRI+RwOPq7HQAAcBwsy9KBAwfk8/kUE/PV8yyDNsDs379fycnJ/d0GAAA4Afv27dN3v/vdrxwftAFmxIgRkv7yL8DlcvVzNwAA4HiEQiElJyfbn+NfZdAGmN6vjVwuFwEGAADDfNPlH32+iLe6ulozZ86Uz+eTw+HQunXrjqrZtWuXrrnmGrndbg0fPlznn3++mpqa7PFDhw4pLy9Po0aN0umnn66srCw1NzeH7aOpqUmZmZk67bTTlJSUpIULF6q7u7uv7QIAgEGozwHm4MGDmjJlikpLS485/oc//EGXXHKJJk6cqE2bNmnHjh1avHix4uPj7ZoFCxbopZde0vPPP6/Nmzdr//79uvbaa+3xw4cPKzMzU52dndqyZYtWr16t8vJyLVmy5AQOEQAADDYOy7KsE97Y4dDatWs1a9Yse93s2bM1dOhQ/fu///sxtwkGg/rOd76jZ555Rtddd50kaffu3Zo0aZJqamp04YUX6pVXXtHVV1+t/fv3y+PxSJLKysq0aNEiffrpp4qLi/vG3kKhkNxut4LBIF8hAQBgiOP9/I7oc2B6enr08ssv6/vf/74yMjKUlJSktLS0sK+Z6urq1NXVpfT0dHvdxIkTNXbsWNXU1EiSampqNHnyZDu8SFJGRoZCoZAaGhoi2TIAADBQRANMS0uL2tvbtXz5ck2fPl2vvfaafvazn+naa6/V5s2bJUmBQEBxcXFKSEgI29bj8SgQCNg1Xw4vveO9Y8fS0dGhUCgUtgAAgMEponch9fT0SJJ++tOfasGCBZKk8847T1u2bFFZWZkuv/zySL5dmOLiYi1btixq+wcAAANHRGdgRo8erdjYWKWkpIStnzRpkn0XktfrVWdnp9ra2sJqmpub5fV67Zoj70rqfd1bc6SioiIFg0F72bdvXyQOCQAADEARDTBxcXE6//zz1djYGLb+/fff17hx4yRJU6dO1dChQ1VVVWWPNzY2qqmpSX6/X5Lk9/u1c+dOtbS02DWVlZVyuVxHhaNeTqfTfuYLz34BAGBw6/NXSO3t7frwww/t13v27FF9fb0SExM1duxYLVy4UDfccIMuu+wyXXHFFaqoqNBLL72kTZs2SZLcbrdyc3NVUFCgxMREuVwuzZ8/X36/XxdeeKEkadq0aUpJSdGcOXNUUlKiQCCgO++8U3l5eXI6nZE5cgAAYC6rj15//XVL0lFLTk6OXfPUU09Z3/ve96z4+HhrypQp1rp168L28ec//9m6+eabrZEjR1qnnXaa9bOf/cz605/+FFazd+9e66qrrrKGDRtmjR492rr11lutrq6u4+4zGAxakqxgMNjXQwQAAP3keD+/v9VzYAYyngMDAIB5+uU5MAAAACcDAQYAABiHAAMAAIwT0QfZAQCAgWV84ctR2e/e5ZlR2e/xYgYGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGCcPgeY6upqzZw5Uz6fTw6HQ+vWrfvK2l/+8pdyOBx69NFHw9a3trYqOztbLpdLCQkJys3NVXt7e1jNjh07dOmllyo+Pl7JyckqKSnpa6sAAGCQ6nOAOXjwoKZMmaLS0tKvrVu7dq3eeust+Xy+o8ays7PV0NCgyspKrV+/XtXV1Zo3b549HgqFNG3aNI0bN051dXV68MEHtXTpUq1ataqv7QIAgEEotq8bXHXVVbrqqqu+tuaPf/yj5s+fr1dffVWZmZlhY7t27VJFRYW2bdum1NRUSdLjjz+uGTNm6KGHHpLP59OaNWvU2dmp3/zmN4qLi9M555yj+vp6Pfzww2FBBwAAnJoifg1MT0+P5syZo4ULF+qcc845arympkYJCQl2eJGk9PR0xcTEqLa21q657LLLFBcXZ9dkZGSosbFRn3/++THft6OjQ6FQKGwBAACDU8QDzAMPPKDY2Fj96le/OuZ4IBBQUlJS2LrY2FglJiYqEAjYNR6PJ6ym93VvzZGKi4vldrvtJTk5+dseCgAAGKAiGmDq6ur02GOPqby8XA6HI5K7/kZFRUUKBoP2sm/fvpP6/gAA4OSJaID5/e9/r5aWFo0dO1axsbGKjY3Vxx9/rFtvvVXjx4+XJHm9XrW0tIRt193drdbWVnm9Xrumubk5rKb3dW/NkZxOp1wuV9gCAAAGp4gGmDlz5mjHjh2qr6+3F5/Pp4ULF+rVV1+VJPn9frW1tamurs7ebuPGjerp6VFaWppdU11dra6uLrumsrJSZ599tkaOHBnJlgEAgIH6fBdSe3u7PvzwQ/v1nj17VF9fr8TERI0dO1ajRo0Kqx86dKi8Xq/OPvtsSdKkSZM0ffp0zZ07V2VlZerq6lJ+fr5mz55t33J94403atmyZcrNzdWiRYv07rvv6rHHHtMjjzzybY4VAAAMEn0OMG+//bauuOIK+3VBQYEkKScnR+Xl5ce1jzVr1ig/P19XXnmlYmJilJWVpRUrVtjjbrdbr732mvLy8jR16lSNHj1aS5Ys4RZqAAAgSXJYlmX1dxPREAqF5Ha7FQwGuR4GAHDKGl/4clT2u3d55jcXnYDj/fzmt5AAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDh9DjDV1dWaOXOmfD6fHA6H1q1bZ491dXVp0aJFmjx5soYPHy6fz6ef//zn2r9/f9g+WltblZ2dLZfLpYSEBOXm5qq9vT2sZseOHbr00ksVHx+v5ORklZSUnNgRAgCAQafPAebgwYOaMmWKSktLjxr74osvtH37di1evFjbt2/XCy+8oMbGRl1zzTVhddnZ2WpoaFBlZaXWr1+v6upqzZs3zx4PhUKaNm2axo0bp7q6Oj344INaunSpVq1adQKHCAAABhuHZVnWCW/scGjt2rWaNWvWV9Zs27ZNF1xwgT7++GONHTtWu3btUkpKirZt26bU1FRJUkVFhWbMmKFPPvlEPp9PK1eu1B133KFAIKC4uDhJUmFhodatW6fdu3cfV2+hUEhut1vBYFAul+tEDxEAAKONL3w5KvvduzwzKvs93s/vqF8DEwwG5XA4lJCQIEmqqalRQkKCHV4kKT09XTExMaqtrbVrLrvsMju8SFJGRoYaGxv1+eefH/N9Ojo6FAqFwhYAADA4RTXAHDp0SIsWLdLf/M3f2CkqEAgoKSkprC42NlaJiYkKBAJ2jcfjCavpfd1bc6Ti4mK53W57SU5OjvThAACAASJqAaarq0vXX3+9LMvSypUro/U2tqKiIgWDQXvZt29f1N8TAAD0j9ho7LQ3vHz88cfauHFj2HdYXq9XLS0tYfXd3d1qbW2V1+u1a5qbm8Nqel/31hzJ6XTK6XRG8jAAAMAAFfEZmN7w8sEHH+h3v/udRo0aFTbu9/vV1tamuro6e93GjRvV09OjtLQ0u6a6ulpdXV12TWVlpc4++2yNHDky0i0DAADD9DnAtLe3q76+XvX19ZKkPXv2qL6+Xk1NTerq6tJ1112nt99+W2vWrNHhw4cVCAQUCATU2dkpSZo0aZKmT5+uuXPnauvWrXrzzTeVn5+v2bNny+fzSZJuvPFGxcXFKTc3Vw0NDXruuef02GOPqaCgIHJHDgAAjNXn26g3bdqkK6644qj1OTk5Wrp0qSZMmHDM7V5//XX9+Mc/lvSXB9nl5+frpZdeUkxMjLKysrRixQqdfvrpdv2OHTuUl5enbdu2afTo0Zo/f74WLVp03H1yGzUAAIP3Nupv9RyYgYwAAwDA4A0w/BYSAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABinzwGmurpaM2fOlM/nk8Ph0Lp168LGLcvSkiVLNGbMGA0bNkzp6en64IMPwmpaW1uVnZ0tl8ulhIQE5ebmqr29Paxmx44duvTSSxUfH6/k5GSVlJT0/egAAMCg1OcAc/DgQU2ZMkWlpaXHHC8pKdGKFStUVlam2tpaDR8+XBkZGTp06JBdk52drYaGBlVWVmr9+vWqrq7WvHnz7PFQKKRp06Zp3Lhxqqur04MPPqilS5dq1apVJ3CIAABgsHFYlmWd8MYOh9auXatZs2ZJ+svsi8/n06233qrbbrtNkhQMBuXxeFReXq7Zs2dr165dSklJ0bZt25SamipJqqio0IwZM/TJJ5/I5/Np5cqVuuOOOxQIBBQXFydJKiws1Lp167R79+7j6i0UCsntdisYDMrlcp3oIQIAYLTxhS9HZb97l2dGZb/H+/kd0Wtg9uzZo0AgoPT0dHud2+1WWlqaampqJEk1NTVKSEiww4skpaenKyYmRrW1tXbNZZddZocXScrIyFBjY6M+//zzY753R0eHQqFQ2AIAAAaniAaYQCAgSfJ4PGHrPR6PPRYIBJSUlBQ2Hhsbq8TExLCaY+3jy+9xpOLiYrndbntJTk7+9gcEAAAGpEFzF1JRUZGCwaC97Nu3r79bAgAAURLRAOP1eiVJzc3NYeubm5vtMa/Xq5aWlrDx7u5utba2htUcax9ffo8jOZ1OuVyusAUAAAxOEQ0wEyZMkNfrVVVVlb0uFAqptrZWfr9fkuT3+9XW1qa6ujq7ZuPGjerp6VFaWppdU11dra6uLrumsrJSZ599tkaOHBnJlgEAgIH6HGDa29tVX1+v+vp6SX+5cLe+vl5NTU1yOBy65ZZbdO+99+rFF1/Uzp079fOf/1w+n8++U2nSpEmaPn265s6dq61bt+rNN99Ufn6+Zs+eLZ/PJ0m68cYbFRcXp9zcXDU0NOi5557TY489poKCgogdOAAAMFdsXzd4++23dcUVV9ive0NFTk6OysvLdfvtt+vgwYOaN2+e2tradMkll6iiokLx8fH2NmvWrFF+fr6uvPJKxcTEKCsrSytWrLDH3W63XnvtNeXl5Wnq1KkaPXq0lixZEvasGAAAcOr6Vs+BGch4DgwAADwHBgAAYMDo81dIAAAgsqI1SzKYMQMDAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABgn4gHm8OHDWrx4sSZMmKBhw4bpzDPP1D333CPLsuway7K0ZMkSjRkzRsOGDVN6ero++OCDsP20trYqOztbLpdLCQkJys3NVXt7e6TbBQAABop4gHnggQe0cuVK/frXv9auXbv0wAMPqKSkRI8//rhdU1JSohUrVqisrEy1tbUaPny4MjIydOjQIbsmOztbDQ0Nqqys1Pr161VdXa158+ZFul0AAGAgh/XlqZEIuPrqq+XxePTUU0/Z67KysjRs2DD99re/lWVZ8vl8uvXWW3XbbbdJkoLBoDwej8rLyzV79mzt2rVLKSkp2rZtm1JTUyVJFRUVmjFjhj755BP5fL5v7CMUCsntdisYDMrlckXyEAEAiKjxhS/3dwt9tnd5ZlT2e7yf3xGfgbnoootUVVWl999/X5L0P//zP3rjjTd01VVXSZL27NmjQCCg9PR0exu32620tDTV1NRIkmpqapSQkGCHF0lKT09XTEyMamtrj/m+HR0dCoVCYQsAABicYiO9w8LCQoVCIU2cOFFDhgzR4cOHdd999yk7O1uSFAgEJEkejydsO4/HY48FAgElJSWFNxobq8TERLvmSMXFxVq2bFmkDwcAAAxAEZ+B+c///E+tWbNGzzzzjLZv367Vq1froYce0urVqyP9VmGKiooUDAbtZd++fVF9PwAA0H8iPgOzcOFCFRYWavbs2ZKkyZMn6+OPP1ZxcbFycnLk9XolSc3NzRozZoy9XXNzs8477zxJktfrVUtLS9h+u7u71draam9/JKfTKafTGenDAQAAA1DEZ2C++OILxcSE73bIkCHq6emRJE2YMEFer1dVVVX2eCgUUm1trfx+vyTJ7/erra1NdXV1ds3GjRvV09OjtLS0SLcMAAAME/EZmJkzZ+q+++7T2LFjdc455+idd97Rww8/rL//+7+XJDkcDt1yyy269957ddZZZ2nChAlavHixfD6fZs2aJUmaNGmSpk+frrlz56qsrExdXV3Kz8/X7Nmzj+sOJAAAMLhFPMA8/vjjWrx4sW6++Wa1tLTI5/PpH//xH7VkyRK75vbbb9fBgwc1b948tbW16ZJLLlFFRYXi4+PtmjVr1ig/P19XXnmlYmJilJWVpRUrVkS6XQAAYKCIPwdmoOA5MAAAU/AcmP/Xb8+BAQAAiDYCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwTlQCzB//+Ef97d/+rUaNGqVhw4Zp8uTJevvtt+1xy7K0ZMkSjRkzRsOGDVN6ero++OCDsH20trYqOztbLpdLCQkJys3NVXt7ezTaBQAAhol4gPn888918cUXa+jQoXrllVf03nvv6V/+5V80cuRIu6akpEQrVqxQWVmZamtrNXz4cGVkZOjQoUN2TXZ2thoaGlRZWan169erurpa8+bNi3S7AADAQA7LsqxI7rCwsFBvvvmmfv/73x9z3LIs+Xw+3XrrrbrtttskScFgUB6PR+Xl5Zo9e7Z27dqllJQUbdu2TampqZKkiooKzZgxQ5988ol8Pt839hEKheR2uxUMBuVyuSJ3gAAARNj4wpf7u4U+27s8Myr7Pd7P74jPwLz44otKTU3VX//1XyspKUk//OEP9eSTT9rje/bsUSAQUHp6ur3O7XYrLS1NNTU1kqSamholJCTY4UWS0tPTFRMTo9ra2ki3DAAADBPxAPPRRx9p5cqVOuuss/Tqq6/qpptu0q9+9SutXr1akhQIBCRJHo8nbDuPx2OPBQIBJSUlhY3HxsYqMTHRrjlSR0eHQqFQ2AIAAAan2EjvsKenR6mpqbr//vslST/84Q/17rvvqqysTDk5OZF+O1txcbGWLVsWtf0DAICBI+IzMGPGjFFKSkrYukmTJqmpqUmS5PV6JUnNzc1hNc3NzfaY1+tVS0tL2Hh3d7daW1vtmiMVFRUpGAzay759+yJyPAAAYOCJeIC5+OKL1djYGLbu/fff17hx4yRJEyZMkNfrVVVVlT0eCoVUW1srv98vSfL7/Wpra1NdXZ1ds3HjRvX09CgtLe2Y7+t0OuVyucIWAAAwOEX8K6QFCxbooosu0v3336/rr79eW7du1apVq7Rq1SpJksPh0C233KJ7771XZ511liZMmKDFixfL5/Np1qxZkv4yYzN9+nTNnTtXZWVl6urqUn5+vmbPnn1cdyABAIDBLeIB5vzzz9fatWtVVFSku+++WxMmTNCjjz6q7Oxsu+b222/XwYMHNW/ePLW1temSSy5RRUWF4uPj7Zo1a9YoPz9fV155pWJiYpSVlaUVK1ZEul0AAGCgiD8HZqDgOTAAAFPwHJj/12/PgQEAAIg2AgwAADAOAQYAABgn4hfxAgAwWJl4rcpgxQwMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjBPb3w0A/WF84ctR2/fe5ZlR2zcA4C+YgQEAAMYhwAAAAOMQYAAAgHG4BgYDWjSvVQEAmIsZGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcaIeYJYvXy6Hw6FbbrnFXnfo0CHl5eVp1KhROv3005WVlaXm5uaw7ZqampSZmanTTjtNSUlJWrhwobq7u6PdLgAAMEBUA8y2bdv0r//6r/rBD34Qtn7BggV66aWX9Pzzz2vz5s3av3+/rr32Wnv88OHDyszMVGdnp7Zs2aLVq1ervLxcS5YsiWa7AADAEFELMO3t7crOztaTTz6pkSNH2uuDwaCeeuopPfzww/rJT36iqVOn6umnn9aWLVv01ltvSZJee+01vffee/rtb3+r8847T1dddZXuuecelZaWqrOzM1otAwAAQ0QtwOTl5SkzM1Pp6elh6+vq6tTV1RW2fuLEiRo7dqxqamokSTU1NZo8ebI8Ho9dk5GRoVAopIaGhmO+X0dHh0KhUNgCAAAGp6j8FtKzzz6r7du3a9u2bUeNBQIBxcXFKSEhIWy9x+NRIBCwa74cXnrHe8eOpbi4WMuWLYtA9wAAYKCL+AzMvn379E//9E9as2aN4uPjI737r1RUVKRgMGgv+/btO2nvDQAATq6IB5i6ujq1tLToRz/6kWJjYxUbG6vNmzdrxYoVio2NlcfjUWdnp9ra2sK2a25ultfrlSR5vd6j7krqfd1bcySn0ymXyxW2AACAwSniAebKK6/Uzp07VV9fby+pqanKzs62/3no0KGqqqqyt2lsbFRTU5P8fr8kye/3a+fOnWppabFrKisr5XK5lJKSEumWAQCAYSJ+DcyIESN07rnnhq0bPny4Ro0aZa/Pzc1VQUGBEhMT5XK5NH/+fPn9fl144YWSpGnTpiklJUVz5sxRSUmJAoGA7rzzTuXl5cnpdEa6ZQAAYJioXMT7TR555BHFxMQoKytLHR0dysjI0BNPPGGPDxkyROvXr9dNN90kv9+v4cOHKycnR3fffXd/tAsAAAaYkxJgNm3aFPY6Pj5epaWlKi0t/cptxo0bpw0bNkS5MwAAYCJ+CwkAABiHAAMAAIxDgAEAAMYhwAAAAOP0y11IAABEy/jCl/u7BZwEzMAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHH4KQEgwqL1GPO9yzOjsl8AMBEzMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhx9zBAD0i2j98ClODczAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwTsQDTHFxsc4//3yNGDFCSUlJmjVrlhobG8NqDh06pLy8PI0aNUqnn366srKy1NzcHFbT1NSkzMxMnXbaaUpKStLChQvV3d0d6XYBAICBIh5gNm/erLy8PL311luqrKxUV1eXpk2bpoMHD9o1CxYs0EsvvaTnn39emzdv1v79+3Xttdfa44cPH1ZmZqY6Ozu1ZcsWrV69WuXl5VqyZEmk2wUAAAZyWJZlRfMNPv30UyUlJWnz5s267LLLFAwG9Z3vfEfPPPOMrrvuOknS7t27NWnSJNXU1OjCCy/UK6+8oquvvlr79++Xx+ORJJWVlWnRokX69NNPFRcX943vGwqF5Ha7FQwG5XK5onmIiCKeE/H/9i7P7O8WgIjiz7fZovV30vF+fkf9GphgMChJSkxMlCTV1dWpq6tL6enpds3EiRM1duxY1dTUSJJqamo0efJkO7xIUkZGhkKhkBoaGo75Ph0dHQqFQmELAAAYnKIaYHp6enTLLbfo4osv1rnnnitJCgQCiouLU0JCQlitx+NRIBCwa74cXnrHe8eOpbi4WG63216Sk5MjfDQAAGCgiOpPCeTl5endd9/VG2+8Ec23kSQVFRWpoKDAfh0KhQgxAPAt8TUPBqqoBZj8/HytX79e1dXV+u53v2uv93q96uzsVFtbW9gsTHNzs7xer12zdevWsP313qXUW3Mkp9Mpp9MZ4aMAAAADUcS/QrIsS/n5+Vq7dq02btyoCRMmhI1PnTpVQ4cOVVVVlb2usbFRTU1N8vv9kiS/36+dO3eqpaXFrqmsrJTL5VJKSkqkWwYAAIaJ+AxMXl6ennnmGf33f/+3RowYYV+z4na7NWzYMLndbuXm5qqgoECJiYlyuVyaP3++/H6/LrzwQknStGnTlJKSojlz5qikpESBQEB33nmn8vLymGXBKSuaU/nc4QTANBEPMCtXrpQk/fjHPw5b//TTT+sXv/iFJOmRRx5RTEyMsrKy1NHRoYyMDD3xxBN27ZAhQ7R+/XrddNNN8vv9Gj58uHJycnT33XdHul0AAGCgiAeY43msTHx8vEpLS1VaWvqVNePGjdOGDRsi2RoAABgk+C0kAABgnKjeRg0AODm43RmnGmZgAACAcQgwAADAOAQYAABgHK6BAYCThOtUgMhhBgYAABiHAAMAAIxDgAEAAMbhGhgAUbs2g99YAhAtzMAAAADjEGAAAIBxCDAAAMA4XAMDwEjRfKYK1+4AAx8zMAAAwDgEGAAAYBy+QgKAI/DIf2DgI8DgW+MvewDAycZXSAAAwDjMwACIGmbnAEQLMzAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcfczyF8MN6AIDBghkYAABgnAEdYEpLSzV+/HjFx8crLS1NW7du7e+WAADAADBgA8xzzz2ngoIC3XXXXdq+fbumTJmijIwMtbS09HdrAACgnzksy7L6u4ljSUtL0/nnn69f//rXkqSenh4lJydr/vz5Kiws/MbtQ6GQ3G63gsGgXC5XtNuNGK5TAQCYYO/yzKjs93g/vwfkRbydnZ2qq6tTUVGRvS4mJkbp6emqqak55jYdHR3q6OiwXweDQUl/+Rdhkp6OL/q7BQAAvlG0Pl979/tN8ysDMsB89tlnOnz4sDweT9h6j8ej3bt3H3Ob4uJiLVu27Kj1ycnJUekRAIBTmfvR6O7/wIEDcrvdXzk+IAPMiSgqKlJBQYH9uqenR62trRo1apQcDkc/dvbVQqGQkpOTtW/fPqO+5jpVcb7MwzkzC+fLPNE4Z5Zl6cCBA/L5fF9bNyADzOjRozVkyBA1NzeHrW9ubpbX6z3mNk6nU06nM2xdQkJCtFqMKJfLxR9Wg3C+zMM5MwvnyzyRPmdfN/PSa0DehRQXF6epU6eqqqrKXtfT06Oqqir5/f5+7AwAAAwEA3IGRpIKCgqUk5Oj1NRUXXDBBXr00Ud18OBB/d3f/V1/twYAAPrZgA0wN9xwgz799FMtWbJEgUBA5513nioqKo66sNdkTqdTd91111FffWFg4nyZh3NmFs6XefrznA3Y58AAAAB8lQF5DQwAAMDXIcAAAADjEGAAAIBxCDAAAMA4BJgoKy0t1fjx4xUfH6+0tDRt3br1K2uffPJJXXrppRo5cqRGjhyp9PT0r61H5PXlfH3Zs88+K4fDoVmzZkW3QRylr+esra1NeXl5GjNmjJxOp77//e9rw4YNJ6lb9PV8Pfroozr77LM1bNgwJScna8GCBTp06NBJ6vbUVl1drZkzZ8rn88nhcGjdunXfuM2mTZv0ox/9SE6nU9/73vdUXl4evQYtRM2zzz5rxcXFWb/5zW+shoYGa+7cuVZCQoLV3Nx8zPobb7zRKi0ttd555x1r165d1i9+8QvL7XZbn3zyyUnu/NTU1/PVa8+ePdZf/dVfWZdeeqn105/+9OQ0C8uy+n7OOjo6rNTUVGvGjBnWG2+8Ye3Zs8fatGmTVV9ff5I7PzX19XytWbPGcjqd1po1a6w9e/ZYr776qjVmzBhrwYIFJ7nzU9OGDRusO+64w3rhhRcsSdbatWu/tv6jjz6yTjvtNKugoMB67733rMcff9waMmSIVVFREZX+CDBRdMEFF1h5eXn268OHD1s+n88qLi4+ru27u7utESNGWKtXr45Wi/iSEzlf3d3d1kUXXWT927/9m5WTk0OAOcn6es5WrlxpnXHGGVZnZ+fJahFf0tfzlZeXZ/3kJz8JW1dQUGBdfPHFUe0TRzueAHP77bdb55xzTti6G264wcrIyIhKT3yFFCWdnZ2qq6tTenq6vS4mJkbp6emqqak5rn188cUX6urqUmJiYrTaxP850fN19913KykpSbm5uSejTXzJiZyzF198UX6/X3l5efJ4PDr33HN1//336/Dhwyer7VPWiZyviy66SHV1dfbXTB999JE2bNigGTNmnJSe0Tc1NTVh51eSMjIyjvszr68G7JN4TffZZ5/p8OHDRz052OPxaPfu3ce1j0WLFsnn8x31HwQi70TO1xtvvKGnnnpK9fX1J6FDHOlEztlHH32kjRs3Kjs7Wxs2bNCHH36om2++WV1dXbrrrrtORtunrBM5XzfeeKM+++wzXXLJJbIsS93d3frlL3+pf/7nfz4ZLaOPAoHAMc9vKBTSn//8Zw0bNiyi78cMzAC1fPlyPfvss1q7dq3i4+P7ux0c4cCBA5ozZ46efPJJjR49ur/bwXHq6elRUlKSVq1apalTp+qGG27QHXfcobKysv5uDcewadMm3X///XriiSe0fft2vfDCC3r55Zd1zz339HdrGACYgYmS0aNHa8iQIWpubg5b39zcLK/X+7XbPvTQQ1q+fLl+97vf6Qc/+EE028T/6ev5+sMf/qC9e/dq5syZ9rqenh5JUmxsrBobG3XmmWdGt+lT3In8GRszZoyGDh2qIUOG2OsmTZqkQCCgzs5OxcXFRbXnU9mJnK/Fixdrzpw5+od/+AdJ0uTJk3Xw4EHNmzdPd9xxh2Ji+H/wgcTr9R7z/LpcrojPvkjMwERNXFycpk6dqqqqKntdT0+Pqqqq5Pf7v3K7kpIS3XPPPaqoqFBqaurJaBXq+/maOHGidu7cqfr6enu55pprdMUVV6i+vl7Jyckns/1T0on8Gbv44ov14Ycf2mFTkt5//32NGTOG8BJlJ3K+vvjii6NCSm/4tPgZvwHH7/eHnV9Jqqys/NrPvG8lKpcGw7Ksv9wy6HQ6rfLycuu9996z5s2bZyUkJFiBQMCyLMuaM2eOVVhYaNcvX77ciouLs/7rv/7L+tOf/mQvBw4c6K9DOKX09XwdibuQTr6+nrOmpiZrxIgRVn5+vtXY2GitX7/eSkpKsu69997+OoRTSl/P11133WWNGDHC+o//+A/ro48+sl577TXrzDPPtK6//vr+OoRTyoEDB6x33nnHeueddyxJ1sMPP2y988471scff2xZlmUVFhZac+bMset7b6NeuHChtWvXLqu0tJTbqE32+OOPW2PHjrXi4uKsCy64wHrrrbfsscsvv9zKycmxX48bN86SdNRy1113nfzGT1F9OV9HIsD0j76esy1btlhpaWmW0+m0zjjjDOu+++6zuru7T3LXp66+nK+uri5r6dKl1plnnmnFx8dbycnJ1s0332x9/vnnJ7/xU9Drr79+zM+k3nOUk5NjXX755Udtc95551lxcXHWGWecYT399NNR689hWczDAQAAs3ANDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADG+V+w/BBI4Cd+NgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "import matplotlib.pyplot as plt\n",
    "#Dictionary Comparison\n",
    "smaller_dict_features, _ = smaller_dict.shape\n",
    "larger_dict_features, _ = larger_dict.shape\n",
    "larger_dict = larger_dict.to(device)\n",
    "# Hungary algorithm\n",
    "# Calculate all cosine similarities and store in a 2D array\n",
    "cos_sims = np.zeros((smaller_dict_features, larger_dict_features))\n",
    "for idx, vector in enumerate(smaller_dict):\n",
    "    cos_sims[idx] = torch.nn.functional.cosine_similarity(vector.to(device), larger_dict, dim=1).cpu().numpy()\n",
    "# Convert to a minimization problem\n",
    "cos_sims = 1 - cos_sims\n",
    "# Use the Hungarian algorithm to solve the assignment problem\n",
    "row_ind, col_ind = linear_sum_assignment(cos_sims)\n",
    "# Retrieve the max cosine similarities and corresponding indices\n",
    "max_cosine_similarities = 1 - cos_sims[row_ind, col_ind]\n",
    "\n",
    "# Get the indices of the max cosine similarities in descending order\n",
    "max_indices = np.argsort(max_cosine_similarities)[::-1].copy()\n",
    "print((\"# of features above 0.9:\", (max_cosine_similarities > .9).sum()))\n",
    "# Plot histogram of max_cosine_similarities\n",
    "plt.hist(max_cosine_similarities, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model activations & Dictionary Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "                                                                      \r"
     ]
    }
   ],
   "source": [
    "# Downnload dataset\n",
    "from datasets import Dataset, load_dataset\n",
    "dataset_name = \"NeelNanda/pile-10k\"\n",
    "token_amount= 40\n",
    "dataset = load_dataset(dataset_name, split=\"train\").map(\n",
    "    lambda x: model.tokenizer(x['text']),\n",
    "    batched=True,\n",
    ").filter(\n",
    "    lambda x: len(x['input_ids']) > token_amount\n",
    ").map(\n",
    "    lambda x: {'input_ids': x['input_ids'][:token_amount]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [00:17<00:00,  8.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the model to get the activations\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange\n",
    "# neurons = model.W_in.shape[-1]\n",
    "neurons = model.cfg.d_model\n",
    "datapoints = dataset.num_rows\n",
    "batch_size = 64\n",
    "neuron_activations = torch.zeros((datapoints*token_amount, neurons))\n",
    "dictionary_activations = torch.zeros((datapoints*token_amount, smaller_dict_features))\n",
    "smaller_auto_encoder = smaller_auto_encoder.to(device)\n",
    "\n",
    "with torch.no_grad(), dataset.formatted_as(\"pt\"):\n",
    "    dl = DataLoader(dataset[\"input_ids\"], batch_size=batch_size)\n",
    "    for i, batch in enumerate(tqdm(dl)):\n",
    "        _, cache = model.run_with_cache(batch.to(device))\n",
    "        batched_neuron_activations = rearrange(cache[cache_name], \"b s n -> (b s) n\" )\n",
    "        neuron_activations[i*batch_size*token_amount:(i+1)*batch_size*token_amount,:] = batched_neuron_activations.cpu()\n",
    "        reconstruction, batched_dictionary_activations = smaller_auto_encoder(batched_neuron_activations)\n",
    "        dictionary_activations[i*batch_size*token_amount:(i+1)*batch_size*token_amount,:] = batched_dictionary_activations.cpu()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Activation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuitsvis.activations import text_neuron_activations\n",
    "# Get the activations for the best dict features\n",
    "def get_feature_datapoints(feature_index, dictionary_activations, dataset, k=10, setting=\"max\"):\n",
    "    best_feature_activations = dictionary_activations[:, feature_index]\n",
    "    # Sort the features by activation, get the indices\n",
    "    if setting==\"max\":\n",
    "        found_indices = torch.argsort(best_feature_activations, descending=True)[:k]\n",
    "    elif setting==\"uniform\":\n",
    "        min_value = torch.min(best_feature_activations)\n",
    "        max_value = torch.max(best_feature_activations)\n",
    "\n",
    "        # Define the number of bins\n",
    "        num_bins = k\n",
    "\n",
    "        # Calculate the bin boundaries as linear interpolation between min and max\n",
    "        bin_boundaries = torch.linspace(min_value, max_value, num_bins + 1)\n",
    "\n",
    "        # Assign each activation to its respective bin\n",
    "        bins = torch.bucketize(best_feature_activations, bin_boundaries)\n",
    "\n",
    "        # Initialize a list to store the sampled indices\n",
    "        sampled_indices = []\n",
    "\n",
    "        # Sample from each bin\n",
    "        for bin_idx in torch.unique(bins):\n",
    "            # Get the indices corresponding to the current bin\n",
    "            bin_indices = torch.nonzero(bins == bin_idx, as_tuple=False).squeeze(dim=1)\n",
    "            \n",
    "            # Randomly sample from the current bin\n",
    "            sampled_indices.extend(np.random.choice(bin_indices, size=1, replace=False))\n",
    "\n",
    "        # Convert the sampled indices to a PyTorch tensor & reverse order\n",
    "        found_indices = torch.tensor(sampled_indices).long().flip(dims=[0])\n",
    "    else: # random\n",
    "        # get nonzero indices\n",
    "        nonzero_indices = torch.nonzero(best_feature_activations)[:, 0]\n",
    "        # shuffle\n",
    "        shuffled_indices = nonzero_indices[torch.randperm(nonzero_indices.shape[0])]\n",
    "        found_indices = shuffled_indices[:k]\n",
    "    datapoint_indices =[np.unravel_index(i, (datapoints, token_amount)) for i in found_indices]\n",
    "    text_list = []\n",
    "    full_text = []\n",
    "    token_list = []\n",
    "    full_token_list = []\n",
    "    for md, s_ind in datapoint_indices:\n",
    "        md = int(md)\n",
    "        s_ind = int(s_ind)\n",
    "        full_tok = torch.tensor(dataset[md][\"input_ids\"])\n",
    "        full_text.append(model.tokenizer.decode(full_tok))\n",
    "        tok = dataset[md][\"input_ids\"][:s_ind+1]\n",
    "        text = model.tokenizer.decode(tok)\n",
    "        text_list.append(text)\n",
    "        token_list.append(tok)\n",
    "        full_token_list.append(full_tok)\n",
    "    return text_list, full_text, token_list, full_token_list\n",
    "\n",
    "def get_neuron_activation(token, feature, model, setting=\"dictionary_basis\"):\n",
    "    with torch.no_grad():\n",
    "        _, cache = model.run_with_cache(token.to(model.cfg.device))\n",
    "        neuron_act_batch = cache[cache_name]\n",
    "        if setting==\"dictionary_basis\":\n",
    "            _, act = smaller_auto_encoder(neuron_act_batch)\n",
    "            return act[0, :, feature].tolist()\n",
    "        else: # neuron/residual basis\n",
    "            return neuron_act_batch[0, :, feature].tolist()\n",
    "\n",
    "def ablate_text(text, feature, model, setting=\"plot\"):\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    display_text_list = []\n",
    "    activation_list = []\n",
    "    for t in text:\n",
    "        # Convert text into tokens\n",
    "        if isinstance(t, str): # If the text is a list of tokens\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            tokens = model.to_tokens(t, prepend_bos=False)\n",
    "        else: # t equals tokens\n",
    "            tokens = t\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "        seq_size = tokens.shape[1]\n",
    "        if(seq_size == 1): # If the text is a single token, we can't ablate it\n",
    "            continue\n",
    "        original = get_neuron_activation(tokens, feature, model)[-1]\n",
    "        changed_activations = torch.zeros(seq_size, device=device).cpu()\n",
    "        for i in range(seq_size):\n",
    "            # Remove the i'th token from the input\n",
    "            ablated_tokens = torch.cat((tokens[:,:i], tokens[:,i+1:]), dim=1)\n",
    "            changed_activations[i] += get_neuron_activation(ablated_tokens, feature, model)[-1]\n",
    "        changed_activations -= original\n",
    "        display_text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "        activation_list += changed_activations.tolist() + [0.0]\n",
    "    activation_list = torch.tensor(activation_list).reshape(-1,1,1)\n",
    "    if setting == \"plot\":\n",
    "        return text_neuron_activations(tokens=display_text_list, activations=activation_list)\n",
    "    else:\n",
    "        return display_text_list, activation_list\n",
    "def visualize_text(text, feature, model, setting=\"dictionary_basis\", max_activation = None):\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    if isinstance(feature, int):\n",
    "        feature = [feature]\n",
    "    display_text_list = []\n",
    "    act_list = []\n",
    "    for t in text:\n",
    "        if isinstance(t, str): # If the text is a list of tokens\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            token = model.to_tokens(t, prepend_bos=False)\n",
    "        else: # t are tokens\n",
    "            token = t\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "        for f in feature:\n",
    "            display_text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "            act_list += get_neuron_activation(token, f, model, setting) + [0.0]\n",
    "    act_list = torch.tensor(act_list).reshape(-1,1,1)\n",
    "    if(max_activation is not None):\n",
    "        act_list = torch.clamp(act_list, max=max_activation)\n",
    "    return text_neuron_activations(tokens=display_text_list, activations=act_list)\n",
    "# Ablate the feature direction of the tokens\n",
    "# token_list is a list of tokens, convert to tensor of shape (batch_size, seq_len)\n",
    "from einops import rearrange\n",
    "def ablate_feature_direction(tokens, feature, model, autoencoder, entire_feature_direction=False):\n",
    "    def mlp_ablation_hook(value, hook):\n",
    "        # Rearrange to fit autoencoder\n",
    "        int_val = rearrange(value, 'b s h -> (b s) h')\n",
    "\n",
    "        # Run through the autoencoder\n",
    "        _, act = autoencoder(int_val)\n",
    "        feature_to_ablate = feature # TODO: bring this out of the function\n",
    "\n",
    "        # Subtract value with feature direction*act_of_feature\n",
    "        feature_direction = torch.outer(act[:, feature_to_ablate].squeeze(), autoencoder.decoder.weight[:, feature_to_ablate].squeeze())\n",
    "        batch, seq_len, hidden_size = value.shape\n",
    "        feature_direction = rearrange(feature_direction, '(b s) h -> b s h', b=batch, s=seq_len)\n",
    "        value -= feature_direction\n",
    "        return value\n",
    "    \n",
    "    def ablated_this_feature_dir(value, hook):\n",
    "        value -= feature\n",
    "        return value\n",
    "    if(entire_feature_direction):\n",
    "        return model.run_with_hooks(tokens, \n",
    "            fwd_hooks=[(\n",
    "                cache_name, \n",
    "                ablated_this_feature_dir\n",
    "                )]\n",
    "            )\n",
    "    else:\n",
    "        return model.run_with_hooks(tokens, \n",
    "            fwd_hooks=[(\n",
    "                cache_name, \n",
    "                mlp_ablation_hook\n",
    "                )]\n",
    "            )\n",
    "\n",
    "def add_feature_direction(tokens, feature, model, autoencoder, scalar=1.0):\n",
    "    def residual_add_hook(value, hook):\n",
    "        feature_direction = autoencoder.decoder.weight[:, feature].squeeze()\n",
    "        value += scalar*feature_direction\n",
    "        return value\n",
    "\n",
    "    return model.run_with_hooks(tokens, \n",
    "        fwd_hooks=[(\n",
    "            cache_name,\n",
    "            residual_add_hook\n",
    "            )]\n",
    "        )\n",
    "def ablate_feature_direction_display(text, features=None, setting=\"true_tokens\", verbose=False, entire_feature_direction=False):\n",
    "\n",
    "    if features==None:\n",
    "        features = torch.tensor([best_feature])\n",
    "    if isinstance(features, int):\n",
    "        features = torch.tensor([features])\n",
    "    if isinstance(features, list):\n",
    "        features = torch.tensor(features)\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    text_list = []\n",
    "    logit_list = []\n",
    "    for t in text:\n",
    "        tokens = model.to_tokens(t, prepend_bos=False)\n",
    "        with torch.no_grad():\n",
    "            original_logits = model(tokens).log_softmax(-1).cpu()\n",
    "            ablated_logits = ablate_feature_direction(tokens, features, model, smaller_auto_encoder, entire_feature_direction).log_softmax(-1).cpu()\n",
    "        diff_logits = ablated_logits  - original_logits# ablated > original -> negative diff\n",
    "        tokens = tokens.cpu()\n",
    "        if setting == \"true_tokens\":\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            gather_tokens = rearrange(tokens[:,1:], \"b s -> b s 1\") # TODO: verify this is correct\n",
    "            # Gather the logits for the true tokens\n",
    "            diff = rearrange(diff_logits[:, :-1].gather(-1,gather_tokens), \"b s n -> (b s n)\")\n",
    "        elif setting == \"max\":\n",
    "            # Negate the diff_logits to see which tokens have the largest effect on the neuron\n",
    "            val, ind = (-1*diff_logits).max(-1)\n",
    "            diff = rearrange(val[:, :-1], \"b s -> (b s)\")\n",
    "            diff*= -1 # Negate the values gathered\n",
    "            split_text = model.to_str_tokens(ind, prepend_bos=False)\n",
    "            gather_tokens = rearrange(ind[:,1:], \"1 s -> 1 s 1\")\n",
    "        split_text = split_text[1:] # Remove the first token since we're not predicting it\n",
    "        if(verbose):\n",
    "            text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "            text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "            orig = rearrange(original_logits[:, :-1].gather(-1, gather_tokens), \"b s n -> (b s n)\")\n",
    "            ablated = rearrange(ablated_logits[:, :-1].gather(-1, gather_tokens), \"b s n -> (b s n)\")\n",
    "            logit_list += orig.tolist() + [0.0]\n",
    "            logit_list += ablated.tolist() + [0.0]\n",
    "        text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "        logit_list += diff.tolist() + [0.0]\n",
    "    logit_list = torch.tensor(logit_list).reshape(-1,1,1)\n",
    "    if verbose:\n",
    "        print(f\"Max & Min logit-diff: {logit_list.max().item():.2f} & {logit_list.min().item():.2f}\")\n",
    "    return text_neuron_activations(tokens=text_list, activations=logit_list)\n",
    "def generate_text(input_text, num_tokens, model, autoencoder, feature, temperature=0.7, setting=\"add\", scalar=1.0):\n",
    "    # Convert input text to tokens\n",
    "    input_ids = model.tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "\n",
    "    for _ in range(num_tokens):\n",
    "        # Generate logits\n",
    "        with torch.no_grad():\n",
    "            if(setting==\"add\"):\n",
    "                logits = add_feature_direction(input_ids, feature, model, autoencoder, scalar=scalar)\n",
    "            else:\n",
    "                logits = model(input_ids)\n",
    "\n",
    "        # Apply temperature\n",
    "        logits = logits / temperature\n",
    "\n",
    "        # Sample from the distribution\n",
    "        probs = torch.nn.functional.softmax(logits[:, -1, :], dim=-1)\n",
    "        predicted_token = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "        # Append predicted token to input_ids\n",
    "        input_ids = torch.cat((input_ids, predicted_token), dim=-1)\n",
    "\n",
    "    # Decode the tokens to text\n",
    "    output_text = model.tokenizer.decode(input_ids[0])\n",
    "\n",
    "    return output_text\n",
    "\n",
    "# Logit Lens\n",
    "def logit_lens(model, best_feature, smaller_dict, layer):\n",
    "    with torch.no_grad():\n",
    "        # There are never-used tokens, which have high norm. We want to ignore these.\n",
    "        bad_ind = (model.W_U.norm(dim=0) > 20)\n",
    "        feature_direction = smaller_dict[best_feature].to(device)\n",
    "        # feature_direction = torch.matmul(feature_direction, model.W_out[layer]) # if MLP\n",
    "        logits = torch.matmul(feature_direction, model.W_U).cpu()\n",
    "    # Don't include bad indices\n",
    "    logits[bad_ind] = -1000\n",
    "    topk_values, topk_indices = torch.topk(logits, 20)\n",
    "    top_text = model.to_str_tokens(topk_indices)\n",
    "    print(f\"{top_text}\")\n",
    "    print(topk_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Richard', ' Laura', ' Parker', ' Tim', ' Sam', ' Ross', ' Nathan', ' Matt', ' Grant', ' Kate', ' Rose', ' Brooklyn', ' Jeff', ' Jean', ' Elijah', ' Matt', ' Keith', ' Dean', ' Connor', ' Riley', ' Joy', ' Ray']\n",
      "[' Jennifer', ' Catherine', ' Jake', ' Wyatt', ' Peter', ' Jason', ' Eva', ' Evan', ' Taylor', ' Jake', ' Julia', ' Jennifer', ' Mason', ' Richard', ' Ross', ' Taylor', ' Molly', ' Parker', ' Kevin', ' Matt', ' Keith', ' Ruby']\n",
      "A_logit:  tensor([ -0.6420,  -0.5697, -20.6690,  -1.4613,  -2.1344,  -2.5653,  -1.1778,\n",
      "         -0.5647,  -0.5970,  -0.2841,  -1.7202,  -1.6440,  -0.5415,  -0.6980,\n",
      "         -0.7469,  -0.9883,  -1.0942,  -0.6697,  -1.7540,  -2.4680,  -1.0339,\n",
      "         -0.6514], device='cuda:5')\n",
      "B_logit:  tensor([ -5.5163,  -3.3293, -20.0333,  -2.4085,  -3.7961,  -4.0405,  -5.3463,\n",
      "         -4.7985,  -2.7412,  -6.1440,  -3.5804,  -3.9682,  -3.9589,  -5.2075,\n",
      "         -8.4814,  -2.6365,  -2.8979,  -4.6182,  -4.5480,  -4.2179,  -2.8910,\n",
      "         -2.6379], device='cuda:5')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6144 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6144/6144 [03:26<00:00, 29.72it/s]\n"
     ]
    }
   ],
   "source": [
    "#Ablate all directions one at a time, to see the effect of the logit on the output\n",
    "# 1. get io & s token\n",
    "# 2. get the logit of both tokens on a normal model run\n",
    "# 3. get the logit of both tokens on a model run with the direction ablated\n",
    "# 4. get the difference between the two logits, then print out topk features\n",
    "ex_sent_A = [\n",
    "    '<|endoftext|>Then, Richard and Jennifer were working at the plateau. Jennifer decided to give a feather to',\n",
    "    '<|endoftext|>Then, Laura and Catherine were working at the cafe. Catherine decided to give a towel to',\n",
    "    '<|endoftext|>Then, Parker and Jake were working at the glacier. Jake decided to give fins to',\n",
    "    '<|endoftext|>Then, Tim and Wyatt were working at the garage. Wyatt decided to give a bible to',\n",
    "    '<|endoftext|>Then, Sam and Peter were working at the chapel. Peter decided to give a remote to',\n",
    "    '<|endoftext|>Then, Ross and Jason were working at the chapel. Jason decided to give a chalk to',\n",
    "    '<|endoftext|>Then, Nathan and Eva were working at the cafe. Eva decided to give a vinyl to',\n",
    "    '<|endoftext|>Then, Matt and Evan were working at the stadium. Evan decided to give a crate to',\n",
    "]\n",
    "ex_sent_B = [\n",
    "    '<|endoftext|>Then, Taylor and Grant were working at the lounge. Taylor decided to give a shorts to',\n",
    "    '<|endoftext|>Then, Jake and Kate were working at the synagogue. Jake decided to give a backpack to',\n",
    "    '<|endoftext|>Then, Julia and Rose were working at the museum. Julia decided to give a wrench to',\n",
    "    '<|endoftext|>Then, Jennifer and Brooklyn were working at the fortress. Jennifer decided to give a tape to',\n",
    "    '<|endoftext|>Then, Mason and Jeff were working at the street. Mason decided to give a vinyl to',\n",
    "    '<|endoftext|>Then, Richard and Jean were working at the cottage. Richard decided to give a lipstick to',\n",
    "    '<|endoftext|>Then, Ross and Elijah were working at the home. Ross decided to give a flag to',\n",
    "    '<|endoftext|>Then, Taylor and Matt were working at the palace. Taylor decided to give a bookmark to',\n",
    "    '<|endoftext|>Then, Molly and Keith were working at the chapel. Molly decided to give a baseball to',\n",
    "    '<|endoftext|>Then, Parker and Dean were working at the tunnel. Parker decided to give a tablet to',\n",
    "    '<|endoftext|>Then, Kevin and Connor were working at the harbor. Kevin decided to give a bakery to',\n",
    "    '<|endoftext|>Then, Matt and Riley were working at the garden. Matt decided to give a charcoal to',\n",
    "    '<|endoftext|>Then, Keith and Joy were working at the plateau. Keith decided to give a ring to',\n",
    "    '<|endoftext|>Then, Ruby and Ray were working at the brewery. Ruby decided to give a lipstick to',\n",
    "]\n",
    "ex_sent = ex_sent_A + ex_sent_B\n",
    "all_A = []\n",
    "all_B = []\n",
    "\n",
    "for sentence in ex_sent_A:\n",
    "    # Split the sentence by 'and' and 'were' to get the names\n",
    "    names = sentence.split('and')[0].split()[-1]\n",
    "    all_A.append(\" \" + names)\n",
    "    \n",
    "    names = sentence.split('and')[1].split('were')[0].strip()\n",
    "    all_B.append(\" \" + names)\n",
    "\n",
    "for sentence in ex_sent_B:\n",
    "    # Split the sentence by 'and' and 'were' to get the names\n",
    "    names = sentence.split('and')[0].split()[-1]\n",
    "    all_B.append(\" \" + names)\n",
    "    \n",
    "    names = sentence.split('and')[1].split('were')[0].strip()\n",
    "    all_A.append(\" \" + names)\n",
    "\n",
    "\n",
    "print(all_A)\n",
    "print(all_B)\n",
    "sentence_token = model.to_tokens(ex_sent, prepend_bos=False)\n",
    "all_A_tokens = [model.to_single_token(A) for A in all_A]\n",
    "all_B_tokens = [model.to_single_token(B) for B in all_B]\n",
    "\n",
    "#2\n",
    "with torch.no_grad():\n",
    "    logits = model(sentence_token).log_softmax(-1)\n",
    "    A_logits = logits[torch.arange(len(all_A_tokens)), -1, all_A_tokens]\n",
    "    B_logits = logits[torch.arange(len(all_B_tokens)), -1, all_B_tokens]\n",
    "\n",
    "print('A_logit: ', A_logits)\n",
    "print('B_logit: ', B_logits)\n",
    "#import partial\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "#3\n",
    "def mlp_ablation_hook(value, hook, feature_to_ablate):\n",
    "    # Rearrange to fit autoencoder\n",
    "    int_val = rearrange(value, 'b s h -> (b s) h')\n",
    "\n",
    "    # Run through the autoencoder\n",
    "    _, act = smaller_auto_encoder(int_val)\n",
    "\n",
    "    # Subtract value with feature direction*act_of_feature\n",
    "    feature_direction = torch.outer(act[:, feature_to_ablate].squeeze(), smaller_auto_encoder.decoder.weight[:, feature_to_ablate].squeeze())\n",
    "    batch, seq_len, hidden_size = value.shape\n",
    "    feature_direction = rearrange(feature_direction, '(b s) h -> b s h', b=batch, s=seq_len)\n",
    "    value -= feature_direction\n",
    "    return value\n",
    "\n",
    "num_features = smaller_dict.shape[0]\n",
    "diff_A = np.zeros(num_features)\n",
    "diff_B = np.zeros(num_features)\n",
    "with torch.no_grad():\n",
    "    for feature_to_ablate in tqdm(range(num_features)):\n",
    "        ablated_logits = model.run_with_hooks(sentence_token, fwd_hooks=[(cache_name, partial(mlp_ablation_hook, feature_to_ablate=feature_to_ablate))])\n",
    "        ablated_logits = ablated_logits.log_softmax(-1)\n",
    "\n",
    "        A_ablated_logits = ablated_logits[torch.arange(len(all_A_tokens)), -1, all_A_tokens]\n",
    "        B_ablated_logits = ablated_logits[torch.arange(len(all_B_tokens)), -1, all_B_tokens]\n",
    "\n",
    "        diff_A[feature_to_ablate] = (A_logits - A_ablated_logits).mean().item()\n",
    "        diff_B[feature_to_ablate] = (B_logits - B_ablated_logits).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.5355, -0.3452, -1.0188], device='cuda:5'),\n",
       " tensor([-3.6249, -3.9121, -3.1256], device='cuda:5'))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_logits, B_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A we want lower: torch.return_types.topk(\n",
      "values=tensor([4.4833, 1.0377, 0.7852, 0.5161, 0.2330, 0.1923, 0.1923, 0.1911, 0.1763,\n",
      "        0.1647], dtype=torch.float64),\n",
      "indices=tensor([2270, 2865, 4809, 4236, 3527, 2188, 3499, 1263, 4211, 2675]))\n",
      "B we want Higher: torch.return_types.topk(\n",
      "values=tensor([4.2441, 0.6533, 0.4921, 0.4692, 0.2961, 0.1765, 0.1527, 0.1481, 0.1071,\n",
      "        0.0864], dtype=torch.float64),\n",
      "indices=tensor([2270, 1000, 4809, 2865, 4236,  612, 2769, 2188, 3806, 3499]))\n"
     ]
    }
   ],
   "source": [
    "# Topk of diff_A and diff_B\n",
    "topk = 10\n",
    "diff_A_tensor = torch.tensor(diff_A)\n",
    "diff_B_tensor = torch.tensor(diff_B)\n",
    "diff_A_topk = torch.topk(diff_A_tensor, topk)\n",
    "diff_B_topk = torch.topk(diff_B_tensor, topk)\n",
    "print(\"A we want lower:\",diff_A_topk)\n",
    "print(\"B we want Higher:\", diff_B_topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A we want lower: torch.return_types.topk(\n",
      "values=tensor([-0.1092, -0.0988, -0.0747, -0.0705, -0.0593, -0.0589, -0.0553, -0.0551,\n",
      "        -0.0361, -0.0349], dtype=torch.float64),\n",
      "indices=tensor([4786,  998, 1152, 3750, 1753, 3383, 6035, 4225, 5915, 1413]))\n",
      "B we want Higher: torch.return_types.topk(\n",
      "values=tensor([-1.6452, -0.6806, -0.4724, -0.2557, -0.2487, -0.2237, -0.1967, -0.1612,\n",
      "        -0.1597, -0.1281], dtype=torch.float64),\n",
      "indices=tensor([3527, 5112,  998, 2675, 4211, 2898, 4225, 4727, 3800, 2022]))\n"
     ]
    }
   ],
   "source": [
    "# Also do topk of diff_A_tensor, etc , largest=False\n",
    "#   612, 2769, 3806\n",
    "#   4786, 1152, 3750, 1753, 3383, 6035, 5915, 1413\n",
    "print(\"A we want lower:\",torch.topk(diff_A_tensor, 10, largest=False))\n",
    "print(\"B we want Higher:\",torch.topk(diff_B_tensor, 10, largest=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1152, 3383, 4727, 2277, 2022, 4840, 89, 3806, 1639, 2668]\n"
     ]
    }
   ],
   "source": [
    "k = 50\n",
    "diff_A_tensor = torch.tensor(diff_A)\n",
    "diff_B_tensor = torch.tensor(diff_B)\n",
    "low_A = torch.topk(diff_A_tensor, k, largest=False).indices\n",
    "high_B = torch.topk(diff_B_tensor, k).indices\n",
    "feature_list2 = []\n",
    "for l_a in low_A:\n",
    "    if(l_a in high_B):\n",
    "        # print(l_a.item())\n",
    "        feature_list2.append(l_a.item())\n",
    "print(feature_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[612, 5112, 2142, 5051, 2188, 3921, 2898, 3936, 32, 4879, 5808, 3717, 5474, 2204, 5915]\n"
     ]
    }
   ],
   "source": [
    "diff_A_tensor = torch.tensor(diff_A)\n",
    "diff_B_tensor = torch.tensor(diff_B)\n",
    "k = 50\n",
    "low_A = torch.topk(diff_A_tensor, k, largest=True).indices\n",
    "high_B = torch.topk(diff_B_tensor, k, largest=False).indices\n",
    "feature_list = []\n",
    "for l_a in low_A:\n",
    "    if(l_a in high_B):\n",
    "        feature_list.append(l_a.item())\n",
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612 -0.016431424766778946\n",
      "5112 0.07067321985960007\n",
      "2142 -0.055151037871837616\n",
      "5051 0.5127699971199036\n",
      "2188 -0.027765361592173576\n",
      "3921 0.020727992057800293\n",
      "2898 0.018309161067008972\n",
      "3936 -0.028414497151970863\n",
      "32 -0.07746785134077072\n",
      "4879 -0.08254113048315048\n",
      "5808 0.007757381070405245\n",
      "3717 0.05832681804895401\n",
      "5474 0.014952044002711773\n",
      "2204 -0.01615511253476143\n",
      "5915 0.0312351007014513\n",
      "-0.013076208531856537\n"
     ]
    }
   ],
   "source": [
    "original_feature = torch.tensor([ 2.4080e-02, 2.4359e-02, 2.5915e-03, 4.9120e-02, 1.2658e-01,\n",
    "         3.2408e-02, -2.5182e-02, 4.3675e-02, -5.4410e-02, 1.6136e-02,\n",
    "        -2.0048e-02, -2.2420e-02, 3.3210e-02, 3.4793e-02, -2.8834e-02,\n",
    "         7.4147e-02, 3.7202e-02, 5.3582e-02, 1.1046e-03, 1.2104e-02,\n",
    "         5.3141e-03, 1.5514e-02, -3.4517e-02, -1.2846e-02, -1.4674e-02,\n",
    "         8.6960e-03, -1.5789e-02, 9.3915e-04, 5.9387e-04, -6.1752e-02,\n",
    "         4.1706e-02, -6.9348e-02, 6.0245e-02, -1.5278e-02, 4.6114e-03,\n",
    "        -6.0599e-02, 4.6384e-02, 8.7855e-03, 9.8222e-02, -1.4912e-02,\n",
    "        -2.0680e-02, 8.0620e-04, 2.1009e-02, -1.8937e-02, 1.9966e-02,\n",
    "         1.8603e-02, 9.0589e-02, -5.7756e-03, -4.1959e-02, 5.0267e-03,\n",
    "         2.3697e-02, -5.8151e-02, -7.7805e-02, -4.9728e-02, -4.8614e-03,\n",
    "        -3.9631e-02, -4.0052e-02, 3.9487e-02, 6.3542e-03, 2.7683e-02,\n",
    "        -3.4077e-02, -2.9967e-02, 3.2453e-03, -8.4002e-02, -3.5077e-02,\n",
    "        -9.1061e-03, -8.3716e-04, 7.6448e-03, -7.9082e-03, 3.9118e-02,\n",
    "        -3.9306e-02, -2.0184e-02, -1.7360e-02, -9.5160e-03, 1.3632e-02,\n",
    "        -1.1137e-01, -3.2181e-02, -5.6427e-02, -2.3615e-02, 9.5962e-03,\n",
    "         5.5335e-02, -1.8662e-02, 3.4204e-02, -5.0086e-02, -7.4954e-02,\n",
    "         8.4810e-03, 5.8262e-02, 1.7019e-02, 3.1432e-03, 1.1476e-02,\n",
    "         6.3471e-03, -4.1524e-02, 1.8465e-02, 7.5723e-02, 1.5079e-02,\n",
    "         1.9857e-02, 1.1886e-02, 9.8358e-03, -5.3220e-02, 5.9651e-02,\n",
    "         2.2428e-02, 3.4533e-02, -1.7907e-02, 1.0397e-02, 4.1672e-02,\n",
    "        -1.8936e-02, 2.1871e-02, 2.5337e-03, 2.3077e-03, 3.9737e-02,\n",
    "        -3.9214e-02, 9.2625e-03, -3.8041e-02, -1.2577e-02, -3.1696e-03,\n",
    "        -2.7372e-02, -5.1618e-02, 4.4042e-02, 2.4820e-02, 2.7953e-02,\n",
    "         1.5850e-02, -1.6006e-03, 5.3238e-02, 9.8043e-03, 3.8326e-02,\n",
    "        -4.1484e-02, 3.6432e-02, 2.2653e-02, 1.8522e-02, -3.7113e-02,\n",
    "         1.7174e-02, -8.3303e-03, 2.8099e-03, 1.0931e-01, -4.4335e-02,\n",
    "         1.1882e-02, -6.4499e-03, 3.7061e-02, -9.4151e-02, -5.1065e-02,\n",
    "         2.7060e-02, -6.5621e-02, -3.0455e-02, -1.6427e-02, 3.9223e-02,\n",
    "        -3.9643e-02, 6.4269e-04, -1.2907e-03, -5.0777e-03, -5.1587e-02,\n",
    "        -3.4985e-02, 3.7856e-02, -9.9967e-02, -6.5395e-03, -4.6955e-02,\n",
    "         2.4562e-02, 1.5419e-02, -2.1492e-02, -8.9394e-03, 4.2825e-02,\n",
    "        -4.5467e-02, -1.2693e-02, -4.9931e-02, 1.9798e-03, -3.1977e-02,\n",
    "         6.7696e-03, -3.7578e-02, -3.1094e-02, -3.4964e-02, 3.0003e-02,\n",
    "         3.0392e-02, 2.8398e-02, 7.5477e-04, 2.7859e-02, 8.7245e-03,\n",
    "         1.9231e-02, -3.1447e-02, -3.8160e-02, 3.6587e-02, -1.2608e-02,\n",
    "         6.7020e-02, 9.5656e-02, 2.0806e-02, -1.0801e-02, -1.6442e-02,\n",
    "         2.9674e-02, -4.6152e-02, -6.7173e-02, 5.4613e-02, -7.5615e-03,\n",
    "        -1.2474e-05, -9.5788e-03, 6.4168e-03, 1.7756e-02, -1.0295e-02,\n",
    "        -2.1090e-02, -3.4596e-02, -1.4731e-02, 1.0119e-02, 5.8010e-03,\n",
    "        -5.4254e-03, -4.6099e-02, 6.3387e-02, -1.7798e-02, -3.1989e-02,\n",
    "        -2.7206e-02, -7.4612e-02, 3.3296e-02, 9.3995e-03, 3.7320e-02,\n",
    "        -8.7339e-02, 2.0072e-02, -3.8689e-02, -9.5642e-03, -2.8851e-03,\n",
    "         3.4954e-03, -3.7127e-03, -3.8476e-03, 1.9904e-02, -4.4326e-03,\n",
    "         2.4047e-02, 2.1409e-02, -5.3637e-04, -1.3460e-02, -2.5007e-02,\n",
    "        -3.6522e-02, -6.4226e-02, 6.0937e-03, -4.9409e-03, -5.5151e-02,\n",
    "         1.1245e-02, -5.9511e-02, 4.5356e-02, 2.3629e-02, -3.4198e-03,\n",
    "         2.6451e-02, 5.8297e-02, -1.5115e-02, 3.8943e-02, -1.3371e-02,\n",
    "        -2.6044e-02, -5.6735e-02, 6.8021e-02, -3.7823e-02, 7.3421e-02,\n",
    "        -2.4523e-02, -6.3215e-03, -8.1932e-03, 5.6012e-02, 4.7597e-04,\n",
    "        -4.0288e-02, -1.3732e-03, -3.2098e-02, -9.2334e-03, 5.5161e-03,\n",
    "         2.5030e-02, 1.5095e-02, -2.9644e-02, 5.2908e-02, -2.3363e-02,\n",
    "         5.3523e-03, 3.9384e-03, 2.1839e-02, 1.2031e-02, 2.4092e-02,\n",
    "         2.3921e-02, -7.7738e-02, -1.1835e-01, -5.1954e-02, -2.1009e-02,\n",
    "         2.5704e-02, -2.4611e-02, 3.3695e-02, 2.6925e-02, 2.6932e-02,\n",
    "         1.2319e-02, -8.9244e-02, -8.6162e-03, 3.5292e-02, -3.8614e-02,\n",
    "        -3.9250e-02, 1.6301e-02, -3.1443e-02, 1.9028e-03, 5.7968e-02,\n",
    "         3.9234e-03, -2.0115e-02, -7.6918e-03, 4.2788e-02, 3.0034e-02,\n",
    "         9.1978e-02, -5.9110e-02, 2.3647e-02, 2.0807e-02, -1.2634e-02,\n",
    "        -7.6869e-03, 4.4716e-02, -1.8892e-02, 2.7425e-02, -9.9979e-03,\n",
    "         1.9796e-02, 1.0973e-02, -1.6451e-03, -4.3213e-02, -3.5061e-03,\n",
    "         2.9969e-03, -7.1300e-02, 6.3207e-03, 8.0630e-03, -3.5077e-02,\n",
    "        -9.7324e-03, -5.2640e-02, -5.5317e-02, -2.2824e-02, 2.7998e-02,\n",
    "        -7.8537e-02, 4.3458e-02, -1.4984e-02, -7.7363e-02, 3.7290e-02,\n",
    "         7.7163e-02, -3.3954e-03, 1.3120e-02, 5.7814e-02, -1.7183e-02,\n",
    "         2.4303e-03, 3.1352e-02, 7.0760e-02, -5.9879e-03, 6.1438e-02,\n",
    "        -9.8398e-03, 1.6338e-02, 2.8400e-02, 5.7705e-02, -2.2048e-03,\n",
    "        -4.5825e-03, -1.2012e-02, -1.3619e-03, 3.8692e-02, -1.8441e-02,\n",
    "        -1.1080e-02, 3.3503e-03, 1.1516e-02, 5.0336e-02, 2.0678e-03,\n",
    "        -2.6509e-02, 4.7976e-03, -4.7704e-03, -3.4007e-02, -5.1153e-02,\n",
    "        -1.9541e-02, -1.5282e-02, -3.3280e-02, 2.1600e-02, -6.8638e-02,\n",
    "         7.2270e-03, -4.8205e-02, 6.4255e-02, -3.0913e-02, 3.3795e-02,\n",
    "         3.1021e-02, 1.7689e-02, 7.8526e-03, 4.4164e-02, -2.6782e-03,\n",
    "         2.9056e-02, 3.4432e-02, 3.8272e-02, 7.4780e-03, 5.0119e-02,\n",
    "        -1.8974e-02, -2.9729e-02, 4.4389e-02, -2.5922e-02, -6.9515e-02,\n",
    "        -6.1480e-02, -1.2153e-02, -5.7087e-02, 8.2086e-02, 3.9201e-02,\n",
    "         2.0275e-02, 8.8203e-03, -4.9722e-02, 6.9982e-02, -7.2797e-03,\n",
    "         4.0989e-02, 4.1517e-03, 8.9593e-03, 2.5157e-02, -4.8101e-03,\n",
    "        -9.6375e-03, -2.2509e-02, 5.1393e-02, 7.2553e-03, 1.3507e-02,\n",
    "         4.3849e-02, 6.2116e-02, 3.8052e-02, 1.5074e-02, 1.4775e-02,\n",
    "         2.6600e-02, 2.7580e-02, -6.2622e-03, -2.5771e-02, 1.7867e-02,\n",
    "        -1.4621e-02, 1.3103e-02, 1.5070e-02, -4.5592e-02, 6.9849e-06,\n",
    "         5.1731e-03, -2.9146e-02, -1.2707e-02, 2.8848e-02, 8.5701e-02,\n",
    "        -1.1278e-02, 2.7468e-02, -4.3419e-03, -2.8725e-02, -3.2829e-02,\n",
    "        -1.2745e-02, 3.3975e-02, -1.1140e-02, -3.2737e-02, -3.7541e-02,\n",
    "        -1.2454e-02, -1.5200e-02, -2.8173e-02, -1.0102e-01, -1.6749e-02,\n",
    "         2.8634e-02, -1.3546e-02, -1.8982e-02, 9.3449e-02, 4.1330e-02,\n",
    "        -1.3391e-02, -2.9870e-02, -1.0827e-02, -4.5005e-02, 1.5958e-02,\n",
    "        -2.7183e-03, -3.2368e-02, 5.6117e-02, -4.7420e-02, -2.1395e-02,\n",
    "        -4.4957e-02, -5.9798e-03, 2.2991e-02, 7.0553e-02, -9.5782e-03,\n",
    "         9.5198e-03, 5.8040e-03, -3.0258e-02, -5.3331e-02, 8.5738e-03,\n",
    "         5.9829e-02, 4.9407e-02, -3.9949e-02, -1.5012e-02, -5.7299e-02,\n",
    "         3.3791e-02, 2.6755e-02, 1.6138e-02, 1.5216e-02, -1.4221e-02,\n",
    "        -5.5148e-02, -6.4813e-03, -4.5133e-02, 2.5805e-02, 1.9024e-02,\n",
    "         2.3914e-03, 5.3716e-03, -5.0496e-02, -3.6670e-04, -2.6395e-02,\n",
    "         5.3805e-02, -1.9281e-02, 2.9166e-02, 1.8902e-02, 6.9283e-03,\n",
    "        -8.6916e-03, 1.3865e-01, 4.3540e-02, 7.9599e-03, -1.1489e-02,\n",
    "        -1.9561e-02, -3.3223e-02, 4.2447e-02, 2.4892e-02, 7.6215e-03,\n",
    "        -5.5037e-02, -4.0666e-03, -4.7167e-03, 3.1368e-02, 2.2559e-02,\n",
    "        -9.4491e-03, -3.7170e-02, -4.0265e-02, -2.2772e-04, -6.9743e-03,\n",
    "        -7.5886e-03, 3.6595e-02, -1.0402e-02, -3.0940e-02, -1.4825e-02,\n",
    "         1.4237e-02, 4.5008e-02, 2.5084e-02, 1.0162e-02, 2.5703e-02,\n",
    "        -1.3544e-02, -1.1389e-01, -4.0357e-02, -4.7644e-02, -3.7380e-02,\n",
    "        -1.4030e-02, 5.7597e-02, 1.7919e-04, 1.8142e-02, -1.6253e-02,\n",
    "        -7.6142e-02, 3.8851e-02, -2.1893e-02, -1.5224e-02, 2.1425e-02,\n",
    "         1.6085e-02, -2.6741e-02, -2.4140e-02, -1.4206e-02, 4.1798e-02,\n",
    "        -3.2894e-02, 4.9439e-02, -9.9219e-03, -7.2214e-02, -4.4329e-03,\n",
    "         2.9387e-02, -3.9025e-02, 1.9442e-02, 3.4890e-02, 1.3546e-02,\n",
    "         6.8964e-04, -2.7797e-02, -6.8082e-02, 9.9170e-03, 2.3642e-02,\n",
    "        -6.8385e-02, 1.0770e-02, -5.6083e-03, 1.7623e-02, -3.4506e-02,\n",
    "        -4.2243e-02, 7.4690e-02, -2.4971e-02, -5.2503e-02, -1.4595e-02,\n",
    "         5.1033e-02, 6.1160e-02, 3.7497e-03, -3.8879e-02, -4.1647e-03,\n",
    "         2.6918e-02, -1.4865e-02, 9.0000e-03, -1.4608e-02, -2.1336e-02,\n",
    "        -5.9530e-03, -1.6575e-03, -4.7094e-02, 2.3869e-02, 1.4982e-02,\n",
    "         4.9038e-02, -4.5014e-02, 4.8011e-02, -1.5510e-02, -1.6457e-02,\n",
    "         1.2145e-02, 4.9655e-03, -4.4219e-02, 2.6135e-02, 1.6504e-02,\n",
    "         3.7103e-03, 3.4081e-02, -8.6893e-03, -9.9807e-03, 1.2927e-02,\n",
    "         3.5594e-02, 2.4592e-02, 3.7850e-02, -1.1348e-02, -1.1096e-03,\n",
    "        -4.4439e-02, 2.7691e-02, -6.9026e-02, 5.7734e-02, 2.9289e-02,\n",
    "         3.4821e-02, -5.2970e-03, 3.7610e-02, -1.7178e-02, -5.0140e-02,\n",
    "        -8.3218e-02, 4.2783e-02, -1.2670e-02, 1.1850e-02, 3.1992e-02,\n",
    "        -4.4622e-04, 3.7421e-02, -2.3873e-02, -1.9229e-02, 1.4420e-02,\n",
    "         1.5459e-02, 2.4360e-02, -1.4355e-03, 3.8322e-02, -4.1234e-02,\n",
    "        -4.1331e-02, -2.9026e-02, -1.7661e-02, 5.0412e-02, -5.7450e-02,\n",
    "        -2.2180e-02, 1.4419e-02, -1.6419e-02, -2.6536e-02, -6.5096e-02,\n",
    "        -8.5083e-03, -5.8017e-03, 4.6651e-02, 3.4101e-02, -1.8907e-02,\n",
    "         2.7087e-02, 2.5500e-02, 1.1684e-03, 6.8219e-02, -3.2993e-02,\n",
    "        -2.3292e-02, 1.5120e-03, -2.1995e-02, 6.2556e-02, 4.9651e-02,\n",
    "         1.6080e-02, -1.3513e-02, 3.5774e-02, -4.4417e-02, 4.9697e-03,\n",
    "         4.9093e-02, 1.3976e-02, 2.6455e-02, 3.7071e-02, -4.3469e-02,\n",
    "         1.3540e-02, 5.2918e-02, 3.4559e-02, -3.1488e-02, -1.9801e-02,\n",
    "        -3.4259e-02, -1.0953e-02, -3.2256e-02, -3.9682e-02, 9.6360e-03,\n",
    "        -9.6176e-03, 1.2003e-03, 4.2134e-02, -5.7197e-02, -4.2081e-02,\n",
    "        -4.6472e-03, 2.6133e-02, 3.7587e-02, 9.8670e-03, -3.4046e-02,\n",
    "        -3.2811e-03, -1.5316e-02, -4.8647e-03, 1.9632e-02, 1.1838e-02,\n",
    "         1.5452e-02, -6.3881e-02, 1.2259e-02, 1.2232e-03, -4.3000e-02,\n",
    "        -6.8827e-02, 4.1810e-02, 7.1543e-03, -5.1488e-02, 2.4518e-02,\n",
    "        -1.0627e-03, 1.4221e-02, -5.3517e-02, -4.3952e-02, -3.0068e-02,\n",
    "        -1.9294e-03, -1.0837e-02, -1.0782e-02, 1.1658e-02, -7.7354e-03,\n",
    "        -9.4467e-03, 5.8047e-02, 6.2752e-03, 1.7554e-02, 5.2714e-04,\n",
    "         1.2364e-02, 4.7268e-02, -3.3143e-02, -2.9131e-02, -7.5221e-03,\n",
    "        -1.3250e-02, -1.0116e-02, 1.5731e-02, 1.2194e-03, 5.5533e-02,\n",
    "        -2.4715e-02, 3.5104e-04, 7.7462e-02, -4.2483e-02, 9.3196e-03,\n",
    "         3.5436e-04, 3.0903e-02, -6.8819e-02, 1.9523e-02, 2.2681e-04,\n",
    "        -2.1906e-02, -3.0358e-03, 1.9632e-02, 1.0104e-02, -4.5632e-03,\n",
    "         2.3078e-02, -2.9149e-02, -4.9732e-02, 1.2652e-05, 4.3399e-03,\n",
    "         3.1472e-02, 1.0199e-02, -3.4592e-04, -3.0710e-02, 8.5242e-03,\n",
    "        -6.5155e-03, -3.7067e-02, -6.3603e-03, -1.0648e-02, 4.0477e-02,\n",
    "        -1.5365e-02, 2.0180e-02, 8.3195e-03, 1.8911e-02, -3.3727e-02,\n",
    "        -3.8646e-02, -3.2142e-02, -1.6740e-02, 2.0304e-02, 3.7467e-02,\n",
    "         2.5757e-02, -9.1715e-02, 6.6637e-02, -2.6891e-02, 3.7948e-02,\n",
    "        -2.8087e-02, -1.2200e-02, 2.7008e-02, -6.5081e-03, 7.5711e-02,\n",
    "         1.4658e-02, -1.6642e-02, 4.5490e-02, 1.1131e-02, 4.4595e-02,\n",
    "        -5.6698e-02, 1.6837e-02, -7.4032e-03])\n",
    "for feat in feature_list:\n",
    "    # Calculate CS\n",
    "    feature_direction = smaller_dict[feat]\n",
    "    cs = torch.nn.functional.cosine_similarity(feature_direction, original_feature, dim=0)\n",
    "    # cs = torch.nn.functional.cosine_similarity(feature_direction, smaller_dict[feature_list[3]], dim=0)\n",
    "    print(feat, cs.item())\n",
    "# Calculate cs between two random features of size 768\n",
    "rand_dir_1 = torch.randn(768)\n",
    "rand_dir_2 = torch.randn(768)\n",
    "cs = torch.nn.functional.cosine_similarity(rand_dir_1, rand_dir_2, dim=0)\n",
    "print(cs.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_feature_2 = [-2.5726e-02, -6.4886e-04, -5.1383e-04, -2.0602e-03, -1.1533e-01,\n",
    "        -5.2642e-02,  4.8039e-03, -2.6216e-02,  6.1887e-02, -1.2594e-02,\n",
    "        -1.0364e-02,  4.2911e-02, -2.3051e-02, -8.9775e-03,  3.9231e-02,\n",
    "        -8.0026e-02, -3.2398e-02, -4.7174e-02, -2.8013e-02, -5.5694e-03,\n",
    "        -1.0717e-02,  2.3064e-02,  2.9110e-02,  1.0392e-02,  1.4949e-02,\n",
    "        -3.3139e-02,  9.7329e-03,  1.4964e-02,  9.0917e-03,  3.5896e-02,\n",
    "        -3.5559e-02,  6.7633e-02, -5.7505e-02,  1.5716e-02, -1.7437e-02,\n",
    "         5.7396e-02, -4.3503e-02, -8.4819e-03, -6.5898e-02, -7.8586e-03,\n",
    "         2.7507e-02, -2.1453e-02, -4.0811e-03,  4.9995e-03, -4.0651e-02,\n",
    "        -5.1222e-02, -4.9716e-02,  6.1054e-03,  5.4668e-02,  3.9923e-03,\n",
    "        -1.8735e-02,  7.3003e-02,  6.3771e-02,  3.6127e-02,  1.0396e-02,\n",
    "         3.5287e-02,  1.6697e-02, -3.6990e-02, -3.2620e-02, -3.7428e-02,\n",
    "         2.5951e-02,  3.2467e-02,  3.5407e-04,  5.8685e-02,  3.6463e-02,\n",
    "         7.8591e-03,  2.4923e-03,  1.2690e-02,  2.6344e-03, -3.4273e-02,\n",
    "         3.9547e-02,  2.4529e-02,  2.6538e-02, -1.8732e-02, -1.7933e-02,\n",
    "         1.1706e-01,  7.3611e-03,  5.7754e-02,  5.2099e-02, -2.1565e-02,\n",
    "        -6.3068e-02,  5.8480e-03, -4.4039e-02,  3.9488e-02,  6.8688e-02,\n",
    "        -8.3774e-04, -6.2737e-02, -2.1059e-02, -3.9884e-02, -2.7339e-02,\n",
    "         2.3889e-03,  5.1001e-02, -3.7041e-02, -7.8818e-02, -7.8122e-03,\n",
    "        -6.5944e-03, -3.0724e-02, -2.1623e-03,  4.0961e-02, -6.5949e-02,\n",
    "        -1.2377e-02, -5.4195e-02,  3.4806e-02, -5.7749e-03, -2.7602e-02,\n",
    "         2.8398e-02, -2.5806e-02, -4.9847e-03, -1.3046e-02, -5.0813e-02,\n",
    "         3.8295e-02, -1.8783e-02,  3.5261e-02,  3.0712e-03,  3.4825e-02,\n",
    "         1.5244e-02,  2.7976e-02, -4.9202e-02, -3.1048e-02, -1.2737e-02,\n",
    "        -1.4603e-02,  1.2811e-02, -5.5029e-02, -2.3307e-02, -3.5287e-02,\n",
    "         6.5566e-02, -3.1492e-02, -1.1382e-02, -1.3777e-02,  5.6112e-02,\n",
    "        -2.3837e-02, -6.7690e-05,  4.8088e-03, -1.0323e-01,  3.7318e-02,\n",
    "        -3.1996e-03, -1.9138e-02, -1.7097e-02,  6.7230e-02,  2.3842e-02,\n",
    "        -4.3859e-02,  5.9642e-02,  3.0886e-02,  1.8266e-02, -5.4966e-02,\n",
    "         4.2181e-02,  2.4301e-03,  3.7863e-03,  1.4051e-02,  4.8524e-02,\n",
    "         5.1219e-02, -2.2420e-02,  8.2472e-02,  2.1550e-02,  4.3147e-02,\n",
    "        -1.0695e-02, -1.0234e-02,  1.4201e-02,  1.5793e-02, -2.9356e-02,\n",
    "         3.2282e-02,  2.3433e-02,  4.2362e-02, -8.9699e-04,  8.8142e-03,\n",
    "        -1.1446e-02,  4.0446e-02,  1.1830e-02,  4.1430e-02, -3.8639e-02,\n",
    "        -9.0949e-03, -1.8916e-02,  1.5558e-02, -4.4642e-02, -7.8419e-03,\n",
    "        -1.9711e-02,  4.5687e-02,  1.2629e-02, -3.8284e-02,  9.4555e-03,\n",
    "        -6.1299e-02, -9.5572e-02, -1.5757e-02,  1.7990e-02,  2.5031e-02,\n",
    "        -2.9053e-02,  1.8828e-02,  4.9860e-02, -4.5340e-02, -1.4800e-02,\n",
    "         1.3446e-03, -1.2208e-02, -1.6560e-02, -4.1575e-03,  7.8791e-03,\n",
    "         2.9964e-02,  3.5376e-02,  1.0379e-02, -1.3305e-02, -6.4321e-03,\n",
    "        -8.0099e-04,  3.6716e-02, -5.0114e-02, -1.3348e-03,  2.8296e-02,\n",
    "         2.8295e-02,  8.1506e-02, -4.5367e-02, -7.9561e-03, -3.3327e-02,\n",
    "         7.6064e-02, -1.2496e-02,  1.5921e-02,  1.6194e-02,  7.7633e-03,\n",
    "         2.0605e-02,  1.5549e-02, -7.1915e-04, -2.5339e-02,  5.6805e-03,\n",
    "        -1.2525e-02, -3.3941e-02, -4.7678e-02,  1.9785e-02,  3.4760e-02,\n",
    "         4.5086e-02,  5.0492e-02, -2.0813e-02, -2.0093e-02,  7.7106e-02,\n",
    "        -1.9640e-02,  6.7751e-02, -3.7802e-02, -2.1798e-02, -1.6374e-02,\n",
    "        -3.7402e-02, -4.7581e-02,  8.5529e-03, -5.9982e-02,  1.3218e-03,\n",
    "         4.7270e-02,  4.8120e-02, -4.6423e-02,  2.8720e-02, -5.6258e-02,\n",
    "         4.2057e-02, -2.7699e-03,  2.1331e-02, -4.0283e-02, -1.4520e-02,\n",
    "         2.1053e-02, -1.0795e-03,  3.2510e-02, -4.3478e-03, -3.2881e-03,\n",
    "        -6.1366e-02,  1.5677e-02,  4.0255e-02, -7.7206e-02,  2.9707e-02,\n",
    "        -1.8393e-02,  2.1846e-03, -2.1147e-02, -3.8249e-02, -2.9695e-02,\n",
    "        -3.1903e-02,  7.6872e-02,  1.0846e-01,  5.4730e-02,  3.1813e-03,\n",
    "        -1.5633e-03,  1.9181e-03, -4.9521e-02, -1.5803e-02, -2.4915e-02,\n",
    "        -1.7885e-02,  6.0699e-02, -3.8426e-02, -5.1543e-02,  2.3449e-02,\n",
    "         5.8460e-02, -2.9590e-02,  3.2966e-02,  1.0397e-03, -2.6838e-02,\n",
    "         5.0908e-03,  4.1476e-02,  2.5819e-02, -3.9116e-02, -2.2437e-02,\n",
    "        -8.0938e-02,  6.1203e-02, -3.0964e-02, -3.0232e-02,  2.5044e-02,\n",
    "        -1.0622e-02, -3.2421e-02,  5.8003e-03, -3.1614e-02,  2.3944e-02,\n",
    "        -2.4293e-04, -3.3807e-02,  1.3699e-02,  3.4272e-02,  1.1896e-02,\n",
    "        -8.9490e-03,  8.2719e-02,  1.3622e-02,  1.6564e-03,  5.6063e-02,\n",
    "        -9.6542e-03,  4.0601e-02,  4.2192e-02,  2.7282e-02, -4.0123e-02,\n",
    "         8.1882e-02, -2.6121e-02,  2.3286e-02,  4.9314e-02, -2.8606e-03,\n",
    "        -7.4387e-02, -5.1504e-03,  6.0365e-04, -5.9640e-02,  1.2083e-02,\n",
    "        -2.4037e-02, -4.7537e-02, -8.9067e-02,  1.5172e-02, -7.0192e-02,\n",
    "         1.1639e-02, -4.6833e-03, -3.5606e-02, -2.1418e-02, -8.3400e-03,\n",
    "        -1.1812e-02,  8.8803e-04,  1.5831e-03, -3.0439e-02,  5.4649e-03,\n",
    "         6.3953e-03, -1.4518e-02, -1.8259e-03, -5.2184e-02, -2.1835e-02,\n",
    "         5.8973e-03, -8.5032e-03,  2.1707e-02,  4.8014e-02,  4.7849e-02,\n",
    "         2.3958e-03,  1.2922e-02,  4.2764e-02, -2.6646e-02,  7.2119e-02,\n",
    "        -2.0728e-02,  5.8134e-02, -5.1347e-02,  5.2139e-02, -5.4106e-02,\n",
    "        -3.1487e-02, -4.2379e-03, -1.1163e-02, -3.4577e-02,  2.0586e-02,\n",
    "         1.2625e-04, -3.5940e-02, -6.4555e-02, -4.3353e-02, -5.8778e-02,\n",
    "         1.5517e-02, -1.0910e-03, -6.6798e-02, -2.7699e-02,  7.8522e-02,\n",
    "         8.6146e-02,  7.7630e-03,  5.0124e-02, -5.7992e-02, -2.2200e-02,\n",
    "        -4.3185e-03, -2.8709e-03,  3.9246e-02, -8.1500e-02, -1.0423e-02,\n",
    "        -5.7764e-02, -5.9561e-03, -5.1224e-03, -2.0711e-02, -3.7797e-03,\n",
    "         3.2807e-03,  2.6843e-02, -3.6737e-02, -3.0800e-02, -1.0503e-02,\n",
    "        -5.3457e-02, -4.1221e-02, -3.3799e-02, -8.6349e-03, -4.7439e-03,\n",
    "        -2.4835e-02, -5.2798e-02,  9.5092e-03,  3.1724e-02, -9.0052e-03,\n",
    "         7.5382e-03,  3.8200e-03, -7.7856e-03,  2.9869e-02, -4.8750e-03,\n",
    "        -7.8292e-03,  2.3758e-02,  1.4873e-02, -9.4694e-03, -4.6604e-02,\n",
    "        -6.2212e-03, -2.0669e-02,  1.2701e-02,  1.7831e-02,  3.5741e-02,\n",
    "        -3.8615e-03, -2.3966e-02,  2.1824e-03,  2.3840e-02,  4.9500e-02,\n",
    "         1.8837e-02, -5.2920e-05,  2.6114e-02,  1.0073e-01,  1.9235e-02,\n",
    "        -1.7241e-02,  3.3887e-02,  2.9006e-02, -9.1689e-02, -3.1656e-02,\n",
    "        -1.1117e-02,  4.8628e-02,  2.7492e-02,  3.9009e-02, -3.0926e-02,\n",
    "        -4.2895e-03,  3.5016e-02, -3.9638e-02,  5.9491e-02,  8.9960e-03,\n",
    "         3.0452e-02, -1.2911e-03,  1.0351e-02, -5.9746e-02, -1.9469e-03,\n",
    "        -2.3070e-02, -4.6439e-03,  1.4491e-02,  2.8515e-02, -2.3155e-02,\n",
    "        -2.7369e-02, -4.1841e-02,  4.8859e-02, -1.4076e-02,  5.4690e-02,\n",
    "        -4.4104e-02, -2.7567e-02, -8.5394e-03,  2.0238e-02,  3.1467e-02,\n",
    "         7.9279e-02, -3.3372e-03,  3.4812e-02, -3.9662e-02, -2.3040e-02,\n",
    "        -8.3274e-03,  3.8463e-03,  6.4554e-02,  1.8813e-02,  2.2556e-02,\n",
    "        -6.8544e-02,  2.1708e-02, -4.1814e-02, -3.0375e-02, -1.5941e-02,\n",
    "         1.7288e-04, -2.9641e-02, -3.3388e-02,  2.9383e-02, -7.4426e-03,\n",
    "         1.2448e-02,  3.7900e-02, -6.3293e-02, -2.8445e-02,  4.9981e-03,\n",
    "         5.2990e-02, -1.4166e-03,  3.9616e-02, -6.4212e-03, -2.0357e-02,\n",
    "        -1.9757e-03,  5.4820e-02,  5.0063e-02,  3.7313e-03,  1.3351e-02,\n",
    "        -8.3974e-03, -4.8734e-02,  3.1723e-02,  4.3567e-02,  3.4318e-02,\n",
    "         3.6629e-04, -3.9988e-02, -1.3103e-02, -1.5312e-02, -1.7292e-02,\n",
    "         3.1800e-03,  9.6552e-02,  2.7071e-02,  6.1272e-02,  3.2394e-02,\n",
    "         1.4733e-02, -7.6506e-02, -1.1652e-02, -3.4143e-02,  8.1766e-03,\n",
    "         4.8835e-02, -1.5100e-02,  1.8776e-02,  4.3010e-02, -2.3001e-02,\n",
    "         8.3834e-03,  2.6201e-02,  3.0167e-02, -5.6585e-03, -2.6402e-02,\n",
    "         2.6883e-02, -5.3909e-02, -4.0254e-03,  6.2743e-02, -7.9913e-04,\n",
    "        -3.7325e-02,  6.0301e-02, -2.7798e-02, -3.3212e-02,  1.3380e-02,\n",
    "         8.1164e-03,  2.3546e-02,  2.8834e-02, -1.3174e-02, -2.3931e-02,\n",
    "         4.8266e-02, -8.1734e-03,  7.8013e-03, -2.5567e-02,  2.6538e-02,\n",
    "         3.7964e-02, -9.0547e-02,  3.2511e-02,  4.3442e-02,  2.7266e-02,\n",
    "        -6.2117e-02, -7.3943e-02,  3.6751e-04,  4.8327e-02,  4.1736e-02,\n",
    "        -2.4926e-02,  2.3507e-03, -2.5331e-02,  2.5488e-02,  1.6013e-02,\n",
    "         2.1877e-02, -2.1653e-02,  2.1313e-02, -1.2351e-02, -1.2053e-02,\n",
    "        -5.0269e-02,  4.3835e-02, -2.0020e-02,  2.4839e-03,  2.5738e-02,\n",
    "        -5.5224e-03, -5.8843e-03,  5.7469e-02, -1.6048e-02, -3.1025e-02,\n",
    "         2.1149e-02, -4.8876e-02, -2.8336e-02,  2.5896e-02,  6.3234e-03,\n",
    "        -3.7355e-02, -8.4070e-03, -4.3917e-02,  2.3865e-02,  7.2084e-03,\n",
    "         5.4681e-02, -1.8412e-02,  4.4411e-02, -6.0587e-02, -3.7133e-02,\n",
    "        -2.3951e-02, -9.2139e-04, -4.0388e-02,  1.4934e-02,  5.0151e-02,\n",
    "         5.7851e-02, -1.0180e-02, -6.8106e-03,  5.6417e-04, -1.7309e-02,\n",
    "        -1.0165e-03, -2.9528e-02,  4.1398e-02,  1.6000e-02, -2.4035e-02,\n",
    "        -2.0178e-04, -2.7096e-02, -1.1785e-02, -5.6973e-02,  2.4596e-02,\n",
    "         2.5844e-02,  3.5915e-02,  2.1663e-02, -5.6594e-02,  7.3724e-02,\n",
    "         2.6818e-02, -2.1379e-02,  7.2263e-04,  3.2312e-02,  5.1703e-02,\n",
    "         6.0316e-03,  1.5219e-02, -5.1856e-02, -3.6642e-02,  2.4889e-02,\n",
    "        -3.0064e-02, -1.4434e-02,  1.3706e-02, -8.8471e-02,  1.5549e-02,\n",
    "         1.0244e-02,  1.1725e-02,  2.1740e-02, -4.2962e-02, -6.0788e-02,\n",
    "        -2.9457e-02,  1.5662e-02, -1.5633e-02,  8.1673e-02, -2.5786e-03,\n",
    "        -5.7903e-02,  1.7249e-03, -5.6719e-02, -3.6636e-02,  3.4668e-02,\n",
    "        -2.4915e-02, -3.2883e-02, -3.5396e-02,  2.5812e-02,  2.2283e-02,\n",
    "         2.9422e-02,  1.9445e-02,  2.8004e-02,  5.4516e-02, -1.4896e-02,\n",
    "         2.1365e-02, -4.3958e-03, -4.8943e-02,  4.0144e-02,  3.8219e-02,\n",
    "        -7.8286e-04, -4.1919e-02, -4.6140e-02, -1.1789e-02,  1.0216e-02,\n",
    "         2.0828e-03,  2.9919e-02,  8.3159e-03, -8.5125e-03, -8.1263e-03,\n",
    "        -2.0636e-02,  6.6536e-02, -6.5788e-03, -1.0293e-02,  2.8445e-02,\n",
    "         5.2921e-02, -5.5562e-02, -1.7273e-02,  7.5576e-02, -4.2413e-02,\n",
    "         2.7888e-02, -3.1687e-02,  3.3248e-02,  6.2094e-02, -4.7034e-03,\n",
    "        -1.7305e-02,  1.5567e-02, -3.3363e-03, -1.3980e-02,  3.3695e-02,\n",
    "         1.9907e-02, -6.3426e-02, -2.1559e-02,  5.6458e-03,  1.0381e-02,\n",
    "        -1.7983e-02, -6.4998e-02,  3.9473e-02,  1.6300e-02,  1.9143e-02,\n",
    "         1.0056e-02,  3.0917e-03, -1.3239e-02,  4.7693e-03, -6.5798e-02,\n",
    "         2.6512e-02, -1.3273e-02, -6.7242e-02,  2.7019e-02,  6.2950e-03,\n",
    "        -1.7237e-02, -3.8856e-02,  6.9744e-02, -2.7839e-02, -1.1612e-02,\n",
    "         2.5963e-04, -4.9502e-03, -2.7478e-02, -2.4752e-02,  2.2492e-02,\n",
    "        -4.3067e-02,  6.9937e-03,  5.5968e-02,  2.0326e-02, -1.6968e-02,\n",
    "        -1.9992e-02, -1.0691e-02,  2.8936e-02,  4.6730e-02, -2.8219e-03,\n",
    "         1.9446e-02,  2.0802e-02,  1.2312e-02,  1.4868e-02, -4.9224e-02,\n",
    "         7.9079e-03, -2.0139e-02, -6.3683e-03, -3.9114e-03,  2.8311e-02,\n",
    "         3.4844e-02,  3.7943e-02,  8.6546e-03, -1.7897e-02, -2.7561e-02,\n",
    "        -2.7213e-02,  8.1288e-02, -4.9007e-02,  2.4349e-02, -5.4233e-02,\n",
    "         3.3028e-02, -7.7637e-03, -3.3826e-02,  1.7515e-02, -7.4451e-02,\n",
    "        -5.0871e-03,  1.7512e-02, -6.9451e-02, -1.2467e-02, -4.8812e-02,\n",
    "         7.1086e-02,  2.0196e-02,  3.5404e-03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.topk(\n",
       " values=tensor([0.5128, 0.3047, 0.2705, 0.2428, 0.1394, 0.1377, 0.1370, 0.1359, 0.1263,\n",
       "         0.1253]),\n",
       " indices=tensor([5051, 3149, 4725, 3657, 1827, 3944, 2945, 4863, 1056,  432])),\n",
       " torch.return_types.topk(\n",
       " values=tensor([-0.2296, -0.2266, -0.2089, -0.2084, -0.2083, -0.2077, -0.2044, -0.2014,\n",
       "         -0.2009, -0.1946]),\n",
       " indices=tensor([1266, 4811, 2096, 1162, 1410, 1491, 4502, 4149, 1486, 2839])))"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cs = torch.nn.functional.cosine_similarity(smaller_dict, original_feature, dim=1)\n",
    "all_cs.topk(10), all_cs.topk(10, largest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.topk(\n",
       " values=tensor([0.2111, 0.1947, 0.1907, 0.1902, 0.1855, 0.1801, 0.1789, 0.1788, 0.1761,\n",
       "         0.1753]),\n",
       " indices=tensor([4811, 1266, 1491, 1486, 4124, 4502, 2847, 4923, 1940, 2096])),\n",
       " torch.return_types.topk(\n",
       " values=tensor([-0.5040, -0.3177, -0.2426, -0.2329, -0.1698, -0.1490, -0.1450, -0.1329,\n",
       "         -0.1195, -0.1192]),\n",
       " indices=tensor([5051, 3149, 3657, 4725, 3944,  652, 3221,  320, 1827, 2945])))"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cs = torch.nn.functional.cosine_similarity(smaller_dict, torch.tensor(original_feature_2), dim=1)\n",
    "all_cs.topk(10), all_cs.topk(10, largest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([768]), torch.Size([768]))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_direction.shape, original_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2582, dtype=torch.float64), tensor(-2.3955, dtype=torch.float64))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 3527 affects the B word negatively\n",
    "diff_A_tensor[3527], diff_B_tensor[3527]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1734\n",
      "tensor(-0.2882, dtype=torch.float64) tensor(-0.1428, dtype=torch.float64)\n",
      "998\n",
      "tensor(-0.2256, dtype=torch.float64) tensor(-0.8486, dtype=torch.float64)\n",
      "6035\n",
      "tensor(-0.1720, dtype=torch.float64) tensor(0.1614, dtype=torch.float64)\n",
      "4786\n",
      "tensor(-0.1701, dtype=torch.float64) tensor(-0.2577, dtype=torch.float64)\n",
      "1152\n",
      "tensor(-0.1408, dtype=torch.float64) tensor(0.0018, dtype=torch.float64)\n",
      "3383\n",
      "tensor(-0.1214, dtype=torch.float64) tensor(0.0549, dtype=torch.float64)\n",
      "4225\n",
      "tensor(-0.1101, dtype=torch.float64) tensor(-0.2457, dtype=torch.float64)\n",
      "6102\n",
      "tensor(-0.1040, dtype=torch.float64) tensor(-0.0340, dtype=torch.float64)\n",
      "1538\n",
      "tensor(-0.1028, dtype=torch.float64) tensor(0.0544, dtype=torch.float64)\n",
      "5524\n",
      "tensor(-0.1024, dtype=torch.float64) tensor(-0.0798, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "lll = [1734,  998, 6035, 4786, 1152, 3383, 4225, 6102, 1538, 5524]\n",
    "for iii in range(10):\n",
    "    print(lll[iii])\n",
    "    print(diff_A_tensor[lll[iii]], diff_B_tensor[lll[iii]])\n",
    "# maybe 6035?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6144, 768])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = smaller_dict.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Text\n",
    "You can use the functions below to find interesting features to then add here to \"feature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:\n",
      " for a certain place.\n",
      "\n",
      "Lilmore\n",
      "\n",
      "The Lilmore is a three-mile\n",
      "Add:\n",
      " for,” LLP LLP LLP LLP LLP LLP Court,” LLPheets,” Court“ He LLP ruled His,”,’\n"
     ]
    }
   ],
   "source": [
    "sentence = \" for\"\n",
    "temp = 0.7\n",
    "tokens_to_generate = 20\n",
    "feature = 10 \n",
    "scalar = 100.0\n",
    "# Using the function:\n",
    "print(\"Normal:\\n\" + generate_text(sentence, tokens_to_generate, model, smaller_auto_encoder, feature=feature, temperature=temp, scalar=scalar, setting=\"normal\"))\n",
    "print(\"Add:\\n\" + generate_text(sentence, tokens_to_generate, model, smaller_auto_encoder, feature=feature, temperature=temp, scalar=scalar, setting=\"add\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Search\n",
    "Type in a sentence & see which features activate \n",
    "Note: Some features may be outliers, which will typically show up as high activations for the first word & first period or \\n (or high positive bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations: [4.49, 4.19, 3.51, 2.46, 2.41, 1.67, 1.27, 1.23, 1.23, 1.17]\n",
      "Feature_ids [1644, 3277, 1696, 1963, 1809, 2332, 3235, 93, 2140, 601]\n"
     ]
    }
   ],
   "source": [
    "t = \"いさんさん��に\"\n",
    "split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "token = model.to_tokens(t, prepend_bos=False)\n",
    "_, cache = model.run_with_cache(token.to(model.cfg.device))\n",
    "neuron_act_batch = cache[cache_name]\n",
    "_, act = smaller_auto_encoder(neuron_act_batch)\n",
    "v, i = act[0, -1, :].topk(10)\n",
    "\n",
    "print(\"Activations:\",[round(val,2) for val in v.tolist()])\n",
    "print(\"Feature_ids\", i.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Interp\n",
    "Investigate the example sentences the activate this feature.\n",
    "\n",
    "Max: show max activating (tokens,contexts)\n",
    "\n",
    "Uniform: Show range of activations from each bin (e.g. sample an example from 1-2, 2-3, etc). \n",
    "[Note: if a feature is monosemantic, then the full range of activations should be that feature, not just max-activating ones]\n",
    "\n",
    "Full_text: shows the full text example\n",
    "\n",
    "Text_list: shows up to the most activating example (try w/ max activating on a couple of examples to see)\n",
    "\n",
    "ablate_text: remove the context one token at a time, and show the decrease/increase in activation of that feature\n",
    "\n",
    "ablate_feature_direction: removes feature direction from model's activation mid-inference, showing the logit diff in the output for every token.\n",
    "\n",
    "logit_lens: show the logit lens for that feature. If matches ablate_feature_direction, then the computation path is through the residual stream, else, it's through future layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias: -5.620166\n",
      "Feature index: 3383\n",
      "MCS: 0.9939594268798828\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-5443c72b-bd7c\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-5443c72b-bd7c\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"\\\"\", \"Val\", \"encia\", \",\", \" CA\", \" 2\", \":\", \"43\", \" am\", \"\\\"\", \" \\\"\", \"Yeah\", \".\\\"\", \" \\\"\", \"Sh\", \"it\", \".\\\"\", \" \\\"\", \"Where\", \" is\", \" he\", \"?\\\"\", \" \\\"\", \"G\", \"otta\", \" go\", \".\\\"\", \" \\\"\", \"What\", \"'s\", \" the\", \" latest\", \"?\\\"\", \" \\\"\", \" Nothing\", \".\\\"\", \" \\\"\", \"They\", \" say\", \" the\", \"\\n\", \"\\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Yeah\", \".\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Hey\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Come\", \" here\", \".\\\"\", \" \\\"\", \"What\", \"'s\", \" up\", \"?\\\"\", \" \\\"\", \"Hey\", \"\\n\", \"\\\"\", \"So\", \" you\", \" got\", \" everything\", \"?\\\"\", \" \\\"\", \"You\", \" gonna\", \" play\", \" video\", \" games\", \" the\", \" whole\", \" flight\", \" or\", \" do\", \" you\", \" think\", \" you\", \" might\", \" actually\", \" crack\", \" a\", \" book\", \"?\\\"\", \" \\\"\", \"Probably\", \" read\", \" some\", \".\\\"\", \" \\\"\", \"Well\", \",\", \" if\", \" I\", \" write\", \" you\", \" an\", \" email\", \"\\n\", \"\\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Yeah\", \".\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Hey\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Come\", \" here\", \".\\\"\", \" \\\"\", \"What\", \"'s\", \" up\", \"?\\\"\", \" \\\"\", \"Hey\", \"\\n\", \"\\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Yeah\", \".\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Hey\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Come\", \" here\", \".\\\"\", \" \\\"\", \"What\", \"'s\", \" up\", \"?\\\"\", \" \\\"\", \"Hey\", \"\\n\", \"\\\"\", \"Previously\", \" on\", \" \\\"\", \"The\", \" L\", \" Word\", \"\\\"\\\"\", \" \\\"\", \"I\", \" don\", \"'t\", \" wanna\", \" break\", \" up\", \" with\", \" you\", \".\\\"\", \" \\\"\", \"You\", \" think\", \" we\", \" should\", \" go\", \" to\", \" therapy\", \"?\\\"\", \" \\\"\", \"Ther\", \"apy\", \"'s\", \" for\", \" people\", \" with\", \" problems\", \".\\\"\", \" \\\"\", \"Tell\", \" me\", \" you\", \"\\n\", \"\\\"\", \"Val\", \"encia\", \",\", \" CA\", \" 2\", \":\", \"43\", \" am\", \"\\\"\", \" \\\"\", \"Yeah\", \".\\\"\", \" \\\"\", \"Sh\", \"it\", \".\\\"\", \" \\\"\", \"Where\", \" is\", \" he\", \"?\\\"\", \" \\\"\", \"G\", \"otta\", \" go\", \".\\\"\", \" \\\"\", \"What\", \"'s\", \" the\", \" latest\", \"?\\\"\", \" \\\"\", \" Nothing\", \".\\\"\", \" \\\"\", \"They\", \" say\", \" the\", \"\\n\", \"\\\"\", \"Val\", \"encia\", \",\", \" CA\", \" 2\", \":\", \"43\", \" am\", \"\\\"\", \" \\\"\", \"Yeah\", \".\\\"\", \" \\\"\", \"Sh\", \"it\", \".\\\"\", \" \\\"\", \"Where\", \" is\", \" he\", \"?\\\"\", \" \\\"\", \"G\", \"otta\", \" go\", \".\\\"\", \" \\\"\", \"What\", \"'s\", \" the\", \" latest\", \"?\\\"\", \" \\\"\", \" Nothing\", \".\\\"\", \" \\\"\", \"They\", \" say\", \" the\", \"\\n\", \"\\\"\", \"Red\", \" Rover\", \",\", \" Red\", \" Rover\", \" Send\", \" to\", \" Emily\", \" now\", \"!\\\"\", \" \\\"\", \"Emily\", \" Come\", \" on\", \"!\\\"\", \" \\\"\", \"Who\", \" will\", \" be\", \" next\", \"?\\\"\", \" \\\"\", \"Well\", \" Bobby\", \" Tr\", \"icker\", \"\\\"\", \" \\\"\", \"As\", \"co\", \"!\\\"\", \" \\\"\", \"He\", \" scratches\", \" his\", \" nose\", \",\", \" and\", \" eats\", \"\\n\", \"\\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Yeah\", \".\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Hey\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Come\", \" here\", \".\\\"\", \" \\\"\", \"What\", \"'s\", \" up\", \"?\\\"\", \" \\\"\", \"Hey\", \"\\n\"], \"activations\": [[[0.0]], [[0.0]], [[1.1645774841308594]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[14.500540733337402]], [[0.0]], [[0.0]], [[4.192971229553223]], [[23.90380096435547]], [[0.0]], [[2.036372661590576]], [[24.82573699951172]], [[28.209915161132812]], [[22.850292205810547]], [[1.8019976615905762]], [[8.336494445800781]], [[7.68673038482666]], [[28.094207763671875]], [[35.11781692504883]], [[0.0]], [[8.283520698547363]], [[30.644859313964844]], [[26.77908706665039]], [[27.57721710205078]], [[18.01260757446289]], [[0.0]], [[12.753315925598145]], [[16.78799057006836]], [[0.0]], [[8.546957015991211]], [[30.77853012084961]], [[25.483585357666016]], [[17.56454086303711]], [[0.0]], [[0.0]], [[7.044798851013184]], [[15.457287788391113]], [[20.24761199951172]], [[0.43183040618896484]], [[4.9094743728637695]], [[5.888941764831543]], [[11.469359397888184]], [[0.0]], [[7.330780029296875]], [[24.156475067138672]], [[28.980567932128906]], [[23.645103454589844]], [[1.1164169311523438]], [[2.669978141784668]], [[20.442893981933594]], [[0.0]], [[6.4314069747924805]], [[8.719366073608398]], [[24.155750274658203]], [[0.0]], [[2.469304084777832]], [[31.443771362304688]], [[0.0]], [[9.545552253723145]], [[25.773605346679688]], [[28.32177734375]], [[23.105602264404297]], [[0.0]], [[0.0]], [[29.042861938476562]], [[31.392356872558594]], [[0.0]], [[6.360054969787598]], [[32.81212615966797]], [[29.581066131591797]], [[30.25518035888672]], [[0.0]], [[15.291901588439941]], [[21.75119400024414]], [[0.0]], [[0.0]], [[8.79548168182373]], [[11.877917289733887]], [[16.647377014160156]], [[12.153454780578613]], [[0.0]], [[3.7035160064697266]], [[25.293071746826172]], [[32.11552810668945]], [[28.088397979736328]], [[8.909188270568848]], [[18.779438018798828]], [[13.569558143615723]], [[19.11687469482422]], [[12.124053001403809]], [[23.773956298828125]], [[26.414897918701172]], [[23.352474212646484]], [[24.701854705810547]], [[17.752662658691406]], [[18.501033782958984]], [[16.310382843017578]], [[15.173018455505371]], [[12.230921745300293]], [[7.120535850524902]], [[0.0]], [[8.566544532775879]], [[22.926189422607422]], [[13.607476234436035]], [[11.559226036071777]], [[0.0]], [[8.4705810546875]], [[24.749820709228516]], [[22.2515869140625]], [[24.099742889404297]], [[20.542640686035156]], [[19.56853485107422]], [[18.493682861328125]], [[12.589524269104004]], [[11.358160972595215]], [[0.0]], [[0.0]], [[7.044798851013184]], [[15.457287788391113]], [[20.24761199951172]], [[0.43183040618896484]], [[4.9094743728637695]], [[5.888941764831543]], [[11.469359397888184]], [[0.0]], [[7.330780029296875]], [[24.156475067138672]], [[28.980567932128906]], [[23.645103454589844]], [[1.1164169311523438]], [[2.669978141784668]], [[20.442893981933594]], [[0.0]], [[6.4314069747924805]], [[8.719366073608398]], [[24.155750274658203]], [[0.0]], [[2.469304084777832]], [[31.443771362304688]], [[0.0]], [[9.545552253723145]], [[25.773605346679688]], [[28.32177734375]], [[23.105602264404297]], [[0.0]], [[0.0]], [[29.042861938476562]], [[31.392356872558594]], [[0.0]], [[6.360054969787598]], [[32.81212615966797]], [[29.581066131591797]], [[30.25518035888672]], [[0.0]], [[15.291901588439941]], [[21.75119400024414]], [[0.0]], [[0.0]], [[7.044798851013184]], [[15.457287788391113]], [[20.24761199951172]], [[0.43183040618896484]], [[4.9094743728637695]], [[5.888941764831543]], [[11.469359397888184]], [[0.0]], [[7.330780029296875]], [[24.156475067138672]], [[28.980567932128906]], [[23.645103454589844]], [[1.1164169311523438]], [[2.669978141784668]], [[20.442893981933594]], [[0.0]], [[6.4314069747924805]], [[8.719366073608398]], [[24.155750274658203]], [[0.0]], [[2.469304084777832]], [[31.443771362304688]], [[0.0]], [[9.545552253723145]], [[25.773605346679688]], [[28.32177734375]], [[23.105602264404297]], [[0.0]], [[0.0]], [[29.042861938476562]], [[31.392356872558594]], [[0.0]], [[6.360054969787598]], [[32.81212615966797]], [[29.581066131591797]], [[30.25518035888672]], [[0.0]], [[15.291901588439941]], [[21.75119400024414]], [[0.0]], [[0.0]], [[1.0573163032531738]], [[0.0]], [[0.0]], [[1.839451789855957]], [[0.0]], [[3.02728271484375]], [[0.0]], [[0.0]], [[6.417210578918457]], [[11.453316688537598]], [[14.231968879699707]], [[19.140094757080078]], [[18.004871368408203]], [[17.761436462402344]], [[20.754920959472656]], [[20.7679443359375]], [[0.0]], [[0.0]], [[26.573314666748047]], [[31.136234283447266]], [[22.245166778564453]], [[23.53009033203125]], [[23.13845443725586]], [[20.76773452758789]], [[16.918701171875]], [[1.1838769912719727]], [[8.444361686706543]], [[3.8756818771362305]], [[23.504764556884766]], [[17.467079162597656]], [[18.303627014160156]], [[15.0585355758667]], [[9.75027084350586]], [[11.290862083435059]], [[0.0]], [[6.398636817932129]], [[28.823997497558594]], [[22.254135131835938]], [[20.318077087402344]], [[0.0]], [[0.0]], [[0.0]], [[1.1645774841308594]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[14.500540733337402]], [[0.0]], [[0.0]], [[4.192971229553223]], [[23.90380096435547]], [[0.0]], [[2.036372661590576]], [[24.82573699951172]], [[28.209915161132812]], [[22.850292205810547]], [[1.8019976615905762]], [[8.336494445800781]], [[7.68673038482666]], [[28.094207763671875]], [[35.11781692504883]], [[0.0]], [[8.283520698547363]], [[30.644859313964844]], [[26.77908706665039]], [[27.57721710205078]], [[18.01260757446289]], [[0.0]], [[12.753315925598145]], [[16.78799057006836]], [[0.0]], [[8.546957015991211]], [[30.77853012084961]], [[25.483585357666016]], [[17.56454086303711]], [[0.0]], [[0.0]], [[0.0]], [[1.1645774841308594]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[14.500540733337402]], [[0.0]], [[0.0]], [[4.192971229553223]], [[23.90380096435547]], [[0.0]], [[2.036372661590576]], [[24.82573699951172]], [[28.209915161132812]], [[22.850292205810547]], [[1.8019976615905762]], [[8.336494445800781]], [[7.68673038482666]], [[28.094207763671875]], [[35.11781692504883]], [[0.0]], [[8.283520698547363]], [[30.644859313964844]], [[26.77908706665039]], [[27.57721710205078]], [[18.01260757446289]], [[0.0]], [[12.753315925598145]], [[16.78799057006836]], [[0.0]], [[8.546957015991211]], [[30.77853012084961]], [[25.483585357666016]], [[17.56454086303711]], [[0.0]], [[0.0]], [[0.33344411849975586]], [[2.8512725830078125]], [[0.4926152229309082]], [[0.760777473449707]], [[3.649998664855957]], [[2.3521032333374023]], [[5.475892066955566]], [[1.1133956909179688]], [[6.494330406188965]], [[0.0]], [[2.273651599884033]], [[13.598343849182129]], [[22.63726043701172]], [[30.37067413330078]], [[0.0]], [[4.06089973449707]], [[23.834304809570312]], [[23.001556396484375]], [[18.047943115234375]], [[15.792534828186035]], [[0.0]], [[4.996392250061035]], [[16.89590835571289]], [[11.4268217086792]], [[0.0]], [[14.392205238342285]], [[0.0]], [[4.365714073181152]], [[16.773967742919922]], [[4.064383506774902]], [[0.0]], [[2.1326379776000977]], [[15.629258155822754]], [[13.059319496154785]], [[1.2708210945129395]], [[5.763190269470215]], [[6.060302734375]], [[10.73987102508545]], [[10.595520973205566]], [[0.0]], [[0.0]], [[7.044798851013184]], [[15.457287788391113]], [[20.24761199951172]], [[0.43183040618896484]], [[4.9094743728637695]], [[5.888941764831543]], [[11.469359397888184]], [[0.0]], [[7.330780029296875]], [[24.156475067138672]], [[28.980567932128906]], [[23.645103454589844]], [[1.1164169311523438]], [[2.669978141784668]], [[20.442893981933594]], [[0.0]], [[6.4314069747924805]], [[8.719366073608398]], [[24.155750274658203]], [[0.0]], [[2.469304084777832]], [[31.443771362304688]], [[0.0]], [[9.545552253723145]], [[25.773605346679688]], [[28.32177734375]], [[23.105602264404297]], [[0.0]], [[0.0]], [[29.042861938476562]], [[31.392356872558594]], [[0.0]], [[6.360054969787598]], [[32.81212615966797]], [[29.581066131591797]], [[30.25518035888672]], [[0.0]], [[15.291901588439941]], [[21.75119400024414]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fc7b559e170>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l1 = 8e-4, first 8 features don't make sense\n",
    "# 1-3k mostly makes sense. Degrades after 3k (.6 MCS)\n",
    "# 1505, Japanese words\n",
    "\n",
    "# l1 = 4e-4. Loads of single letter features, unsure how legit they are\n",
    "# 127 - induction thing\n",
    "# 1001 - Japanese language, predicts common japanese endings & grammar (their comma char & quotations)\n",
    "# 1012 ? maybe poly, maybe context neuron\n",
    "# 1500: num after +/-\n",
    "# 1501: food-related\n",
    "# 1505 Poly\n",
    "# 2506 Poly\n",
    "# l1 = 2e-4. Definitely some real features, but many many polysemantic ones\n",
    "N = 3004\n",
    "best_feature = int(max_indices[N])\n",
    "# Feature_ids [1644, 3277, 1696, 1963, 1809, 2332, 3235, 93, 2140, 601]\n",
    "ind_for_feature=0\n",
    "indices=[2270, 1000, 4809, 2865, 4236,  612, 2769, 2188, 3806, 3499]\n",
    "# indices=[4786,  998, 1152, 3750, 1753, 3383, 6035, 4225, 5915, 1413]\n",
    "best_feature = 3383\n",
    "\n",
    "# 3383\n",
    "# 6035\n",
    "# 1413\n",
    "# 4466\n",
    "# 3806\n",
    "# 3667\n",
    "# 5455\n",
    "# 4290\n",
    "# 5164\n",
    "# 795\n",
    "# 5380\n",
    "# 3001\n",
    "print(\"bias:\", smaller_auto_encoder.encoder_bias.detach().cpu().numpy()[best_feature])\n",
    "print(f\"Feature index: {best_feature}\")\n",
    "print(f\"MCS: {max_cosine_similarities[best_feature]}\")\n",
    "# text_list, full_text, token_list, full_token_list = get_feature_datapoints(best_feature, dictionary_activations, dataset, setting=\"uniform\")\n",
    "text_list, full_text, token_list, full_token_list = get_feature_datapoints(best_feature, dictionary_activations, dataset, setting=\"max\")\n",
    "visualize_text(full_text, best_feature, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-d96e2799-cc78\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-d96e2799-cc78\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [], \"activations\": [], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fc7ad0ab970>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_text(text_list, best_feature, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Richard',\n",
       " ' Laura',\n",
       " ' Parker',\n",
       " ' Tim',\n",
       " ' Sam',\n",
       " ' Ross',\n",
       " ' Nathan',\n",
       " ' Matt',\n",
       " ' Grant',\n",
       " ' Kate',\n",
       " ' Rose',\n",
       " ' Brooklyn',\n",
       " ' Jeff',\n",
       " ' Jean',\n",
       " ' Elijah',\n",
       " ' Matt',\n",
       " ' Keith',\n",
       " ' Dean',\n",
       " ' Connor',\n",
       " ' Riley',\n",
       " ' Joy',\n",
       " ' Ray']"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>Then, Richard and Jennifer were working at the plateau. Jennifer decided to give a feather to Richard',\n",
       " '<|endoftext|>Then, Laura and Catherine were working at the cafe. Catherine decided to give a towel to Laura',\n",
       " '<|endoftext|>Then, Parker and Jake were working at the glacier. Jake decided to give fins to Parker',\n",
       " '<|endoftext|>Then, Tim and Wyatt were working at the garage. Wyatt decided to give a bible to Tim',\n",
       " '<|endoftext|>Then, Sam and Peter were working at the chapel. Peter decided to give a remote to Sam',\n",
       " '<|endoftext|>Then, Ross and Jason were working at the chapel. Jason decided to give a chalk to Ross',\n",
       " '<|endoftext|>Then, Nathan and Eva were working at the cafe. Eva decided to give a vinyl to Nathan',\n",
       " '<|endoftext|>Then, Matt and Evan were working at the stadium. Evan decided to give a crate to Matt',\n",
       " '<|endoftext|>Then, Taylor and Grant were working at the lounge. Taylor decided to give a shorts to Taylor',\n",
       " '<|endoftext|>Then, Jake and Kate were working at the synagogue. Jake decided to give a backpack to Jake',\n",
       " '<|endoftext|>Then, Julia and Rose were working at the museum. Julia decided to give a wrench to Julia',\n",
       " '<|endoftext|>Then, Jennifer and Brooklyn were working at the fortress. Jennifer decided to give a tape to Jennifer',\n",
       " '<|endoftext|>Then, Mason and Jeff were working at the street. Mason decided to give a vinyl to Mason',\n",
       " '<|endoftext|>Then, Richard and Jean were working at the cottage. Richard decided to give a lipstick to Richard',\n",
       " '<|endoftext|>Then, Ross and Elijah were working at the home. Ross decided to give a flag to Ross',\n",
       " '<|endoftext|>Then, Taylor and Matt were working at the palace. Taylor decided to give a bookmark to Taylor',\n",
       " '<|endoftext|>Then, Molly and Keith were working at the chapel. Molly decided to give a baseball to Molly',\n",
       " '<|endoftext|>Then, Parker and Dean were working at the tunnel. Parker decided to give a tablet to Parker',\n",
       " '<|endoftext|>Then, Kevin and Connor were working at the harbor. Kevin decided to give a bakery to Kevin',\n",
       " '<|endoftext|>Then, Matt and Riley were working at the garden. Matt decided to give a charcoal to Matt',\n",
       " '<|endoftext|>Then, Keith and Joy were working at the plateau. Keith decided to give a ring to Keith',\n",
       " '<|endoftext|>Then, Ruby and Ray were working at the brewery. Ruby decided to give a lipstick to Ruby']"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_sent_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5112\n",
      "tensor(-0.0709)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-cf45ec28-0e26\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-cf45ec28-0e26\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \"Then\", \",\", \" Richard\", \" and\", \" Jennifer\", \" were\", \" working\", \" at\", \" the\", \" plateau\", \".\", \" Jennifer\", \" decided\", \" to\", \" give\", \" a\", \" feather\", \" to\", \" Richard\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Laura\", \" and\", \" Catherine\", \" were\", \" working\", \" at\", \" the\", \" cafe\", \".\", \" Catherine\", \" decided\", \" to\", \" give\", \" a\", \" towel\", \" to\", \" Laura\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Parker\", \" and\", \" Jake\", \" were\", \" working\", \" at\", \" the\", \" glacier\", \".\", \" Jake\", \" decided\", \" to\", \" give\", \" fins\", \" to\", \" Parker\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Tim\", \" and\", \" Wyatt\", \" were\", \" working\", \" at\", \" the\", \" garage\", \".\", \" Wyatt\", \" decided\", \" to\", \" give\", \" a\", \" bible\", \" to\", \" Tim\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Sam\", \" and\", \" Peter\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Peter\", \" decided\", \" to\", \" give\", \" a\", \" remote\", \" to\", \" Sam\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Ross\", \" and\", \" Jason\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Jason\", \" decided\", \" to\", \" give\", \" a\", \" chalk\", \" to\", \" Ross\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Nathan\", \" and\", \" Eva\", \" were\", \" working\", \" at\", \" the\", \" cafe\", \".\", \" Eva\", \" decided\", \" to\", \" give\", \" a\", \" vinyl\", \" to\", \" Nathan\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Matt\", \" and\", \" Evan\", \" were\", \" working\", \" at\", \" the\", \" stadium\", \".\", \" Evan\", \" decided\", \" to\", \" give\", \" a\", \" crate\", \" to\", \" Matt\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Taylor\", \" and\", \" Grant\", \" were\", \" working\", \" at\", \" the\", \" lounge\", \".\", \" Taylor\", \" decided\", \" to\", \" give\", \" a\", \" shorts\", \" to\", \" Grant\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Jake\", \" and\", \" Kate\", \" were\", \" working\", \" at\", \" the\", \" synagogue\", \".\", \" Jake\", \" decided\", \" to\", \" give\", \" a\", \" backpack\", \" to\", \" Kate\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Julia\", \" and\", \" Rose\", \" were\", \" working\", \" at\", \" the\", \" museum\", \".\", \" Julia\", \" decided\", \" to\", \" give\", \" a\", \" wrench\", \" to\", \" Rose\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Jennifer\", \" and\", \" Brooklyn\", \" were\", \" working\", \" at\", \" the\", \" fortress\", \".\", \" Jennifer\", \" decided\", \" to\", \" give\", \" a\", \" tape\", \" to\", \" Brooklyn\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Mason\", \" and\", \" Jeff\", \" were\", \" working\", \" at\", \" the\", \" street\", \".\", \" Mason\", \" decided\", \" to\", \" give\", \" a\", \" vinyl\", \" to\", \" Jeff\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Richard\", \" and\", \" Jean\", \" were\", \" working\", \" at\", \" the\", \" cottage\", \".\", \" Richard\", \" decided\", \" to\", \" give\", \" a\", \" lipstick\", \" to\", \" Jean\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Ross\", \" and\", \" Elijah\", \" were\", \" working\", \" at\", \" the\", \" home\", \".\", \" Ross\", \" decided\", \" to\", \" give\", \" a\", \" flag\", \" to\", \" Elijah\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Taylor\", \" and\", \" Matt\", \" were\", \" working\", \" at\", \" the\", \" palace\", \".\", \" Taylor\", \" decided\", \" to\", \" give\", \" a\", \" bookmark\", \" to\", \" Matt\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Molly\", \" and\", \" Keith\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Molly\", \" decided\", \" to\", \" give\", \" a\", \" baseball\", \" to\", \" Keith\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Parker\", \" and\", \" Dean\", \" were\", \" working\", \" at\", \" the\", \" tunnel\", \".\", \" Parker\", \" decided\", \" to\", \" give\", \" a\", \" tablet\", \" to\", \" Dean\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Kevin\", \" and\", \" Connor\", \" were\", \" working\", \" at\", \" the\", \" harbor\", \".\", \" Kevin\", \" decided\", \" to\", \" give\", \" a\", \" bakery\", \" to\", \" Connor\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Matt\", \" and\", \" Riley\", \" were\", \" working\", \" at\", \" the\", \" garden\", \".\", \" Matt\", \" decided\", \" to\", \" give\", \" a\", \" charcoal\", \" to\", \" Riley\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Keith\", \" and\", \" Joy\", \" were\", \" working\", \" at\", \" the\", \" plateau\", \".\", \" Keith\", \" decided\", \" to\", \" give\", \" a\", \" ring\", \" to\", \" Joy\", \"\\n\", \"<|endoftext|>\", \"Then\", \",\", \" Ruby\", \" and\", \" Ray\", \" were\", \" working\", \" at\", \" the\", \" brewery\", \".\", \" Ruby\", \" decided\", \" to\", \" give\", \" a\", \" lipstick\", \" to\", \" Ray\", \"\\n\"], \"activations\": [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[23.08037567138672]], [[6.269387245178223]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[22.05998992919922]], [[7.52291202545166]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[17.61972427368164]], [[9.101611137390137]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[20.06482696533203]], [[5.886294364929199]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[21.873497009277344]], [[5.489073753356934]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[20.894088745117188]], [[6.477961540222168]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[26.260547637939453]], [[8.12393856048584]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[24.352096557617188]], [[5.1369428634643555]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[21.886837005615234]], [[7.237627983093262]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[24.24944305419922]], [[5.889483451843262]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[24.61479949951172]], [[7.727391242980957]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[21.386463165283203]], [[8.243990898132324]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[17.669536590576172]], [[8.533425331115723]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[22.09100341796875]], [[6.307772636413574]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[21.74200439453125]], [[7.570742607116699]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[20.75055694580078]], [[7.477435111999512]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[25.010601043701172]], [[8.562262535095215]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[19.189678192138672]], [[7.006094932556152]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[24.79500961303711]], [[5.520020484924316]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[22.256126403808594]], [[5.1272993087768555]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[16.37078857421875]], [[6.707106590270996]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[19.353351593017578]], [[11.184046745300293]], [[0.31817626953125]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fc7b24ae7d0>"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ex_sent_combined = [\n",
    "#     '<|endoftext|>Then, Richard and Jennifer were working at the plateau. Jennifer decided to give a feather to Richard',\n",
    "#     '<|endoftext|>Then, Laura and Catherine were working at the cafe. Catherine decided to give a towel to Laura',\n",
    "#     '<|endoftext|>Then, Parker and Jake were working at the glacier. Jake decided to give fins to Parker',\n",
    "#     '<|endoftext|>Then, Jennifer and Richard were working at the plateau. Richard decided to give a feather to Jennifer',\n",
    "#     '<|endoftext|>Then, Catherine and Laura were working at the cafe. Laura decided to give a towel to Catherine',\n",
    "#     '<|endoftext|>Then, Jake and Parker were working at the glacier. Parker decided to give fins to Jake'\n",
    "# ]\n",
    "\n",
    "# 3383\n",
    "# 6035\n",
    "# 1413\n",
    "# 4466\n",
    "# 3806\n",
    "# 3667\n",
    "# 5455\n",
    "# 4290\n",
    "# 5164\n",
    "# 795\n",
    "# 5380\n",
    "# 3001\",\n",
    "# New ones\n",
    "features_ind_found = [\n",
    "    3527,\n",
    "    4211,\n",
    "    2675,\n",
    "    4006,\n",
    "    5189,\n",
    "    4478,\n",
    "    4977,\n",
    "    852,\n",
    "    2898,\n",
    "    5112,\n",
    "    4879,\n",
    "    3971,\n",
    "    4261,\n",
    "    1746,\n",
    "    4647,\n",
    "    2022,\n",
    "    3160,\n",
    "    32,\n",
    "    3657,\n",
    "    3173\n",
    "]\n",
    "ex_sent_combined = [ex_s + a_word for ex_s, a_word in zip(ex_sent, all_A)] \n",
    "wrong_sentences = [ex_s + b_word for ex_s, b_word in zip(ex_sent, all_B)] \n",
    "# feature_list\n",
    "# 1 is okay-ish\n",
    "# 3 is just after 'and'\n",
    "# 4 is a mixed bag, but activates for names\n",
    "# 5 mixed bag, but worse\n",
    "# 6 is mixed\n",
    "# 7 ???\n",
    "selector = 1\n",
    "best_feature = feature_list[selector]\n",
    "print(feature_list[selector])\n",
    "print(torch.nn.functional.cosine_similarity(smaller_dict[best_feature], torch.tensor(original_feature_2), dim=0))\n",
    "# best_feature = feature_list2[selector]\n",
    "# best_feature = 3657 # & selector 0\n",
    "# selector = 8\n",
    "# cs_features = [5051, 3149, 4725, 3657, 1827, 3944, 2945, 4863, 1056,  432]\n",
    "# cs_features =  [4811, 1266, 1491, 1486, 4124, 4502, 2847, 4923, 1940, 2096]\n",
    "# best_feature = cs_features[selector]\n",
    "visualize_text(ex_sent_combined, best_feature, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-7630d1c9-a02d\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-7630d1c9-a02d\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"Then\", \",\", \" Richard\", \" and\", \" Jennifer\", \" were\", \" working\", \" at\", \" the\", \" plateau\", \".\", \" Jennifer\", \" decided\", \" to\", \" give\", \" a\", \" feather\", \" to\", \" Richard\", \"\\n\", \"Then\", \",\", \" Laura\", \" and\", \" Catherine\", \" were\", \" working\", \" at\", \" the\", \" cafe\", \".\", \" Catherine\", \" decided\", \" to\", \" give\", \" a\", \" towel\", \" to\", \" Laura\", \"\\n\", \"Then\", \",\", \" Parker\", \" and\", \" Jake\", \" were\", \" working\", \" at\", \" the\", \" glacier\", \".\", \" Jake\", \" decided\", \" to\", \" give\", \" fins\", \" to\", \" Parker\", \"\\n\", \"Then\", \",\", \" Tim\", \" and\", \" Wyatt\", \" were\", \" working\", \" at\", \" the\", \" garage\", \".\", \" Wyatt\", \" decided\", \" to\", \" give\", \" a\", \" bible\", \" to\", \" Tim\", \"\\n\", \"Then\", \",\", \" Sam\", \" and\", \" Peter\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Peter\", \" decided\", \" to\", \" give\", \" a\", \" remote\", \" to\", \" Sam\", \"\\n\", \"Then\", \",\", \" Ross\", \" and\", \" Jason\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Jason\", \" decided\", \" to\", \" give\", \" a\", \" chalk\", \" to\", \" Ross\", \"\\n\", \"Then\", \",\", \" Nathan\", \" and\", \" Eva\", \" were\", \" working\", \" at\", \" the\", \" cafe\", \".\", \" Eva\", \" decided\", \" to\", \" give\", \" a\", \" vinyl\", \" to\", \" Nathan\", \"\\n\", \"Then\", \",\", \" Matt\", \" and\", \" Evan\", \" were\", \" working\", \" at\", \" the\", \" stadium\", \".\", \" Evan\", \" decided\", \" to\", \" give\", \" a\", \" crate\", \" to\", \" Matt\", \"\\n\", \"Then\", \",\", \" Taylor\", \" and\", \" Grant\", \" were\", \" working\", \" at\", \" the\", \" lounge\", \".\", \" Taylor\", \" decided\", \" to\", \" give\", \" a\", \" shorts\", \" to\", \" Grant\", \"\\n\", \"Then\", \",\", \" Jake\", \" and\", \" Kate\", \" were\", \" working\", \" at\", \" the\", \" synagogue\", \".\", \" Jake\", \" decided\", \" to\", \" give\", \" a\", \" backpack\", \" to\", \" Kate\", \"\\n\", \"Then\", \",\", \" Julia\", \" and\", \" Rose\", \" were\", \" working\", \" at\", \" the\", \" museum\", \".\", \" Julia\", \" decided\", \" to\", \" give\", \" a\", \" wrench\", \" to\", \" Rose\", \"\\n\", \"Then\", \",\", \" Jennifer\", \" and\", \" Brooklyn\", \" were\", \" working\", \" at\", \" the\", \" fortress\", \".\", \" Jennifer\", \" decided\", \" to\", \" give\", \" a\", \" tape\", \" to\", \" Brooklyn\", \"\\n\", \"Then\", \",\", \" Mason\", \" and\", \" Jeff\", \" were\", \" working\", \" at\", \" the\", \" street\", \".\", \" Mason\", \" decided\", \" to\", \" give\", \" a\", \" vinyl\", \" to\", \" Jeff\", \"\\n\", \"Then\", \",\", \" Richard\", \" and\", \" Jean\", \" were\", \" working\", \" at\", \" the\", \" cottage\", \".\", \" Richard\", \" decided\", \" to\", \" give\", \" a\", \" lipstick\", \" to\", \" Jean\", \"\\n\", \"Then\", \",\", \" Ross\", \" and\", \" Elijah\", \" were\", \" working\", \" at\", \" the\", \" home\", \".\", \" Ross\", \" decided\", \" to\", \" give\", \" a\", \" flag\", \" to\", \" Elijah\", \"\\n\", \"Then\", \",\", \" Taylor\", \" and\", \" Matt\", \" were\", \" working\", \" at\", \" the\", \" palace\", \".\", \" Taylor\", \" decided\", \" to\", \" give\", \" a\", \" bookmark\", \" to\", \" Matt\", \"\\n\", \"Then\", \",\", \" Molly\", \" and\", \" Keith\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Molly\", \" decided\", \" to\", \" give\", \" a\", \" baseball\", \" to\", \" Keith\", \"\\n\", \"Then\", \",\", \" Parker\", \" and\", \" Dean\", \" were\", \" working\", \" at\", \" the\", \" tunnel\", \".\", \" Parker\", \" decided\", \" to\", \" give\", \" a\", \" tablet\", \" to\", \" Dean\", \"\\n\", \"Then\", \",\", \" Kevin\", \" and\", \" Connor\", \" were\", \" working\", \" at\", \" the\", \" harbor\", \".\", \" Kevin\", \" decided\", \" to\", \" give\", \" a\", \" bakery\", \" to\", \" Connor\", \"\\n\", \"Then\", \",\", \" Matt\", \" and\", \" Riley\", \" were\", \" working\", \" at\", \" the\", \" garden\", \".\", \" Matt\", \" decided\", \" to\", \" give\", \" a\", \" charcoal\", \" to\", \" Riley\", \"\\n\", \"Then\", \",\", \" Keith\", \" and\", \" Joy\", \" were\", \" working\", \" at\", \" the\", \" plateau\", \".\", \" Keith\", \" decided\", \" to\", \" give\", \" a\", \" ring\", \" to\", \" Joy\", \"\\n\", \"Then\", \",\", \" Ruby\", \" and\", \" Ray\", \" were\", \" working\", \" at\", \" the\", \" brewery\", \".\", \" Ruby\", \" decided\", \" to\", \" give\", \" a\", \" lipstick\", \" to\", \" Ray\", \"\\n\"], \"activations\": [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.23246407508850098]], [[-0.032052040100097656]], [[0.005444765090942383]], [[-0.0034720897674560547]], [[0.020882606506347656]], [[0.004131317138671875]], [[0.02515435218811035]], [[0.012512683868408203]], [[0.0020889341831207275]], [[0.010663986206054688]], [[0.009011983871459961]], [[0.008788108825683594]], [[0.0015717744827270508]], [[0.007400214672088623]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.19469332695007324]], [[-0.033525943756103516]], [[0.0059833526611328125]], [[-0.012211084365844727]], [[-0.0012912750244140625]], [[-0.0050182342529296875]], [[0.11696648597717285]], [[0.01785564422607422]], [[0.0012475550174713135]], [[0.005936384201049805]], [[-0.007285356521606445]], [[-0.0050258636474609375]], [[0.00025710463523864746]], [[-0.1422051191329956]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.1974024772644043]], [[-0.052356719970703125]], [[0.0045757293701171875]], [[-0.010634779930114746]], [[-0.012930870056152344]], [[0.0009438991546630859]], [[-0.03262662887573242]], [[0.013803482055664062]], [[-0.0012052655220031738]], [[0.015021324157714844]], [[-0.010660171508789062]], [[0.00015997886657714844]], [[0.03172183036804199]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.28868842124938965]], [[-0.02869129180908203]], [[-0.0007052421569824219]], [[-0.0024260282516479492]], [[0.008505821228027344]], [[0.0011477470397949219]], [[-0.1404721736907959]], [[0.011883258819580078]], [[-0.00024324655532836914]], [[0.004954099655151367]], [[0.021988630294799805]], [[0.0229949951171875]], [[0.006717562675476074]], [[-0.21309363842010498]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.16577982902526855]], [[-0.032204627990722656]], [[0.0017933845520019531]], [[-0.015320658683776855]], [[0.026824951171875]], [[0.0020842552185058594]], [[0.07494783401489258]], [[0.010121822357177734]], [[0.0011683404445648193]], [[0.007421970367431641]], [[0.006356477737426758]], [[0.011791229248046875]], [[0.0018262863159179688]], [[-0.08789491653442383]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.20824432373046875]], [[-0.038089752197265625]], [[0.0006923675537109375]], [[-0.004929065704345703]], [[0.010123252868652344]], [[0.002589106559753418]], [[0.18663501739501953]], [[0.0041599273681640625]], [[0.0018446743488311768]], [[0.005127906799316406]], [[0.01236104965209961]], [[-0.0063304901123046875]], [[0.0036668777465820312]], [[-0.001960277557373047]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.17023921012878418]], [[-0.05022573471069336]], [[0.003916740417480469]], [[-0.007248878479003906]], [[-0.022615432739257812]], [[-0.005077362060546875]], [[0.28868985176086426]], [[0.006206512451171875]], [[0.0021871626377105713]], [[0.005753517150878906]], [[0.036582231521606445]], [[-0.0038127899169921875]], [[0.0020761489868164062]], [[-0.2299262285232544]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.2777571678161621]], [[-0.019336700439453125]], [[-0.0013158321380615234]], [[-0.0031703710556030273]], [[-0.008260726928710938]], [[0.002803325653076172]], [[0.12803959846496582]], [[0.011270523071289062]], [[0.0003299415111541748]], [[0.005216121673583984]], [[0.04369640350341797]], [[-0.013020515441894531]], [[3.695487976074219e-05]], [[0.014495015144348145]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.15246081352233887]], [[-0.047492027282714844]], [[0.0009679794311523438]], [[-0.0019055604934692383]], [[0.015187263488769531]], [[-0.0032874345779418945]], [[-0.09653115272521973]], [[0.0059680938720703125]], [[-0.0028306245803833008]], [[0.006328582763671875]], [[-0.017522811889648438]], [[-0.0276336669921875]], [[0.015860557556152344]], [[-0.17280727624893188]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.2677338123321533]], [[-0.042754173278808594]], [[0.0030226707458496094]], [[-0.009443163871765137]], [[-0.009085655212402344]], [[-0.00031566619873046875]], [[-0.1757817268371582]], [[-0.0019178390502929688]], [[-0.0025826096534729004]], [[0.00405120849609375]], [[-0.10482645034790039]], [[-0.01690959930419922]], [[-0.005302131175994873]], [[-0.061781346797943115]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.11403250694274902]], [[-0.04063272476196289]], [[0.00638270378112793]], [[-0.010868072509765625]], [[-0.015557289123535156]], [[-0.00015354156494140625]], [[-0.2020726203918457]], [[0.014209270477294922]], [[-0.004138588905334473]], [[0.00710749626159668]], [[-0.011434555053710938]], [[0.00046634674072265625]], [[0.0015018880367279053]], [[-0.065041184425354]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.15830445289611816]], [[-0.04542207717895508]], [[-0.0034554004669189453]], [[-0.0002759695053100586]], [[-0.023416519165039062]], [[0.006494641304016113]], [[-0.030142545700073242]], [[0.012692451477050781]], [[-0.002528548240661621]], [[0.0054264068603515625]], [[-0.003398895263671875]], [[0.00786590576171875]], [[0.0009002685546875]], [[-0.31861793994903564]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.16220641136169434]], [[-0.030889511108398438]], [[0.0012068748474121094]], [[-0.0038520097732543945]], [[0.004103660583496094]], [[0.012752056121826172]], [[0.06048250198364258]], [[0.02501058578491211]], [[0.0037393569946289062]], [[0.007857322692871094]], [[0.002958059310913086]], [[0.0025548934936523438]], [[0.0011744499206542969]], [[-0.1950470209121704]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.20473861694335938]], [[-0.024764537811279297]], [[-6.151199340820312e-05]], [[-0.011402368545532227]], [[-0.00946807861328125]], [[-0.003286123275756836]], [[-0.1121068000793457]], [[0.006744861602783203]], [[0.003184795379638672]], [[0.0051441192626953125]], [[0.04031658172607422]], [[0.0015659332275390625]], [[0.0023773908615112305]], [[-0.21641957759857178]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.19630217552185059]], [[-0.04508829116821289]], [[0.0035517215728759766]], [[-0.00837397575378418]], [[0.004262447357177734]], [[-0.003835916519165039]], [[-0.10821819305419922]], [[0.0022678375244140625]], [[0.003123939037322998]], [[0.0075609683990478516]], [[0.08629727363586426]], [[0.0008640289306640625]], [[0.0042032599449157715]], [[-0.5761778950691223]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.22566819190979004]], [[-0.03749704360961914]], [[0.0012993812561035156]], [[-0.010314106941223145]], [[0.020203590393066406]], [[0.006706953048706055]], [[-0.02463364601135254]], [[0.0011610984802246094]], [[-0.0032387971878051758]], [[0.0030913352966308594]], [[-0.03554892539978027]], [[-0.008281707763671875]], [[-0.0006603151559829712]], [[-0.3858734369277954]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.22486257553100586]], [[-0.028198719024658203]], [[0.0030553340911865234]], [[-0.007585048675537109]], [[0.017913818359375]], [[0.006427645683288574]], [[0.11919128894805908]], [[0.01004791259765625]], [[-0.003360152244567871]], [[0.00485539436340332]], [[0.004054069519042969]], [[0.03547382354736328]], [[0.004053831100463867]], [[-0.2296072244644165]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.19234108924865723]], [[-0.04674053192138672]], [[0.002901792526245117]], [[-0.010224580764770508]], [[-0.012457847595214844]], [[0.0021930932998657227]], [[-0.026563644409179688]], [[0.010080337524414062]], [[0.003958374261856079]], [[0.009083271026611328]], [[0.03898143768310547]], [[0.0017242431640625]], [[-0.0033058524131774902]], [[-0.20810431241989136]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.2948932647705078]], [[-0.03567028045654297]], [[0.001064300537109375]], [[-0.012877225875854492]], [[0.010120391845703125]], [[0.003426074981689453]], [[-0.24024724960327148]], [[0.00650787353515625]], [[0.0004981458187103271]], [[0.008542537689208984]], [[-0.013366460800170898]], [[-0.04648113250732422]], [[0.0017540454864501953]], [[-0.2657647132873535]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.20046091079711914]], [[-0.041370391845703125]], [[-0.0058307647705078125]], [[-0.005259394645690918]], [[-0.025323867797851562]], [[0.007467031478881836]], [[-0.14570856094360352]], [[0.01534271240234375]], [[-0.004408717155456543]], [[0.004195213317871094]], [[0.06267833709716797]], [[-0.025427818298339844]], [[0.007318973541259766]], [[-0.09137845039367676]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.05338764190673828]], [[-0.03135538101196289]], [[0.003683328628540039]], [[-0.0006632804870605469]], [[0.009402275085449219]], [[0.002589106559753418]], [[0.03978228569030762]], [[0.01766061782836914]], [[-0.0013532936573028564]], [[0.008070945739746094]], [[-0.012161731719970703]], [[0.018798828125]], [[0.0006980597972869873]], [[-0.24113976955413818]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.18676018714904785]], [[-0.09901666641235352]], [[0.013880491256713867]], [[-0.003508925437927246]], [[-0.002555370330810547]], [[0.003337860107421875]], [[-0.059739112854003906]], [[0.008483409881591797]], [[-0.0053362250328063965]], [[0.003726482391357422]], [[-0.05905318260192871]], [[0.017913818359375]], [[0.008614063262939453]], [[-0.26125282049179077]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fc7b195feb0>"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_feature_direction_display(ex_sent_combined, best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-8c2acbfb-4dcc\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-8c2acbfb-4dcc\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"Then\", \",\", \" Richard\", \" and\", \" Jennifer\", \" were\", \" working\", \" at\", \" the\", \" plateau\", \".\", \" Jennifer\", \" decided\", \" to\", \" give\", \" a\", \" feather\", \" to\", \" Jennifer\", \"\\n\", \"Then\", \",\", \" Laura\", \" and\", \" Catherine\", \" were\", \" working\", \" at\", \" the\", \" cafe\", \".\", \" Catherine\", \" decided\", \" to\", \" give\", \" a\", \" towel\", \" to\", \" Catherine\", \"\\n\", \"Then\", \",\", \" Parker\", \" and\", \" Jake\", \" were\", \" working\", \" at\", \" the\", \" glacier\", \".\", \" Jake\", \" decided\", \" to\", \" give\", \" fins\", \" to\", \" Jake\", \"\\n\", \"Then\", \",\", \" Tim\", \" and\", \" Wyatt\", \" were\", \" working\", \" at\", \" the\", \" garage\", \".\", \" Wyatt\", \" decided\", \" to\", \" give\", \" a\", \" bible\", \" to\", \" Wyatt\", \"\\n\", \"Then\", \",\", \" Sam\", \" and\", \" Peter\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Peter\", \" decided\", \" to\", \" give\", \" a\", \" remote\", \" to\", \" Peter\", \"\\n\", \"Then\", \",\", \" Ross\", \" and\", \" Jason\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Jason\", \" decided\", \" to\", \" give\", \" a\", \" chalk\", \" to\", \" Jason\", \"\\n\", \"Then\", \",\", \" Nathan\", \" and\", \" Eva\", \" were\", \" working\", \" at\", \" the\", \" cafe\", \".\", \" Eva\", \" decided\", \" to\", \" give\", \" a\", \" vinyl\", \" to\", \" Eva\", \"\\n\", \"Then\", \",\", \" Matt\", \" and\", \" Evan\", \" were\", \" working\", \" at\", \" the\", \" stadium\", \".\", \" Evan\", \" decided\", \" to\", \" give\", \" a\", \" crate\", \" to\", \" Evan\", \"\\n\", \"Then\", \",\", \" Taylor\", \" and\", \" Grant\", \" were\", \" working\", \" at\", \" the\", \" lounge\", \".\", \" Taylor\", \" decided\", \" to\", \" give\", \" a\", \" shorts\", \" to\", \" Taylor\", \"\\n\", \"Then\", \",\", \" Jake\", \" and\", \" Kate\", \" were\", \" working\", \" at\", \" the\", \" synagogue\", \".\", \" Jake\", \" decided\", \" to\", \" give\", \" a\", \" backpack\", \" to\", \" Jake\", \"\\n\", \"Then\", \",\", \" Julia\", \" and\", \" Rose\", \" were\", \" working\", \" at\", \" the\", \" museum\", \".\", \" Julia\", \" decided\", \" to\", \" give\", \" a\", \" wrench\", \" to\", \" Julia\", \"\\n\", \"Then\", \",\", \" Jennifer\", \" and\", \" Brooklyn\", \" were\", \" working\", \" at\", \" the\", \" fortress\", \".\", \" Jennifer\", \" decided\", \" to\", \" give\", \" a\", \" tape\", \" to\", \" Jennifer\", \"\\n\", \"Then\", \",\", \" Mason\", \" and\", \" Jeff\", \" were\", \" working\", \" at\", \" the\", \" street\", \".\", \" Mason\", \" decided\", \" to\", \" give\", \" a\", \" vinyl\", \" to\", \" Mason\", \"\\n\", \"Then\", \",\", \" Richard\", \" and\", \" Jean\", \" were\", \" working\", \" at\", \" the\", \" cottage\", \".\", \" Richard\", \" decided\", \" to\", \" give\", \" a\", \" lipstick\", \" to\", \" Richard\", \"\\n\", \"Then\", \",\", \" Ross\", \" and\", \" Elijah\", \" were\", \" working\", \" at\", \" the\", \" home\", \".\", \" Ross\", \" decided\", \" to\", \" give\", \" a\", \" flag\", \" to\", \" Ross\", \"\\n\", \"Then\", \",\", \" Taylor\", \" and\", \" Matt\", \" were\", \" working\", \" at\", \" the\", \" palace\", \".\", \" Taylor\", \" decided\", \" to\", \" give\", \" a\", \" bookmark\", \" to\", \" Taylor\", \"\\n\", \"Then\", \",\", \" Molly\", \" and\", \" Keith\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Molly\", \" decided\", \" to\", \" give\", \" a\", \" baseball\", \" to\", \" Molly\", \"\\n\", \"Then\", \",\", \" Parker\", \" and\", \" Dean\", \" were\", \" working\", \" at\", \" the\", \" tunnel\", \".\", \" Parker\", \" decided\", \" to\", \" give\", \" a\", \" tablet\", \" to\", \" Parker\", \"\\n\", \"Then\", \",\", \" Kevin\", \" and\", \" Connor\", \" were\", \" working\", \" at\", \" the\", \" harbor\", \".\", \" Kevin\", \" decided\", \" to\", \" give\", \" a\", \" bakery\", \" to\", \" Kevin\", \"\\n\", \"Then\", \",\", \" Matt\", \" and\", \" Riley\", \" were\", \" working\", \" at\", \" the\", \" garden\", \".\", \" Matt\", \" decided\", \" to\", \" give\", \" a\", \" charcoal\", \" to\", \" Matt\", \"\\n\", \"Then\", \",\", \" Keith\", \" and\", \" Joy\", \" were\", \" working\", \" at\", \" the\", \" plateau\", \".\", \" Keith\", \" decided\", \" to\", \" give\", \" a\", \" ring\", \" to\", \" Keith\", \"\\n\", \"Then\", \",\", \" Ruby\", \" and\", \" Ray\", \" were\", \" working\", \" at\", \" the\", \" brewery\", \".\", \" Ruby\", \" decided\", \" to\", \" give\", \" a\", \" lipstick\", \" to\", \" Ruby\", \"\\n\"], \"activations\": [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.23246407508850098]], [[-0.032052040100097656]], [[0.005444765090942383]], [[-0.0034720897674560547]], [[0.020882606506347656]], [[0.004131317138671875]], [[0.02515435218811035]], [[0.012512683868408203]], [[0.0020889341831207275]], [[0.010663986206054688]], [[0.009011983871459961]], [[0.008788108825683594]], [[0.0015717744827270508]], [[0.34201955795288086]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.19469332695007324]], [[-0.033525943756103516]], [[0.0059833526611328125]], [[-0.012211084365844727]], [[-0.0012912750244140625]], [[-0.0050182342529296875]], [[0.11696648597717285]], [[0.01785564422607422]], [[0.0012475550174713135]], [[0.005936384201049805]], [[-0.007285356521606445]], [[-0.0050258636474609375]], [[0.00025710463523864746]], [[1.043990135192871]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.1974024772644043]], [[-0.052356719970703125]], [[0.0045757293701171875]], [[-0.010634779930114746]], [[-0.012930870056152344]], [[0.0009438991546630859]], [[-0.03262662887573242]], [[0.013803482055664062]], [[-0.0012052655220031738]], [[0.015021324157714844]], [[-0.010660171508789062]], [[0.00015997886657714844]], [[0.34749388694763184]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.28868842124938965]], [[-0.02869129180908203]], [[-0.0007052421569824219]], [[-0.0024260282516479492]], [[0.008505821228027344]], [[0.0011477470397949219]], [[-0.1404721736907959]], [[0.011883258819580078]], [[-0.00024324655532836914]], [[0.004954099655151367]], [[0.021988630294799805]], [[0.0229949951171875]], [[0.006717562675476074]], [[0.25839829444885254]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.16577982902526855]], [[-0.032204627990722656]], [[0.0017933845520019531]], [[-0.015320658683776855]], [[0.026824951171875]], [[0.0020842552185058594]], [[0.07494783401489258]], [[0.010121822357177734]], [[0.0011683404445648193]], [[0.007421970367431641]], [[0.006356477737426758]], [[0.011791229248046875]], [[0.0018262863159179688]], [[0.21536588668823242]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.20824432373046875]], [[-0.038089752197265625]], [[0.0006923675537109375]], [[-0.004929065704345703]], [[0.010123252868652344]], [[0.002589106559753418]], [[0.18663501739501953]], [[0.0041599273681640625]], [[0.0018446743488311768]], [[0.005127906799316406]], [[0.01236104965209961]], [[-0.0063304901123046875]], [[0.0036668777465820312]], [[0.5862994194030762]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.17023921012878418]], [[-0.05022573471069336]], [[0.003916740417480469]], [[-0.007248878479003906]], [[-0.022615432739257812]], [[-0.005077362060546875]], [[0.28868985176086426]], [[0.006206512451171875]], [[0.0021871626377105713]], [[0.005753517150878906]], [[0.036582231521606445]], [[-0.0038127899169921875]], [[0.0020761489868164062]], [[1.0182571411132812]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.2777571678161621]], [[-0.019336700439453125]], [[-0.0013158321380615234]], [[-0.0031703710556030273]], [[-0.008260726928710938]], [[0.002803325653076172]], [[0.12803959846496582]], [[0.011270523071289062]], [[0.0003299415111541748]], [[0.005216121673583984]], [[0.04369640350341797]], [[-0.013020515441894531]], [[3.695487976074219e-05]], [[0.978062629699707]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.15246081352233887]], [[-0.047492027282714844]], [[0.0009679794311523438]], [[-0.0019055604934692383]], [[0.015187263488769531]], [[-0.0032874345779418945]], [[-0.09653115272521973]], [[0.0059680938720703125]], [[-0.0028306245803833008]], [[0.006328582763671875]], [[-0.017522811889648438]], [[-0.0276336669921875]], [[0.015860557556152344]], [[0.49163103103637695]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.2677338123321533]], [[-0.042754173278808594]], [[0.0030226707458496094]], [[-0.009443163871765137]], [[-0.009085655212402344]], [[-0.00031566619873046875]], [[-0.1757817268371582]], [[-0.0019178390502929688]], [[-0.0025826096534729004]], [[0.00405120849609375]], [[-0.10482645034790039]], [[-0.01690959930419922]], [[-0.005302131175994873]], [[0.5644130706787109]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.11403250694274902]], [[-0.04063272476196289]], [[0.00638270378112793]], [[-0.010868072509765625]], [[-0.015557289123535156]], [[-0.00015354156494140625]], [[-0.2020726203918457]], [[0.014209270477294922]], [[-0.004138588905334473]], [[0.00710749626159668]], [[-0.011434555053710938]], [[0.00046634674072265625]], [[0.0015018880367279053]], [[0.035036563873291016]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.15830445289611816]], [[-0.04542207717895508]], [[-0.0034554004669189453]], [[-0.0002759695053100586]], [[-0.023416519165039062]], [[0.006494641304016113]], [[-0.030142545700073242]], [[0.012692451477050781]], [[-0.002528548240661621]], [[0.0054264068603515625]], [[-0.003398895263671875]], [[0.00786590576171875]], [[0.0009002685546875]], [[0.15694618225097656]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.16220641136169434]], [[-0.030889511108398438]], [[0.0012068748474121094]], [[-0.0038520097732543945]], [[0.004103660583496094]], [[0.012752056121826172]], [[0.06048250198364258]], [[0.02501058578491211]], [[0.0037393569946289062]], [[0.007857322692871094]], [[0.002958059310913086]], [[0.0025548934936523438]], [[0.0011744499206542969]], [[1.13100266456604]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.20473861694335938]], [[-0.024764537811279297]], [[-6.151199340820312e-05]], [[-0.011402368545532227]], [[-0.00946807861328125]], [[-0.003286123275756836]], [[-0.1121068000793457]], [[0.006744861602783203]], [[0.003184795379638672]], [[0.0051441192626953125]], [[0.04031658172607422]], [[0.0015659332275390625]], [[0.0023773908615112305]], [[0.45766305923461914]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.19630217552185059]], [[-0.04508829116821289]], [[0.0035517215728759766]], [[-0.00837397575378418]], [[0.004262447357177734]], [[-0.003835916519165039]], [[-0.10821819305419922]], [[0.0022678375244140625]], [[0.003123939037322998]], [[0.0075609683990478516]], [[0.08629727363586426]], [[0.0008640289306640625]], [[0.0042032599449157715]], [[1.3519973754882812]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.22566819190979004]], [[-0.03749704360961914]], [[0.0012993812561035156]], [[-0.010314106941223145]], [[0.020203590393066406]], [[0.006706953048706055]], [[-0.02463364601135254]], [[0.0011610984802246094]], [[-0.0032387971878051758]], [[0.0030913352966308594]], [[-0.03554892539978027]], [[-0.008281707763671875]], [[-0.0006603151559829712]], [[0.3408026695251465]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.22486257553100586]], [[-0.028198719024658203]], [[0.0030553340911865234]], [[-0.007585048675537109]], [[0.017913818359375]], [[0.006427645683288574]], [[0.11919128894805908]], [[0.01004791259765625]], [[-0.003360152244567871]], [[0.00485539436340332]], [[0.004054069519042969]], [[0.03547382354736328]], [[0.004053831100463867]], [[0.1433422565460205]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.19234108924865723]], [[-0.04674053192138672]], [[0.002901792526245117]], [[-0.010224580764770508]], [[-0.012457847595214844]], [[0.0021930932998657227]], [[-0.026563644409179688]], [[0.010080337524414062]], [[0.003958374261856079]], [[0.009083271026611328]], [[0.03898143768310547]], [[0.0017242431640625]], [[-0.0033058524131774902]], [[0.753173828125]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.2948932647705078]], [[-0.03567028045654297]], [[0.001064300537109375]], [[-0.012877225875854492]], [[0.010120391845703125]], [[0.003426074981689453]], [[-0.24024724960327148]], [[0.00650787353515625]], [[0.0004981458187103271]], [[0.008542537689208984]], [[-0.013366460800170898]], [[-0.04648113250732422]], [[0.0017540454864501953]], [[0.08148527145385742]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.20046091079711914]], [[-0.041370391845703125]], [[-0.0058307647705078125]], [[-0.005259394645690918]], [[-0.025323867797851562]], [[0.007467031478881836]], [[-0.14570856094360352]], [[0.01534271240234375]], [[-0.004408717155456543]], [[0.004195213317871094]], [[0.06267833709716797]], [[-0.025427818298339844]], [[0.007318973541259766]], [[0.052670955657958984]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.05338764190673828]], [[-0.03135538101196289]], [[0.003683328628540039]], [[-0.0006632804870605469]], [[0.009402275085449219]], [[0.002589106559753418]], [[0.03978228569030762]], [[0.01766061782836914]], [[-0.0013532936573028564]], [[0.008070945739746094]], [[-0.012161731719970703]], [[0.018798828125]], [[0.0006980597972869873]], [[0.47122931480407715]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.18676018714904785]], [[-0.09901666641235352]], [[0.013880491256713867]], [[-0.003508925437927246]], [[-0.002555370330810547]], [[0.003337860107421875]], [[-0.059739112854003906]], [[0.008483409881591797]], [[-0.0053362250328063965]], [[0.003726482391357422]], [[-0.05905318260192871]], [[0.017913818359375]], [[0.008614063262939453]], [[0.38641786575317383]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fc7b195f6d0>"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_feature_direction_display(wrong_sentences, best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-9dfce7c7-e893\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-9dfce7c7-e893\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"Then\", \",\", \" Richard\", \" and\", \" Jennifer\", \" were\", \" working\", \" at\", \" the\", \" plateau\", \".\", \" Jennifer\", \" decided\", \" to\", \" give\", \" a\", \" feather\", \" to\", \" Jennifer\", \"\\n\", \"Then\", \",\", \" Laura\", \" and\", \" Catherine\", \" were\", \" working\", \" at\", \" the\", \" cafe\", \".\", \" Catherine\", \" decided\", \" to\", \" give\", \" a\", \" towel\", \" to\", \" Catherine\", \"\\n\", \"Then\", \",\", \" Parker\", \" and\", \" Jake\", \" were\", \" working\", \" at\", \" the\", \" glacier\", \".\", \" Jake\", \" decided\", \" to\", \" give\", \" fins\", \" to\", \" Jake\", \"\\n\", \"Then\", \",\", \" Tim\", \" and\", \" Wyatt\", \" were\", \" working\", \" at\", \" the\", \" garage\", \".\", \" Wyatt\", \" decided\", \" to\", \" give\", \" a\", \" bible\", \" to\", \" Wyatt\", \"\\n\", \"Then\", \",\", \" Sam\", \" and\", \" Peter\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Peter\", \" decided\", \" to\", \" give\", \" a\", \" remote\", \" to\", \" Peter\", \"\\n\", \"Then\", \",\", \" Ross\", \" and\", \" Jason\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Jason\", \" decided\", \" to\", \" give\", \" a\", \" chalk\", \" to\", \" Jason\", \"\\n\", \"Then\", \",\", \" Nathan\", \" and\", \" Eva\", \" were\", \" working\", \" at\", \" the\", \" cafe\", \".\", \" Eva\", \" decided\", \" to\", \" give\", \" a\", \" vinyl\", \" to\", \" Eva\", \"\\n\", \"Then\", \",\", \" Matt\", \" and\", \" Evan\", \" were\", \" working\", \" at\", \" the\", \" stadium\", \".\", \" Evan\", \" decided\", \" to\", \" give\", \" a\", \" crate\", \" to\", \" Evan\", \"\\n\", \"Then\", \",\", \" Taylor\", \" and\", \" Grant\", \" were\", \" working\", \" at\", \" the\", \" lounge\", \".\", \" Taylor\", \" decided\", \" to\", \" give\", \" a\", \" shorts\", \" to\", \" Taylor\", \"\\n\", \"Then\", \",\", \" Jake\", \" and\", \" Kate\", \" were\", \" working\", \" at\", \" the\", \" synagogue\", \".\", \" Jake\", \" decided\", \" to\", \" give\", \" a\", \" backpack\", \" to\", \" Jake\", \"\\n\", \"Then\", \",\", \" Julia\", \" and\", \" Rose\", \" were\", \" working\", \" at\", \" the\", \" museum\", \".\", \" Julia\", \" decided\", \" to\", \" give\", \" a\", \" wrench\", \" to\", \" Julia\", \"\\n\", \"Then\", \",\", \" Jennifer\", \" and\", \" Brooklyn\", \" were\", \" working\", \" at\", \" the\", \" fortress\", \".\", \" Jennifer\", \" decided\", \" to\", \" give\", \" a\", \" tape\", \" to\", \" Jennifer\", \"\\n\", \"Then\", \",\", \" Mason\", \" and\", \" Jeff\", \" were\", \" working\", \" at\", \" the\", \" street\", \".\", \" Mason\", \" decided\", \" to\", \" give\", \" a\", \" vinyl\", \" to\", \" Mason\", \"\\n\", \"Then\", \",\", \" Richard\", \" and\", \" Jean\", \" were\", \" working\", \" at\", \" the\", \" cottage\", \".\", \" Richard\", \" decided\", \" to\", \" give\", \" a\", \" lipstick\", \" to\", \" Richard\", \"\\n\", \"Then\", \",\", \" Ross\", \" and\", \" Elijah\", \" were\", \" working\", \" at\", \" the\", \" home\", \".\", \" Ross\", \" decided\", \" to\", \" give\", \" a\", \" flag\", \" to\", \" Ross\", \"\\n\", \"Then\", \",\", \" Taylor\", \" and\", \" Matt\", \" were\", \" working\", \" at\", \" the\", \" palace\", \".\", \" Taylor\", \" decided\", \" to\", \" give\", \" a\", \" bookmark\", \" to\", \" Taylor\", \"\\n\", \"Then\", \",\", \" Molly\", \" and\", \" Keith\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Molly\", \" decided\", \" to\", \" give\", \" a\", \" baseball\", \" to\", \" Molly\", \"\\n\", \"Then\", \",\", \" Parker\", \" and\", \" Dean\", \" were\", \" working\", \" at\", \" the\", \" tunnel\", \".\", \" Parker\", \" decided\", \" to\", \" give\", \" a\", \" tablet\", \" to\", \" Parker\", \"\\n\", \"Then\", \",\", \" Kevin\", \" and\", \" Connor\", \" were\", \" working\", \" at\", \" the\", \" harbor\", \".\", \" Kevin\", \" decided\", \" to\", \" give\", \" a\", \" bakery\", \" to\", \" Kevin\", \"\\n\", \"Then\", \",\", \" Matt\", \" and\", \" Riley\", \" were\", \" working\", \" at\", \" the\", \" garden\", \".\", \" Matt\", \" decided\", \" to\", \" give\", \" a\", \" charcoal\", \" to\", \" Matt\", \"\\n\", \"Then\", \",\", \" Keith\", \" and\", \" Joy\", \" were\", \" working\", \" at\", \" the\", \" plateau\", \".\", \" Keith\", \" decided\", \" to\", \" give\", \" a\", \" ring\", \" to\", \" Keith\", \"\\n\", \"Then\", \",\", \" Ruby\", \" and\", \" Ray\", \" were\", \" working\", \" at\", \" the\", \" brewery\", \".\", \" Ruby\", \" decided\", \" to\", \" give\", \" a\", \" lipstick\", \" to\", \" Ruby\", \"\\n\"], \"activations\": [[[0.0022649765014648438]], [[0.00011801719665527344]], [[0.014321327209472656]], [[7.009506225585938e-05]], [[-0.023974895477294922]], [[-0.016510963439941406]], [[0.009851455688476562]], [[0.0043027400970458984]], [[-0.0024045705795288086]], [[-0.0015115737915039062]], [[-0.0013089179992675781]], [[-0.10856199264526367]], [[0.011088848114013672]], [[-0.0005521476268768311]], [[-0.010959625244140625]], [[-0.014956951141357422]], [[0.03501319885253906]], [[-0.019893944263458252]], [[-0.12469339370727539]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.01872730255126953]], [[-0.007091045379638672]], [[-0.006995201110839844]], [[-0.013813495635986328]], [[0.008151531219482422]], [[0.0030040740966796875]], [[0.0011625289916992188]], [[0.003097057342529297]], [[0.0011148452758789062]], [[-0.1297447681427002]], [[0.01393890380859375]], [[-0.0015087723731994629]], [[-0.009514808654785156]], [[-0.03609728813171387]], [[-0.030946731567382812]], [[-0.003821134567260742]], [[-0.21745967864990234]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.013175010681152344]], [[-0.0035600662231445312]], [[-0.013773918151855469]], [[-0.004466056823730469]], [[0.011275291442871094]], [[0.0044097900390625]], [[-0.000812530517578125]], [[-0.021575927734375]], [[-0.002766132354736328]], [[-0.07112407684326172]], [[0.014347076416015625]], [[-0.0015672743320465088]], [[-0.0088043212890625]], [[-0.011075019836425781]], [[0.0016570091247558594]], [[-0.10304498672485352]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.018683433532714844]], [[-0.00786447525024414]], [[0.009722709655761719]], [[-0.013342142105102539]], [[0.010752677917480469]], [[0.007184505462646484]], [[-0.0022569894790649414]], [[0.0028128623962402344]], [[0.00038313865661621094]], [[-0.10992002487182617]], [[0.010116100311279297]], [[-0.002773791551589966]], [[-0.010713577270507812]], [[-0.04602956771850586]], [[0.005580902099609375]], [[-0.0008633732795715332]], [[-0.10968184471130371]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.028082847595214844]], [[-0.0020322799682617188]], [[0.010447502136230469]], [[-0.008121967315673828]], [[0.007628440856933594]], [[0.003999948501586914]], [[0.0002855062484741211]], [[0.0005931854248046875]], [[-0.001316070556640625]], [[-0.06950855255126953]], [[0.007730960845947266]], [[-0.0014910697937011719]], [[-0.009915351867675781]], [[-0.031070947647094727]], [[0.02602863311767578]], [[0.0021767616271972656]], [[-0.07170486450195312]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.01592254638671875]], [[0.00025844573974609375]], [[-0.012169837951660156]], [[-0.010526180267333984]], [[0.010656356811523438]], [[0.006152629852294922]], [[-0.0032001733779907227]], [[-0.009308815002441406]], [[4.863739013671875e-05]], [[-0.09356284141540527]], [[0.016138553619384766]], [[-0.0017150342464447021]], [[-0.010634899139404297]], [[-0.006658077239990234]], [[-0.011851310729980469]], [[0.03739500045776367]], [[-0.1279611587524414]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.01578807830810547]], [[0.007590770721435547]], [[-0.0027709007263183594]], [[-0.012078285217285156]], [[0.012618064880371094]], [[0.0026264190673828125]], [[-0.0025597810745239258]], [[0.009250640869140625]], [[0.0022454261779785156]], [[-0.1028144359588623]], [[0.018222332000732422]], [[-0.0027076303958892822]], [[-0.008693933486938477]], [[-0.01714491844177246]], [[-0.005908012390136719]], [[-0.0069732666015625]], [[-0.09656381607055664]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.012661933898925781]], [[0.008759260177612305]], [[0.02038097381591797]], [[-0.010403633117675781]], [[0.009507179260253906]], [[0.007952213287353516]], [[-0.0016335248947143555]], [[-0.01720905303955078]], [[0.003307342529296875]], [[-0.09962677955627441]], [[0.00964212417602539]], [[-0.0012597441673278809]], [[-0.011534690856933594]], [[-0.04120302200317383]], [[0.00015163421630859375]], [[0.0013689994812011719]], [[-0.19992685317993164]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.022907257080078125]], [[-0.00055694580078125]], [[0.029809951782226562]], [[-0.013696908950805664]], [[0.012282848358154297]], [[0.0041790008544921875]], [[-0.00041806697845458984]], [[-0.006656646728515625]], [[0.0008301734924316406]], [[0.02951216697692871]], [[0.016957759857177734]], [[-0.002310454845428467]], [[-0.011583328247070312]], [[-0.013662099838256836]], [[-0.0038604736328125]], [[-0.004159688949584961]], [[0.1858046054840088]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.01132965087890625]], [[-0.00013947486877441406]], [[-0.006052970886230469]], [[-0.009699583053588867]], [[0.009695053100585938]], [[0.0021200180053710938]], [[-0.0006301403045654297]], [[-0.008393287658691406]], [[-0.0038504600524902344]], [[0.04381263256072998]], [[0.005794048309326172]], [[-0.002703368663787842]], [[-0.011276006698608398]], [[0.00262451171875]], [[0.010163307189941406]], [[0.0012625455856323242]], [[0.28137922286987305]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.015857696533203125]], [[-0.002820253372192383]], [[-0.012377738952636719]], [[-0.01101994514465332]], [[0.010821819305419922]], [[0.004931211471557617]], [[0.001130223274230957]], [[0.0019559860229492188]], [[-0.0013089179992675781]], [[0.04137849807739258]], [[0.01205301284790039]], [[-0.0019567012786865234]], [[-0.010921478271484375]], [[-0.0005609989166259766]], [[-0.038550376892089844]], [[-0.0021667778491973877]], [[0.1492617130279541]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.013024330139160156]], [[0.0009219646453857422]], [[-0.017861366271972656]], [[-0.020667076110839844]], [[0.00964975357055664]], [[0.0030264854431152344]], [[-0.0035687685012817383]], [[-0.013444900512695312]], [[-0.0029524564743041992]], [[0.05920052528381348]], [[0.013521194458007812]], [[-0.0002620816230773926]], [[-0.011551856994628906]], [[-0.0073010921478271484]], [[-0.0006237030029296875]], [[0.005793869495391846]], [[0.1538710594177246]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.01718616485595703]], [[-0.004257917404174805]], [[0.02179431915283203]], [[-0.012546777725219727]], [[0.010365486145019531]], [[0.005730867385864258]], [[-0.002299070358276367]], [[0.0070514678955078125]], [[0.023110389709472656]], [[0.04694032669067383]], [[0.013448715209960938]], [[-0.003868997097015381]], [[-0.013043403625488281]], [[-0.017963409423828125]], [[0.0026350021362304688]], [[0.002119302749633789]], [[0.26139283180236816]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.014321327209472656]], [[7.009506225585938e-05]], [[-0.014755725860595703]], [[-0.01851820945739746]], [[0.008883953094482422]], [[0.004275321960449219]], [[-9.191036224365234e-05]], [[0.012018680572509766]], [[0.0008862018585205078]], [[0.06594204902648926]], [[0.012050628662109375]], [[-0.0016400814056396484]], [[-0.009138822555541992]], [[-0.00931406021118164]], [[-0.008419990539550781]], [[0.0022276639938354492]], [[0.2786850929260254]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.01592254638671875]], [[0.00025844573974609375]], [[-0.005198478698730469]], [[-0.014854669570922852]], [[0.008595943450927734]], [[0.004681825637817383]], [[-0.001619577407836914]], [[0.026288509368896484]], [[0.009806632995605469]], [[0.06873655319213867]], [[0.012034416198730469]], [[-0.0024697482585906982]], [[-0.007423877716064453]], [[-0.0038962364196777344]], [[0.016099929809570312]], [[-0.000938117504119873]], [[0.3598651885986328]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.022907257080078125]], [[-0.00055694580078125]], [[-0.010260581970214844]], [[-0.0031325817108154297]], [[0.011211872100830078]], [[0.005429506301879883]], [[0.0008275508880615234]], [[0.00042438507080078125]], [[-0.0007009506225585938]], [[0.04439973831176758]], [[0.01668548583984375]], [[-0.002846956253051758]], [[-0.013667821884155273]], [[-0.005007743835449219]], [[0.011074066162109375]], [[-0.001708388328552246]], [[0.1956620216369629]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.011763572692871094]], [[-0.006783485412597656]], [[-0.006911754608154297]], [[-0.014008045196533203]], [[0.009936332702636719]], [[0.002489328384399414]], [[0.00033915042877197266]], [[-0.015419960021972656]], [[-0.0006580352783203125]], [[0.009425163269042969]], [[0.008229255676269531]], [[-0.0031671524047851562]], [[-0.008466958999633789]], [[-0.018948793411254883]], [[0.0007543563842773438]], [[0.03905987739562988]], [[0.2978188991546631]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.013175010681152344]], [[-0.0035600662231445312]], [[0.0078582763671875]], [[-0.011157751083374023]], [[0.011084556579589844]], [[0.005335807800292969]], [[-0.0007183551788330078]], [[-0.003147125244140625]], [[-0.0016930103302001953]], [[0.058348894119262695]], [[0.014826297760009766]], [[-0.0009430050849914551]], [[-0.012067317962646484]], [[0.007509708404541016]], [[0.016254425048828125]], [[0.0028107762336730957]], [[0.2469182014465332]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.01700592041015625]], [[0.00593256950378418]], [[-0.013852119445800781]], [[-0.012873172760009766]], [[0.012081146240234375]], [[0.0049533843994140625]], [[-0.0012993812561035156]], [[-0.018403053283691406]], [[0.0021125078201293945]], [[0.11144781112670898]], [[0.01554107666015625]], [[-0.002071082592010498]], [[-0.013031482696533203]], [[0.0013065338134765625]], [[0.013696670532226562]], [[0.013261556625366211]], [[0.2521376609802246]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.012661933898925781]], [[0.008759260177612305]], [[0.011384963989257812]], [[-0.01107335090637207]], [[0.009493827819824219]], [[0.006960630416870117]], [[-0.0011841058731079102]], [[-0.0027289390563964844]], [[0.00034928321838378906]], [[0.07842493057250977]], [[0.012987136840820312]], [[-0.0006939470767974854]], [[-0.008067607879638672]], [[-0.01841259002685547]], [[0.00567626953125]], [[0.02353954315185547]], [[0.29103946685791016]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.016347885131835938]], [[0.0025720596313476562]], [[-0.037933349609375]], [[-0.021494388580322266]], [[0.011833667755126953]], [[0.0068280696868896484]], [[-0.002981424331665039]], [[0.00159454345703125]], [[-0.0002281665802001953]], [[0.006194114685058594]], [[0.013964653015136719]], [[-0.0015254020690917969]], [[-0.012606620788574219]], [[-0.019949674606323242]], [[0.013515472412109375]], [[-0.00555148720741272]], [[0.39985203742980957]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.02917766571044922]], [[-0.008330821990966797]], [[-0.03006744384765625]], [[-0.005756378173828125]], [[0.014564990997314453]], [[0.007142066955566406]], [[0.0005151033401489258]], [[-0.003665447235107422]], [[-0.0029764175415039062]], [[0.03528428077697754]], [[0.013267993927001953]], [[-0.0016202926635742188]], [[-0.008514165878295898]], [[-0.022026538848876953]], [[-6.771087646484375e-05]], [[0.006811380386352539]], [[0.17435812950134277]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fc7b1db38e0>"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_feature_direction_display(wrong_sentences, original_feature.to(device), entire_feature_direction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-47a72fc4-4017\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-47a72fc4-4017\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"Then\", \",\", \" Richard\", \" and\", \" Jennifer\", \" were\", \" working\", \" at\", \" the\", \" plateau\", \".\", \" Jennifer\", \" decided\", \" to\", \" give\", \" a\", \" feather\", \" to\", \" Richard\", \"\\n\", \"Then\", \",\", \" Laura\", \" and\", \" Catherine\", \" were\", \" working\", \" at\", \" the\", \" cafe\", \".\", \" Catherine\", \" decided\", \" to\", \" give\", \" a\", \" towel\", \" to\", \" Laura\", \"\\n\", \"Then\", \",\", \" Parker\", \" and\", \" Jake\", \" were\", \" working\", \" at\", \" the\", \" glacier\", \".\", \" Jake\", \" decided\", \" to\", \" give\", \" fins\", \" to\", \" Parker\", \"\\n\", \"Then\", \",\", \" Tim\", \" and\", \" Wyatt\", \" were\", \" working\", \" at\", \" the\", \" garage\", \".\", \" Wyatt\", \" decided\", \" to\", \" give\", \" a\", \" bible\", \" to\", \" Tim\", \"\\n\", \"Then\", \",\", \" Sam\", \" and\", \" Peter\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Peter\", \" decided\", \" to\", \" give\", \" a\", \" remote\", \" to\", \" Sam\", \"\\n\", \"Then\", \",\", \" Ross\", \" and\", \" Jason\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Jason\", \" decided\", \" to\", \" give\", \" a\", \" chalk\", \" to\", \" Ross\", \"\\n\", \"Then\", \",\", \" Nathan\", \" and\", \" Eva\", \" were\", \" working\", \" at\", \" the\", \" cafe\", \".\", \" Eva\", \" decided\", \" to\", \" give\", \" a\", \" vinyl\", \" to\", \" Nathan\", \"\\n\", \"Then\", \",\", \" Matt\", \" and\", \" Evan\", \" were\", \" working\", \" at\", \" the\", \" stadium\", \".\", \" Evan\", \" decided\", \" to\", \" give\", \" a\", \" crate\", \" to\", \" Matt\", \"\\n\", \"Then\", \",\", \" Taylor\", \" and\", \" Grant\", \" were\", \" working\", \" at\", \" the\", \" lounge\", \".\", \" Taylor\", \" decided\", \" to\", \" give\", \" a\", \" shorts\", \" to\", \" Grant\", \"\\n\", \"Then\", \",\", \" Jake\", \" and\", \" Kate\", \" were\", \" working\", \" at\", \" the\", \" synagogue\", \".\", \" Jake\", \" decided\", \" to\", \" give\", \" a\", \" backpack\", \" to\", \" Kate\", \"\\n\", \"Then\", \",\", \" Julia\", \" and\", \" Rose\", \" were\", \" working\", \" at\", \" the\", \" museum\", \".\", \" Julia\", \" decided\", \" to\", \" give\", \" a\", \" wrench\", \" to\", \" Rose\", \"\\n\", \"Then\", \",\", \" Jennifer\", \" and\", \" Brooklyn\", \" were\", \" working\", \" at\", \" the\", \" fortress\", \".\", \" Jennifer\", \" decided\", \" to\", \" give\", \" a\", \" tape\", \" to\", \" Brooklyn\", \"\\n\", \"Then\", \",\", \" Mason\", \" and\", \" Jeff\", \" were\", \" working\", \" at\", \" the\", \" street\", \".\", \" Mason\", \" decided\", \" to\", \" give\", \" a\", \" vinyl\", \" to\", \" Jeff\", \"\\n\", \"Then\", \",\", \" Richard\", \" and\", \" Jean\", \" were\", \" working\", \" at\", \" the\", \" cottage\", \".\", \" Richard\", \" decided\", \" to\", \" give\", \" a\", \" lipstick\", \" to\", \" Jean\", \"\\n\", \"Then\", \",\", \" Ross\", \" and\", \" Elijah\", \" were\", \" working\", \" at\", \" the\", \" home\", \".\", \" Ross\", \" decided\", \" to\", \" give\", \" a\", \" flag\", \" to\", \" Elijah\", \"\\n\", \"Then\", \",\", \" Taylor\", \" and\", \" Matt\", \" were\", \" working\", \" at\", \" the\", \" palace\", \".\", \" Taylor\", \" decided\", \" to\", \" give\", \" a\", \" bookmark\", \" to\", \" Matt\", \"\\n\", \"Then\", \",\", \" Molly\", \" and\", \" Keith\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Molly\", \" decided\", \" to\", \" give\", \" a\", \" baseball\", \" to\", \" Keith\", \"\\n\", \"Then\", \",\", \" Parker\", \" and\", \" Dean\", \" were\", \" working\", \" at\", \" the\", \" tunnel\", \".\", \" Parker\", \" decided\", \" to\", \" give\", \" a\", \" tablet\", \" to\", \" Dean\", \"\\n\", \"Then\", \",\", \" Kevin\", \" and\", \" Connor\", \" were\", \" working\", \" at\", \" the\", \" harbor\", \".\", \" Kevin\", \" decided\", \" to\", \" give\", \" a\", \" bakery\", \" to\", \" Connor\", \"\\n\", \"Then\", \",\", \" Matt\", \" and\", \" Riley\", \" were\", \" working\", \" at\", \" the\", \" garden\", \".\", \" Matt\", \" decided\", \" to\", \" give\", \" a\", \" charcoal\", \" to\", \" Riley\", \"\\n\", \"Then\", \",\", \" Keith\", \" and\", \" Joy\", \" were\", \" working\", \" at\", \" the\", \" plateau\", \".\", \" Keith\", \" decided\", \" to\", \" give\", \" a\", \" ring\", \" to\", \" Joy\", \"\\n\", \"Then\", \",\", \" Ruby\", \" and\", \" Ray\", \" were\", \" working\", \" at\", \" the\", \" brewery\", \".\", \" Ruby\", \" decided\", \" to\", \" give\", \" a\", \" lipstick\", \" to\", \" Ray\", \"\\n\"], \"activations\": [[[0.0022649765014648438]], [[0.00011801719665527344]], [[0.014321327209472656]], [[7.009506225585938e-05]], [[-0.023974895477294922]], [[-0.016510963439941406]], [[0.009851455688476562]], [[0.0043027400970458984]], [[-0.0024045705795288086]], [[-0.0015115737915039062]], [[-0.0013089179992675781]], [[-0.10856199264526367]], [[0.011088848114013672]], [[-0.0005521476268768311]], [[-0.010959625244140625]], [[-0.014956951141357422]], [[0.03501319885253906]], [[-0.019893944263458252]], [[0.023919343948364258]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.01872730255126953]], [[-0.007091045379638672]], [[-0.006995201110839844]], [[-0.013813495635986328]], [[0.008151531219482422]], [[0.0030040740966796875]], [[0.0011625289916992188]], [[0.003097057342529297]], [[0.0011148452758789062]], [[-0.1297447681427002]], [[0.01393890380859375]], [[-0.0015087723731994629]], [[-0.009514808654785156]], [[-0.03609728813171387]], [[-0.030946731567382812]], [[-0.003821134567260742]], [[0.06045246124267578]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.013175010681152344]], [[-0.0035600662231445312]], [[-0.013773918151855469]], [[-0.004466056823730469]], [[0.011275291442871094]], [[0.0044097900390625]], [[-0.000812530517578125]], [[-0.021575927734375]], [[-0.002766132354736328]], [[-0.07112407684326172]], [[0.014347076416015625]], [[-0.0015672743320465088]], [[-0.0088043212890625]], [[-0.011075019836425781]], [[0.0016570091247558594]], [[0.005747318267822266]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.018683433532714844]], [[-0.00786447525024414]], [[0.009722709655761719]], [[-0.013342142105102539]], [[0.010752677917480469]], [[0.007184505462646484]], [[-0.0022569894790649414]], [[0.0028128623962402344]], [[0.00038313865661621094]], [[-0.10992002487182617]], [[0.010116100311279297]], [[-0.002773791551589966]], [[-0.010713577270507812]], [[-0.04602956771850586]], [[0.005580902099609375]], [[-0.0008633732795715332]], [[0.10202610492706299]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.028082847595214844]], [[-0.0020322799682617188]], [[0.010447502136230469]], [[-0.008121967315673828]], [[0.007628440856933594]], [[0.003999948501586914]], [[0.0002855062484741211]], [[0.0005931854248046875]], [[-0.001316070556640625]], [[-0.06950855255126953]], [[0.007730960845947266]], [[-0.0014910697937011719]], [[-0.009915351867675781]], [[-0.031070947647094727]], [[0.02602863311767578]], [[0.0021767616271972656]], [[0.08110427856445312]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.01592254638671875]], [[0.00025844573974609375]], [[-0.012169837951660156]], [[-0.010526180267333984]], [[0.010656356811523438]], [[0.006152629852294922]], [[-0.0032001733779907227]], [[-0.009308815002441406]], [[4.863739013671875e-05]], [[-0.09356284141540527]], [[0.016138553619384766]], [[-0.0017150342464447021]], [[-0.010634899139404297]], [[-0.006658077239990234]], [[-0.011851310729980469]], [[0.03739500045776367]], [[0.06368756294250488]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.01578807830810547]], [[0.007590770721435547]], [[-0.0027709007263183594]], [[-0.012078285217285156]], [[0.012618064880371094]], [[0.0026264190673828125]], [[-0.0025597810745239258]], [[0.009250640869140625]], [[0.0022454261779785156]], [[-0.1028144359588623]], [[0.018222332000732422]], [[-0.0027076303958892822]], [[-0.008693933486938477]], [[-0.01714491844177246]], [[-0.005908012390136719]], [[-0.0069732666015625]], [[0.08079791069030762]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.012661933898925781]], [[0.008759260177612305]], [[0.02038097381591797]], [[-0.010403633117675781]], [[0.009507179260253906]], [[0.007952213287353516]], [[-0.0016335248947143555]], [[-0.01720905303955078]], [[0.003307342529296875]], [[-0.09962677955627441]], [[0.00964212417602539]], [[-0.0012597441673278809]], [[-0.011534690856933594]], [[-0.04120302200317383]], [[0.00015163421630859375]], [[0.0013689994812011719]], [[0.03232818841934204]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.022907257080078125]], [[-0.00055694580078125]], [[0.029809951782226562]], [[-0.013696908950805664]], [[0.012282848358154297]], [[0.0041790008544921875]], [[-0.00041806697845458984]], [[-0.006656646728515625]], [[0.0008301734924316406]], [[0.02951216697692871]], [[0.016957759857177734]], [[-0.002310454845428467]], [[-0.011583328247070312]], [[-0.013662099838256836]], [[-0.0038604736328125]], [[-0.004159688949584961]], [[-0.032101452350616455]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.01132965087890625]], [[-0.00013947486877441406]], [[-0.006052970886230469]], [[-0.009699583053588867]], [[0.009695053100585938]], [[0.0021200180053710938]], [[-0.0006301403045654297]], [[-0.008393287658691406]], [[-0.0038504600524902344]], [[0.04381263256072998]], [[0.005794048309326172]], [[-0.002703368663787842]], [[-0.011276006698608398]], [[0.00262451171875]], [[0.010163307189941406]], [[0.0012625455856323242]], [[-0.017009496688842773]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.015857696533203125]], [[-0.002820253372192383]], [[-0.012377738952636719]], [[-0.01101994514465332]], [[0.010821819305419922]], [[0.004931211471557617]], [[0.001130223274230957]], [[0.0019559860229492188]], [[-0.0013089179992675781]], [[0.04137849807739258]], [[0.01205301284790039]], [[-0.0019567012786865234]], [[-0.010921478271484375]], [[-0.0005609989166259766]], [[-0.038550376892089844]], [[-0.0021667778491973877]], [[-0.04480719566345215]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.013024330139160156]], [[0.0009219646453857422]], [[-0.017861366271972656]], [[-0.020667076110839844]], [[0.00964975357055664]], [[0.0030264854431152344]], [[-0.0035687685012817383]], [[-0.013444900512695312]], [[-0.0029524564743041992]], [[0.05920052528381348]], [[0.013521194458007812]], [[-0.0002620816230773926]], [[-0.011551856994628906]], [[-0.0073010921478271484]], [[-0.0006237030029296875]], [[0.005793869495391846]], [[-0.051348090171813965]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.01718616485595703]], [[-0.004257917404174805]], [[0.02179431915283203]], [[-0.012546777725219727]], [[0.010365486145019531]], [[0.005730867385864258]], [[-0.002299070358276367]], [[0.0070514678955078125]], [[0.023110389709472656]], [[0.04694032669067383]], [[0.013448715209960938]], [[-0.003868997097015381]], [[-0.013043403625488281]], [[-0.017963409423828125]], [[0.0026350021362304688]], [[0.002119302749633789]], [[-0.010319530963897705]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.014321327209472656]], [[7.009506225585938e-05]], [[-0.014755725860595703]], [[-0.01851820945739746]], [[0.008883953094482422]], [[0.004275321960449219]], [[-9.191036224365234e-05]], [[0.012018680572509766]], [[0.0008862018585205078]], [[0.06594204902648926]], [[0.012050628662109375]], [[-0.0016400814056396484]], [[-0.009138822555541992]], [[-0.00931406021118164]], [[-0.008419990539550781]], [[0.0022276639938354492]], [[-0.04158884286880493]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.01592254638671875]], [[0.00025844573974609375]], [[-0.005198478698730469]], [[-0.014854669570922852]], [[0.008595943450927734]], [[0.004681825637817383]], [[-0.001619577407836914]], [[0.026288509368896484]], [[0.009806632995605469]], [[0.06873655319213867]], [[0.012034416198730469]], [[-0.0024697482585906982]], [[-0.007423877716064453]], [[-0.0038962364196777344]], [[0.016099929809570312]], [[-0.000938117504119873]], [[-0.0280342698097229]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.022907257080078125]], [[-0.00055694580078125]], [[-0.010260581970214844]], [[-0.0031325817108154297]], [[0.011211872100830078]], [[0.005429506301879883]], [[0.0008275508880615234]], [[0.00042438507080078125]], [[-0.0007009506225585938]], [[0.04439973831176758]], [[0.01668548583984375]], [[-0.002846956253051758]], [[-0.013667821884155273]], [[-0.005007743835449219]], [[0.011074066162109375]], [[-0.001708388328552246]], [[-0.056070804595947266]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.011763572692871094]], [[-0.006783485412597656]], [[-0.006911754608154297]], [[-0.014008045196533203]], [[0.009936332702636719]], [[0.002489328384399414]], [[0.00033915042877197266]], [[-0.015419960021972656]], [[-0.0006580352783203125]], [[0.009425163269042969]], [[0.008229255676269531]], [[-0.0031671524047851562]], [[-0.008466958999633789]], [[-0.018948793411254883]], [[0.0007543563842773438]], [[0.03905987739562988]], [[-0.10934460163116455]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.013175010681152344]], [[-0.0035600662231445312]], [[0.0078582763671875]], [[-0.011157751083374023]], [[0.011084556579589844]], [[0.005335807800292969]], [[-0.0007183551788330078]], [[-0.003147125244140625]], [[-0.0016930103302001953]], [[0.058348894119262695]], [[0.014826297760009766]], [[-0.0009430050849914551]], [[-0.012067317962646484]], [[0.007509708404541016]], [[0.016254425048828125]], [[0.0028107762336730957]], [[-0.043535828590393066]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.01700592041015625]], [[0.00593256950378418]], [[-0.013852119445800781]], [[-0.012873172760009766]], [[0.012081146240234375]], [[0.0049533843994140625]], [[-0.0012993812561035156]], [[-0.018403053283691406]], [[0.0021125078201293945]], [[0.11144781112670898]], [[0.01554107666015625]], [[-0.002071082592010498]], [[-0.013031482696533203]], [[0.0013065338134765625]], [[0.013696670532226562]], [[0.013261556625366211]], [[-0.09073305130004883]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.012661933898925781]], [[0.008759260177612305]], [[0.011384963989257812]], [[-0.01107335090637207]], [[0.009493827819824219]], [[0.006960630416870117]], [[-0.0011841058731079102]], [[-0.0027289390563964844]], [[0.00034928321838378906]], [[0.07842493057250977]], [[0.012987136840820312]], [[-0.0006939470767974854]], [[-0.008067607879638672]], [[-0.01841259002685547]], [[0.00567626953125]], [[0.02353954315185547]], [[-0.0880744457244873]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.016347885131835938]], [[0.0025720596313476562]], [[-0.037933349609375]], [[-0.021494388580322266]], [[0.011833667755126953]], [[0.0068280696868896484]], [[-0.002981424331665039]], [[0.00159454345703125]], [[-0.0002281665802001953]], [[0.006194114685058594]], [[0.013964653015136719]], [[-0.0015254020690917969]], [[-0.012606620788574219]], [[-0.019949674606323242]], [[0.013515472412109375]], [[-0.00555148720741272]], [[-0.1015547513961792]], [[0.0]], [[0.0022649765014648438]], [[0.00011801719665527344]], [[0.02917766571044922]], [[-0.008330821990966797]], [[-0.03006744384765625]], [[-0.005756378173828125]], [[0.014564990997314453]], [[0.007142066955566406]], [[0.0005151033401489258]], [[-0.003665447235107422]], [[-0.0029764175415039062]], [[0.03528428077697754]], [[0.013267993927001953]], [[-0.0016202926635742188]], [[-0.008514165878295898]], [[-0.022026538848876953]], [[-6.771087646484375e-05]], [[0.006811380386352539]], [[-0.04275327920913696]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fc7b195fd00>"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_feature_direction_display(ex_sent_combined, original_feature.to(device), entire_feature_direction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-eee159ab-3ffd\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-eee159ab-3ffd\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"Then\", \",\", \" Richard\", \" and\", \" Jennifer\", \" were\", \" working\", \" at\", \" the\", \" plateau\", \".\", \" Jennifer\", \" decided\", \" to\", \" give\", \" a\", \" feather\", \" to\", \" Jennifer\", \"\\n\", \"Then\", \",\", \" Laura\", \" and\", \" Catherine\", \" were\", \" working\", \" at\", \" the\", \" cafe\", \".\", \" Catherine\", \" decided\", \" to\", \" give\", \" a\", \" towel\", \" to\", \" Catherine\", \"\\n\", \"Then\", \",\", \" Parker\", \" and\", \" Jake\", \" were\", \" working\", \" at\", \" the\", \" glacier\", \".\", \" Jake\", \" decided\", \" to\", \" give\", \" fins\", \" to\", \" Jake\", \"\\n\", \"Then\", \",\", \" Tim\", \" and\", \" Wyatt\", \" were\", \" working\", \" at\", \" the\", \" garage\", \".\", \" Wyatt\", \" decided\", \" to\", \" give\", \" a\", \" bible\", \" to\", \" Wyatt\", \"\\n\", \"Then\", \",\", \" Sam\", \" and\", \" Peter\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Peter\", \" decided\", \" to\", \" give\", \" a\", \" remote\", \" to\", \" Peter\", \"\\n\", \"Then\", \",\", \" Ross\", \" and\", \" Jason\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Jason\", \" decided\", \" to\", \" give\", \" a\", \" chalk\", \" to\", \" Jason\", \"\\n\", \"Then\", \",\", \" Nathan\", \" and\", \" Eva\", \" were\", \" working\", \" at\", \" the\", \" cafe\", \".\", \" Eva\", \" decided\", \" to\", \" give\", \" a\", \" vinyl\", \" to\", \" Eva\", \"\\n\", \"Then\", \",\", \" Matt\", \" and\", \" Evan\", \" were\", \" working\", \" at\", \" the\", \" stadium\", \".\", \" Evan\", \" decided\", \" to\", \" give\", \" a\", \" crate\", \" to\", \" Evan\", \"\\n\", \"Then\", \",\", \" Taylor\", \" and\", \" Grant\", \" were\", \" working\", \" at\", \" the\", \" lounge\", \".\", \" Taylor\", \" decided\", \" to\", \" give\", \" a\", \" shorts\", \" to\", \" Taylor\", \"\\n\", \"Then\", \",\", \" Jake\", \" and\", \" Kate\", \" were\", \" working\", \" at\", \" the\", \" synagogue\", \".\", \" Jake\", \" decided\", \" to\", \" give\", \" a\", \" backpack\", \" to\", \" Jake\", \"\\n\", \"Then\", \",\", \" Julia\", \" and\", \" Rose\", \" were\", \" working\", \" at\", \" the\", \" museum\", \".\", \" Julia\", \" decided\", \" to\", \" give\", \" a\", \" wrench\", \" to\", \" Julia\", \"\\n\", \"Then\", \",\", \" Jennifer\", \" and\", \" Brooklyn\", \" were\", \" working\", \" at\", \" the\", \" fortress\", \".\", \" Jennifer\", \" decided\", \" to\", \" give\", \" a\", \" tape\", \" to\", \" Jennifer\", \"\\n\", \"Then\", \",\", \" Mason\", \" and\", \" Jeff\", \" were\", \" working\", \" at\", \" the\", \" street\", \".\", \" Mason\", \" decided\", \" to\", \" give\", \" a\", \" vinyl\", \" to\", \" Mason\", \"\\n\", \"Then\", \",\", \" Richard\", \" and\", \" Jean\", \" were\", \" working\", \" at\", \" the\", \" cottage\", \".\", \" Richard\", \" decided\", \" to\", \" give\", \" a\", \" lipstick\", \" to\", \" Richard\", \"\\n\", \"Then\", \",\", \" Ross\", \" and\", \" Elijah\", \" were\", \" working\", \" at\", \" the\", \" home\", \".\", \" Ross\", \" decided\", \" to\", \" give\", \" a\", \" flag\", \" to\", \" Ross\", \"\\n\", \"Then\", \",\", \" Taylor\", \" and\", \" Matt\", \" were\", \" working\", \" at\", \" the\", \" palace\", \".\", \" Taylor\", \" decided\", \" to\", \" give\", \" a\", \" bookmark\", \" to\", \" Taylor\", \"\\n\", \"Then\", \",\", \" Molly\", \" and\", \" Keith\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Molly\", \" decided\", \" to\", \" give\", \" a\", \" baseball\", \" to\", \" Molly\", \"\\n\", \"Then\", \",\", \" Parker\", \" and\", \" Dean\", \" were\", \" working\", \" at\", \" the\", \" tunnel\", \".\", \" Parker\", \" decided\", \" to\", \" give\", \" a\", \" tablet\", \" to\", \" Parker\", \"\\n\", \"Then\", \",\", \" Kevin\", \" and\", \" Connor\", \" were\", \" working\", \" at\", \" the\", \" harbor\", \".\", \" Kevin\", \" decided\", \" to\", \" give\", \" a\", \" bakery\", \" to\", \" Kevin\", \"\\n\", \"Then\", \",\", \" Matt\", \" and\", \" Riley\", \" were\", \" working\", \" at\", \" the\", \" garden\", \".\", \" Matt\", \" decided\", \" to\", \" give\", \" a\", \" charcoal\", \" to\", \" Matt\", \"\\n\", \"Then\", \",\", \" Keith\", \" and\", \" Joy\", \" were\", \" working\", \" at\", \" the\", \" plateau\", \".\", \" Keith\", \" decided\", \" to\", \" give\", \" a\", \" ring\", \" to\", \" Keith\", \"\\n\", \"Then\", \",\", \" Ruby\", \" and\", \" Ray\", \" were\", \" working\", \" at\", \" the\", \" brewery\", \".\", \" Ruby\", \" decided\", \" to\", \" give\", \" a\", \" lipstick\", \" to\", \" Ruby\", \"\\n\"], \"activations\": [[[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.009247779846191406]], [[0.0007658004760742188]], [[0.016803264617919922]], [[0.011093378067016602]], [[-0.019628047943115234]], [[-3.2901763916015625e-05]], [[0.001837015151977539]], [[0.0033044815063476562]], [[0.005516767501831055]], [[0.10762143135070801]], [[-0.012261390686035156]], [[0.0013286769390106201]], [[0.011393547058105469]], [[0.016365528106689453]], [[-0.017081260681152344]], [[0.021907389163970947]], [[0.1392383575439453]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.01316070556640625]], [[0.0014023780822753906]], [[0.007470130920410156]], [[0.009952306747436523]], [[-0.019381999969482422]], [[-0.0007786750793457031]], [[-0.0011942386627197266]], [[-0.0002765655517578125]], [[0.00013971328735351562]], [[0.12082839012145996]], [[-0.013309955596923828]], [[0.0023388266563415527]], [[0.011419534683227539]], [[0.033551931381225586]], [[0.03783130645751953]], [[0.0021404922008514404]], [[0.2202138900756836]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.009607315063476562]], [[-0.0019960403442382812]], [[0.014212608337402344]], [[0.0032837390899658203]], [[-0.020415306091308594]], [[-0.0013422966003417969]], [[0.0014297962188720703]], [[0.02442455291748047]], [[0.006117582321166992]], [[0.05711865425109863]], [[-0.015457630157470703]], [[0.002208322286605835]], [[0.008661746978759766]], [[-0.013426780700683594]], [[-0.004119575023651123]], [[0.10112309455871582]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.01732158660888672]], [[0.011085033416748047]], [[-0.010939598083496094]], [[0.010491132736206055]], [[-0.01987743377685547]], [[-0.0018854141235351562]], [[0.0023207664489746094]], [[0.0021800994873046875]], [[0.0015909671783447266]], [[0.09232056140899658]], [[-0.010550498962402344]], [[0.003441333770751953]], [[0.009153127670288086]], [[0.04382753372192383]], [[0.0019617080688476562]], [[0.006902456283569336]], [[0.11238598823547363]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.017066001892089844]], [[0.001993894577026367]], [[-0.008476734161376953]], [[0.004255056381225586]], [[-0.017534732818603516]], [[0.0005655288696289062]], [[-0.00012373924255371094]], [[0.0037212371826171875]], [[0.0017595291137695312]], [[0.0662076473236084]], [[-0.01024627685546875]], [[0.0026969313621520996]], [[0.010120391845703125]], [[0.025124549865722656]], [[-0.021955490112304688]], [[0.008440494537353516]], [[0.08790445327758789]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.02147197723388672]], [[0.0008876323699951172]], [[0.009229660034179688]], [[0.007867813110351562]], [[-0.019464969635009766]], [[-0.0011138916015625]], [[0.0031360387802124023]], [[0.011547088623046875]], [[0.0006070137023925781]], [[0.08781290054321289]], [[-0.0160064697265625]], [[0.002424091100692749]], [[0.010676145553588867]], [[0.005495548248291016]], [[0.014482498168945312]], [[-0.016479015350341797]], [[0.1331310272216797]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.0065364837646484375]], [[-0.005777597427368164]], [[0.002349376678466797]], [[0.008388042449951172]], [[-0.022075176239013672]], [[0.0001125335693359375]], [[0.0026912689208984375]], [[-0.005694389343261719]], [[-0.0008082389831542969]], [[0.10794734954833984]], [[-0.018288612365722656]], [[0.0032509565353393555]], [[0.010331869125366211]], [[0.013713359832763672]], [[0.01100921630859375]], [[0.012032032012939453]], [[0.09969043731689453]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.007439613342285156]], [[-0.005075931549072266]], [[-0.01913166046142578]], [[0.0073664188385009766]], [[-0.018435955047607422]], [[-0.0008940696716308594]], [[0.002507328987121582]], [[0.006819725036621094]], [[-0.0023741722106933594]], [[0.08461451530456543]], [[-0.008712291717529297]], [[0.0019975602626800537]], [[0.010650634765625]], [[0.036767005920410156]], [[0.009669303894042969]], [[0.0037670135498046875]], [[0.1888113021850586]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.02034282684326172]], [[0.0013332366943359375]], [[-0.02660369873046875]], [[0.009872198104858398]], [[-0.020709514617919922]], [[-0.0013456344604492188]], [[0.0008800029754638672]], [[0.009675979614257812]], [[-9.739398956298828e-05]], [[-0.03436899185180664]], [[-0.018611907958984375]], [[0.0034081339836120605]], [[0.012042999267578125]], [[0.010876655578613281]], [[0.017215728759765625]], [[0.005947113037109375]], [[-0.18756604194641113]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.01116943359375]], [[-0.00030612945556640625]], [[0.006428718566894531]], [[0.006392002105712891]], [[-0.019754409790039062]], [[-0.00014090538024902344]], [[0.0013363361358642578]], [[0.007462501525878906]], [[0.005127429962158203]], [[-0.05198836326599121]], [[-0.00840139389038086]], [[0.003511577844619751]], [[0.011258840560913086]], [[-0.006113767623901367]], [[0.0050258636474609375]], [[-0.00233304500579834]], [[-0.27281713485717773]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.0065441131591796875]], [[0.0018672943115234375]], [[0.011795997619628906]], [[0.007526874542236328]], [[-0.02059793472290039]], [[-0.0019593238830566406]], [[-0.0007041692733764648]], [[-0.008683204650878906]], [[0.0015118122100830078]], [[-0.045191049575805664]], [[-0.013236045837402344]], [[0.0027327537536621094]], [[0.010414600372314453]], [[-0.0012023448944091797]], [[0.049696922302246094]], [[0.0012319087982177734]], [[-0.1545124053955078]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.009036064147949219]], [[-0.0009326934814453125]], [[0.020998001098632812]], [[0.016808509826660156]], [[-0.018651962280273438]], [[-0.00019216537475585938]], [[0.003148674964904785]], [[0.010409355163574219]], [[0.00625157356262207]], [[-0.06509041786193848]], [[-0.015455245971679688]], [[0.0011161565780639648]], [[0.010692119598388672]], [[0.010895967483520508]], [[-0.0036420822143554688]], [[-0.0009396076202392578]], [[-0.14978504180908203]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.006804466247558594]], [[-0.004139900207519531]], [[-0.01817178726196289]], [[0.009734153747558594]], [[-0.01930999755859375]], [[-0.0011742115020751953]], [[0.0026663541793823242]], [[0.005658149719238281]], [[-0.003429889678955078]], [[-0.0523984432220459]], [[-0.01198577880859375]], [[0.004336506128311157]], [[0.010843753814697266]], [[0.01544499397277832]], [[0.002796173095703125]], [[0.002397298812866211]], [[-0.2620255947113037]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.009247779846191406]], [[0.0007658004760742188]], [[0.010116100311279297]], [[0.016279935836791992]], [[-0.01910257339477539]], [[-0.00019311904907226562]], [[-0.00020301342010498047]], [[-0.007723808288574219]], [[0.0014355182647705078]], [[-0.07555830478668213]], [[-0.015497207641601562]], [[0.002121150493621826]], [[0.008776187896728516]], [[0.008548498153686523]], [[0.00698089599609375]], [[0.0007287263870239258]], [[-0.2644166946411133]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.02147197723388672]], [[0.0008876323699951172]], [[0.010043144226074219]], [[0.012490272521972656]], [[-0.018543720245361328]], [[-0.0015053749084472656]], [[0.0017731189727783203]], [[-0.021623611450195312]], [[0.003547191619873047]], [[-0.07735133171081543]], [[-0.014828681945800781]], [[0.003099411725997925]], [[0.007646083831787109]], [[0.001992940902709961]], [[-0.008280754089355469]], [[0.000541388988494873]], [[-0.3247995376586914]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.02034282684326172]], [[0.0013332366943359375]], [[0.013556480407714844]], [[0.0013704299926757812]], [[-0.019545555114746094]], [[-0.0009429454803466797]], [[0.0002371072769165039]], [[-0.012751579284667969]], [[0.0019690990447998047]], [[-0.05231475830078125]], [[-0.018962383270263672]], [[0.003988325595855713]], [[0.012134790420532227]], [[0.003938198089599609]], [[-0.012196540832519531]], [[0.0003217458724975586]], [[-0.2034459114074707]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.005137443542480469]], [[0.002249002456665039]], [[0.004068851470947266]], [[0.010364770889282227]], [[-0.01962757110595703]], [[-0.0005543231964111328]], [[-3.5762786865234375e-05]], [[0.017217636108398438]], [[0.0010020732879638672]], [[-0.02001631259918213]], [[-0.011124610900878906]], [[0.004037141799926758]], [[0.008877992630004883]], [[0.019156455993652344]], [[0.007801055908203125]], [[-0.03526449203491211]], [[-0.2977151870727539]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.009607315063476562]], [[-0.0019960403442382812]], [[-0.002766132354736328]], [[0.008496284484863281]], [[-0.01979827880859375]], [[-0.002086162567138672]], [[0.0009323358535766602]], [[0.001644134521484375]], [[0.00272214412689209]], [[-0.06221151351928711]], [[-0.016727924346923828]], [[0.0018984079360961914]], [[0.00856637954711914]], [[-0.007281303405761719]], [[-0.015350341796875]], [[-0.0021902918815612793]], [[-0.24250507354736328]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.015855789184570312]], [[-0.0019540786743164062]], [[0.006386756896972656]], [[0.011027812957763672]], [[-0.020549774169921875]], [[-0.0009355545043945312]], [[0.0014362335205078125]], [[0.013365745544433594]], [[-0.0006524324417114258]], [[-0.11760616302490234]], [[-0.016284942626953125]], [[0.0029276013374328613]], [[0.011475086212158203]], [[-0.0035343170166015625]], [[-0.0002117156982421875]], [[-0.00893259048461914]], [[-0.23595523834228516]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.007439613342285156]], [[-0.005075931549072266]], [[-0.012537002563476562]], [[0.008638381958007812]], [[-0.01789569854736328]], [[-0.0007693767547607422]], [[0.0020090341567993164]], [[0.008683204650878906]], [[0.00504302978515625]], [[-0.08537983894348145]], [[-0.014393806457519531]], [[0.0016465485095977783]], [[0.007297039031982422]], [[0.017507553100585938]], [[-0.005845069885253906]], [[-0.01611804962158203]], [[-0.2644691467285156]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.015636444091796875]], [[-0.0016813278198242188]], [[0.0364227294921875]], [[0.013523578643798828]], [[-0.021110057830810547]], [[-0.0023009777069091797]], [[0.0030364990234375]], [[0.0002307891845703125]], [[0.0033447742462158203]], [[-0.012643575668334961]], [[-0.015563011169433594]], [[0.002655118703842163]], [[0.011510372161865234]], [[0.01946425437927246]], [[-0.006046295166015625]], [[0.003507256507873535]], [[-0.41709327697753906]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.03124713897705078]], [[0.002218484878540039]], [[0.022492408752441406]], [[0.004976987838745117]], [[-0.022983074188232422]], [[-0.0017428398132324219]], [[0.00036013126373291016]], [[-0.0023679733276367188]], [[0.003210783004760742]], [[-0.04209887981414795]], [[-0.015637874603271484]], [[0.0019336938858032227]], [[0.008495092391967773]], [[0.019115447998046875]], [[-0.0039691925048828125]], [[-0.003906726837158203]], [[-0.17710518836975098]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fc7b195f9d0>"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_feature_direction_display(wrong_sentences, torch.tensor(original_feature_2).to(device), entire_feature_direction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-3b91d59c-f5c6\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-3b91d59c-f5c6\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"Then\", \",\", \" Richard\", \" and\", \" Jennifer\", \" were\", \" working\", \" at\", \" the\", \" plateau\", \".\", \" Jennifer\", \" decided\", \" to\", \" give\", \" a\", \" feather\", \" to\", \" Richard\", \"\\n\", \"Then\", \",\", \" Laura\", \" and\", \" Catherine\", \" were\", \" working\", \" at\", \" the\", \" cafe\", \".\", \" Catherine\", \" decided\", \" to\", \" give\", \" a\", \" towel\", \" to\", \" Laura\", \"\\n\", \"Then\", \",\", \" Parker\", \" and\", \" Jake\", \" were\", \" working\", \" at\", \" the\", \" glacier\", \".\", \" Jake\", \" decided\", \" to\", \" give\", \" fins\", \" to\", \" Parker\", \"\\n\", \"Then\", \",\", \" Tim\", \" and\", \" Wyatt\", \" were\", \" working\", \" at\", \" the\", \" garage\", \".\", \" Wyatt\", \" decided\", \" to\", \" give\", \" a\", \" bible\", \" to\", \" Tim\", \"\\n\", \"Then\", \",\", \" Sam\", \" and\", \" Peter\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Peter\", \" decided\", \" to\", \" give\", \" a\", \" remote\", \" to\", \" Sam\", \"\\n\", \"Then\", \",\", \" Ross\", \" and\", \" Jason\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Jason\", \" decided\", \" to\", \" give\", \" a\", \" chalk\", \" to\", \" Ross\", \"\\n\", \"Then\", \",\", \" Nathan\", \" and\", \" Eva\", \" were\", \" working\", \" at\", \" the\", \" cafe\", \".\", \" Eva\", \" decided\", \" to\", \" give\", \" a\", \" vinyl\", \" to\", \" Nathan\", \"\\n\", \"Then\", \",\", \" Matt\", \" and\", \" Evan\", \" were\", \" working\", \" at\", \" the\", \" stadium\", \".\", \" Evan\", \" decided\", \" to\", \" give\", \" a\", \" crate\", \" to\", \" Matt\", \"\\n\", \"Then\", \",\", \" Taylor\", \" and\", \" Grant\", \" were\", \" working\", \" at\", \" the\", \" lounge\", \".\", \" Taylor\", \" decided\", \" to\", \" give\", \" a\", \" shorts\", \" to\", \" Grant\", \"\\n\", \"Then\", \",\", \" Jake\", \" and\", \" Kate\", \" were\", \" working\", \" at\", \" the\", \" synagogue\", \".\", \" Jake\", \" decided\", \" to\", \" give\", \" a\", \" backpack\", \" to\", \" Kate\", \"\\n\", \"Then\", \",\", \" Julia\", \" and\", \" Rose\", \" were\", \" working\", \" at\", \" the\", \" museum\", \".\", \" Julia\", \" decided\", \" to\", \" give\", \" a\", \" wrench\", \" to\", \" Rose\", \"\\n\", \"Then\", \",\", \" Jennifer\", \" and\", \" Brooklyn\", \" were\", \" working\", \" at\", \" the\", \" fortress\", \".\", \" Jennifer\", \" decided\", \" to\", \" give\", \" a\", \" tape\", \" to\", \" Brooklyn\", \"\\n\", \"Then\", \",\", \" Mason\", \" and\", \" Jeff\", \" were\", \" working\", \" at\", \" the\", \" street\", \".\", \" Mason\", \" decided\", \" to\", \" give\", \" a\", \" vinyl\", \" to\", \" Jeff\", \"\\n\", \"Then\", \",\", \" Richard\", \" and\", \" Jean\", \" were\", \" working\", \" at\", \" the\", \" cottage\", \".\", \" Richard\", \" decided\", \" to\", \" give\", \" a\", \" lipstick\", \" to\", \" Jean\", \"\\n\", \"Then\", \",\", \" Ross\", \" and\", \" Elijah\", \" were\", \" working\", \" at\", \" the\", \" home\", \".\", \" Ross\", \" decided\", \" to\", \" give\", \" a\", \" flag\", \" to\", \" Elijah\", \"\\n\", \"Then\", \",\", \" Taylor\", \" and\", \" Matt\", \" were\", \" working\", \" at\", \" the\", \" palace\", \".\", \" Taylor\", \" decided\", \" to\", \" give\", \" a\", \" bookmark\", \" to\", \" Matt\", \"\\n\", \"Then\", \",\", \" Molly\", \" and\", \" Keith\", \" were\", \" working\", \" at\", \" the\", \" chapel\", \".\", \" Molly\", \" decided\", \" to\", \" give\", \" a\", \" baseball\", \" to\", \" Keith\", \"\\n\", \"Then\", \",\", \" Parker\", \" and\", \" Dean\", \" were\", \" working\", \" at\", \" the\", \" tunnel\", \".\", \" Parker\", \" decided\", \" to\", \" give\", \" a\", \" tablet\", \" to\", \" Dean\", \"\\n\", \"Then\", \",\", \" Kevin\", \" and\", \" Connor\", \" were\", \" working\", \" at\", \" the\", \" harbor\", \".\", \" Kevin\", \" decided\", \" to\", \" give\", \" a\", \" bakery\", \" to\", \" Connor\", \"\\n\", \"Then\", \",\", \" Matt\", \" and\", \" Riley\", \" were\", \" working\", \" at\", \" the\", \" garden\", \".\", \" Matt\", \" decided\", \" to\", \" give\", \" a\", \" charcoal\", \" to\", \" Riley\", \"\\n\", \"Then\", \",\", \" Keith\", \" and\", \" Joy\", \" were\", \" working\", \" at\", \" the\", \" plateau\", \".\", \" Keith\", \" decided\", \" to\", \" give\", \" a\", \" ring\", \" to\", \" Joy\", \"\\n\", \"Then\", \",\", \" Ruby\", \" and\", \" Ray\", \" were\", \" working\", \" at\", \" the\", \" brewery\", \".\", \" Ruby\", \" decided\", \" to\", \" give\", \" a\", \" lipstick\", \" to\", \" Ray\", \"\\n\"], \"activations\": [[[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.009247779846191406]], [[0.0007658004760742188]], [[0.016803264617919922]], [[0.011093378067016602]], [[-0.019628047943115234]], [[-3.2901763916015625e-05]], [[0.001837015151977539]], [[0.0033044815063476562]], [[0.005516767501831055]], [[0.10762143135070801]], [[-0.012261390686035156]], [[0.0013286769390106201]], [[0.011393547058105469]], [[0.016365528106689453]], [[-0.017081260681152344]], [[0.021907389163970947]], [[-0.022024035453796387]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.01316070556640625]], [[0.0014023780822753906]], [[0.007470130920410156]], [[0.009952306747436523]], [[-0.019381999969482422]], [[-0.0007786750793457031]], [[-0.0011942386627197266]], [[-0.0002765655517578125]], [[0.00013971328735351562]], [[0.12082839012145996]], [[-0.013309955596923828]], [[0.0023388266563415527]], [[0.011419534683227539]], [[0.033551931381225586]], [[0.03783130645751953]], [[0.0021404922008514404]], [[-0.06238448619842529]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.009607315063476562]], [[-0.0019960403442382812]], [[0.014212608337402344]], [[0.0032837390899658203]], [[-0.020415306091308594]], [[-0.0013422966003417969]], [[0.0014297962188720703]], [[0.02442455291748047]], [[0.006117582321166992]], [[0.05711865425109863]], [[-0.015457630157470703]], [[0.002208322286605835]], [[0.008661746978759766]], [[-0.013426780700683594]], [[-0.004119575023651123]], [[-0.010104894638061523]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.01732158660888672]], [[0.011085033416748047]], [[-0.010939598083496094]], [[0.010491132736206055]], [[-0.01987743377685547]], [[-0.0018854141235351562]], [[0.0023207664489746094]], [[0.0021800994873046875]], [[0.0015909671783447266]], [[0.09232056140899658]], [[-0.010550498962402344]], [[0.003441333770751953]], [[0.009153127670288086]], [[0.04382753372192383]], [[0.0019617080688476562]], [[0.006902456283569336]], [[-0.10513675212860107]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.017066001892089844]], [[0.001993894577026367]], [[-0.008476734161376953]], [[0.004255056381225586]], [[-0.017534732818603516]], [[0.0005655288696289062]], [[-0.00012373924255371094]], [[0.0037212371826171875]], [[0.0017595291137695312]], [[0.0662076473236084]], [[-0.01024627685546875]], [[0.0026969313621520996]], [[0.010120391845703125]], [[0.025124549865722656]], [[-0.021955490112304688]], [[0.008440494537353516]], [[-0.07395505905151367]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.02147197723388672]], [[0.0008876323699951172]], [[0.009229660034179688]], [[0.007867813110351562]], [[-0.019464969635009766]], [[-0.0011138916015625]], [[0.0031360387802124023]], [[0.011547088623046875]], [[0.0006070137023925781]], [[0.08781290054321289]], [[-0.0160064697265625]], [[0.002424091100692749]], [[0.010676145553588867]], [[0.005495548248291016]], [[0.014482498168945312]], [[-0.016479015350341797]], [[-0.06355667114257812]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.0065364837646484375]], [[-0.005777597427368164]], [[0.002349376678466797]], [[0.008388042449951172]], [[-0.022075176239013672]], [[0.0001125335693359375]], [[0.0026912689208984375]], [[-0.005694389343261719]], [[-0.0008082389831542969]], [[0.10794734954833984]], [[-0.018288612365722656]], [[0.0032509565353393555]], [[0.010331869125366211]], [[0.013713359832763672]], [[0.01100921630859375]], [[0.012032032012939453]], [[-0.06974399089813232]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.007439613342285156]], [[-0.005075931549072266]], [[-0.01913166046142578]], [[0.0073664188385009766]], [[-0.018435955047607422]], [[-0.0008940696716308594]], [[0.002507328987121582]], [[0.006819725036621094]], [[-0.0023741722106933594]], [[0.08461451530456543]], [[-0.008712291717529297]], [[0.0019975602626800537]], [[0.010650634765625]], [[0.036767005920410156]], [[0.009669303894042969]], [[0.0037670135498046875]], [[-0.025812804698944092]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.02034282684326172]], [[0.0013332366943359375]], [[-0.02660369873046875]], [[0.009872198104858398]], [[-0.020709514617919922]], [[-0.0013456344604492188]], [[0.0008800029754638672]], [[0.009675979614257812]], [[-9.739398956298828e-05]], [[-0.03436899185180664]], [[-0.018611907958984375]], [[0.0034081339836120605]], [[0.012042999267578125]], [[0.010876655578613281]], [[0.017215728759765625]], [[0.005947113037109375]], [[0.028792142868041992]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.01116943359375]], [[-0.00030612945556640625]], [[0.006428718566894531]], [[0.006392002105712891]], [[-0.019754409790039062]], [[-0.00014090538024902344]], [[0.0013363361358642578]], [[0.007462501525878906]], [[0.005127429962158203]], [[-0.05198836326599121]], [[-0.00840139389038086]], [[0.003511577844619751]], [[0.011258840560913086]], [[-0.006113767623901367]], [[0.0050258636474609375]], [[-0.00233304500579834]], [[0.015387773513793945]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.0065441131591796875]], [[0.0018672943115234375]], [[0.011795997619628906]], [[0.007526874542236328]], [[-0.02059793472290039]], [[-0.0019593238830566406]], [[-0.0007041692733764648]], [[-0.008683204650878906]], [[0.0015118122100830078]], [[-0.045191049575805664]], [[-0.013236045837402344]], [[0.0027327537536621094]], [[0.010414600372314453]], [[-0.0012023448944091797]], [[0.049696922302246094]], [[0.0012319087982177734]], [[0.05402374267578125]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.009036064147949219]], [[-0.0009326934814453125]], [[0.020998001098632812]], [[0.016808509826660156]], [[-0.018651962280273438]], [[-0.00019216537475585938]], [[0.003148674964904785]], [[0.010409355163574219]], [[0.00625157356262207]], [[-0.06509041786193848]], [[-0.015455245971679688]], [[0.0011161565780639648]], [[0.010692119598388672]], [[0.010895967483520508]], [[-0.0036420822143554688]], [[-0.0009396076202392578]], [[0.05052018165588379]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.006804466247558594]], [[-0.004139900207519531]], [[-0.01817178726196289]], [[0.009734153747558594]], [[-0.01930999755859375]], [[-0.0011742115020751953]], [[0.0026663541793823242]], [[0.005658149719238281]], [[-0.003429889678955078]], [[-0.0523984432220459]], [[-0.01198577880859375]], [[0.004336506128311157]], [[0.010843753814697266]], [[0.01544499397277832]], [[0.002796173095703125]], [[0.002397298812866211]], [[0.013979971408843994]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.009247779846191406]], [[0.0007658004760742188]], [[0.010116100311279297]], [[0.016279935836791992]], [[-0.01910257339477539]], [[-0.00019311904907226562]], [[-0.00020301342010498047]], [[-0.007723808288574219]], [[0.0014355182647705078]], [[-0.07555830478668213]], [[-0.015497207641601562]], [[0.002121150493621826]], [[0.008776187896728516]], [[0.008548498153686523]], [[0.00698089599609375]], [[0.0007287263870239258]], [[0.04169750213623047]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.02147197723388672]], [[0.0008876323699951172]], [[0.010043144226074219]], [[0.012490272521972656]], [[-0.018543720245361328]], [[-0.0015053749084472656]], [[0.0017731189727783203]], [[-0.021623611450195312]], [[0.003547191619873047]], [[-0.07735133171081543]], [[-0.014828681945800781]], [[0.003099411725997925]], [[0.007646083831787109]], [[0.001992940902709961]], [[-0.008280754089355469]], [[0.000541388988494873]], [[0.031243205070495605]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.02034282684326172]], [[0.0013332366943359375]], [[0.013556480407714844]], [[0.0013704299926757812]], [[-0.019545555114746094]], [[-0.0009429454803466797]], [[0.0002371072769165039]], [[-0.012751579284667969]], [[0.0019690990447998047]], [[-0.05231475830078125]], [[-0.018962383270263672]], [[0.003988325595855713]], [[0.012134790420532227]], [[0.003938198089599609]], [[-0.012196540832519531]], [[0.0003217458724975586]], [[0.055279314517974854]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.005137443542480469]], [[0.002249002456665039]], [[0.004068851470947266]], [[0.010364770889282227]], [[-0.01962757110595703]], [[-0.0005543231964111328]], [[-3.5762786865234375e-05]], [[0.017217636108398438]], [[0.0010020732879638672]], [[-0.02001631259918213]], [[-0.011124610900878906]], [[0.004037141799926758]], [[0.008877992630004883]], [[0.019156455993652344]], [[0.007801055908203125]], [[-0.03526449203491211]], [[0.09618109464645386]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.009607315063476562]], [[-0.0019960403442382812]], [[-0.002766132354736328]], [[0.008496284484863281]], [[-0.01979827880859375]], [[-0.002086162567138672]], [[0.0009323358535766602]], [[0.001644134521484375]], [[0.00272214412689209]], [[-0.06221151351928711]], [[-0.016727924346923828]], [[0.0018984079360961914]], [[0.00856637954711914]], [[-0.007281303405761719]], [[-0.015350341796875]], [[-0.0021902918815612793]], [[0.04245847463607788]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.015855789184570312]], [[-0.0019540786743164062]], [[0.006386756896972656]], [[0.011027812957763672]], [[-0.020549774169921875]], [[-0.0009355545043945312]], [[0.0014362335205078125]], [[0.013365745544433594]], [[-0.0006524324417114258]], [[-0.11760616302490234]], [[-0.016284942626953125]], [[0.0029276013374328613]], [[0.011475086212158203]], [[-0.0035343170166015625]], [[-0.0002117156982421875]], [[-0.00893259048461914]], [[0.08667588233947754]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.007439613342285156]], [[-0.005075931549072266]], [[-0.012537002563476562]], [[0.008638381958007812]], [[-0.01789569854736328]], [[-0.0007693767547607422]], [[0.0020090341567993164]], [[0.008683204650878906]], [[0.00504302978515625]], [[-0.08537983894348145]], [[-0.014393806457519531]], [[0.0016465485095977783]], [[0.007297039031982422]], [[0.017507553100585938]], [[-0.005845069885253906]], [[-0.01611804962158203]], [[0.09379434585571289]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.015636444091796875]], [[-0.0016813278198242188]], [[0.0364227294921875]], [[0.013523578643798828]], [[-0.021110057830810547]], [[-0.0023009777069091797]], [[0.0030364990234375]], [[0.0002307891845703125]], [[0.0033447742462158203]], [[-0.012643575668334961]], [[-0.015563011169433594]], [[0.002655118703842163]], [[0.011510372161865234]], [[0.01946425437927246]], [[-0.006046295166015625]], [[0.003507256507873535]], [[0.0969952940940857]], [[0.0]], [[-0.0018129348754882812]], [[-0.0008505582809448242]], [[-0.03124713897705078]], [[0.002218484878540039]], [[0.022492408752441406]], [[0.004976987838745117]], [[-0.022983074188232422]], [[-0.0017428398132324219]], [[0.00036013126373291016]], [[-0.0023679733276367188]], [[0.003210783004760742]], [[-0.04209887981414795]], [[-0.015637874603271484]], [[0.0019336938858032227]], [[0.008495092391967773]], [[0.019115447998046875]], [[-0.0039691925048828125]], [[-0.003906726837158203]], [[0.04265564680099487]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fc7b1db3f40>"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_feature_direction_display(ex_sent_combined, torch.tensor(original_feature_2).to(device), entire_feature_direction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-27f082f6-d770\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-27f082f6-d770\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"Val\", \"encia\", \",\", \" CA\", \" 2\", \":\", \"43\", \" am\", \"\\\"\", \" \\\"\", \"Yeah\", \".\\\"\", \" \\\"\", \"Sh\", \"it\", \".\\\"\", \" \\\"\", \"Where\", \" is\", \" he\", \"?\\\"\", \" \\\"\", \"G\", \"otta\", \" go\", \".\\\"\", \" \\\"\", \"What\", \"'s\", \" the\", \" latest\", \"?\\\"\", \" \\\"\", \" Nothing\", \".\\\"\", \" \\\"\", \"They\", \" say\", \" the\", \"\\n\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Yeah\", \".\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Hey\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Come\", \" here\", \".\\\"\", \" \\\"\", \"What\", \"'s\", \" up\", \"?\\\"\", \" \\\"\", \"Hey\", \"\\n\", \"So\", \" you\", \" got\", \" everything\", \"?\\\"\", \" \\\"\", \"You\", \" gonna\", \" play\", \" video\", \" games\", \" the\", \" whole\", \" flight\", \" or\", \" do\", \" you\", \" think\", \" you\", \" might\", \" actually\", \" crack\", \" a\", \" book\", \"?\\\"\", \" \\\"\", \"Probably\", \" read\", \" some\", \".\\\"\", \" \\\"\", \"Well\", \",\", \" if\", \" I\", \" write\", \" you\", \" an\", \" email\", \"\\n\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Yeah\", \".\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Hey\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Come\", \" here\", \".\\\"\", \" \\\"\", \"What\", \"'s\", \" up\", \"?\\\"\", \" \\\"\", \"Hey\", \"\\n\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Yeah\", \".\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Hey\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Come\", \" here\", \".\\\"\", \" \\\"\", \"What\", \"'s\", \" up\", \"?\\\"\", \" \\\"\", \"Hey\", \"\\n\", \"Previously\", \" on\", \" \\\"\", \"The\", \" L\", \" Word\", \"\\\"\\\"\", \" \\\"\", \"I\", \" don\", \"'t\", \" wanna\", \" break\", \" up\", \" with\", \" you\", \".\\\"\", \" \\\"\", \"You\", \" think\", \" we\", \" should\", \" go\", \" to\", \" therapy\", \"?\\\"\", \" \\\"\", \"Ther\", \"apy\", \"'s\", \" for\", \" people\", \" with\", \" problems\", \".\\\"\", \" \\\"\", \"Tell\", \" me\", \" you\", \"\\n\", \"Val\", \"encia\", \",\", \" CA\", \" 2\", \":\", \"43\", \" am\", \"\\\"\", \" \\\"\", \"Yeah\", \".\\\"\", \" \\\"\", \"Sh\", \"it\", \".\\\"\", \" \\\"\", \"Where\", \" is\", \" he\", \"?\\\"\", \" \\\"\", \"G\", \"otta\", \" go\", \".\\\"\", \" \\\"\", \"What\", \"'s\", \" the\", \" latest\", \"?\\\"\", \" \\\"\", \" Nothing\", \".\\\"\", \" \\\"\", \"They\", \" say\", \" the\", \"\\n\", \"Val\", \"encia\", \",\", \" CA\", \" 2\", \":\", \"43\", \" am\", \"\\\"\", \" \\\"\", \"Yeah\", \".\\\"\", \" \\\"\", \"Sh\", \"it\", \".\\\"\", \" \\\"\", \"Where\", \" is\", \" he\", \"?\\\"\", \" \\\"\", \"G\", \"otta\", \" go\", \".\\\"\", \" \\\"\", \"What\", \"'s\", \" the\", \" latest\", \"?\\\"\", \" \\\"\", \" Nothing\", \".\\\"\", \" \\\"\", \"They\", \" say\", \" the\", \"\\n\", \"Red\", \" Rover\", \",\", \" Red\", \" Rover\", \" Send\", \" to\", \" Emily\", \" now\", \"!\\\"\", \" \\\"\", \"Emily\", \" Come\", \" on\", \"!\\\"\", \" \\\"\", \"Who\", \" will\", \" be\", \" next\", \"?\\\"\", \" \\\"\", \"Well\", \" Bobby\", \" Tr\", \"icker\", \"\\\"\", \" \\\"\", \"As\", \"co\", \"!\\\"\", \" \\\"\", \"He\", \" scratches\", \" his\", \" nose\", \",\", \" and\", \" eats\", \"\\n\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Yeah\", \".\\\"\", \" \\\"\", \"Ros\", \"ie\", \".\\\"\", \" \\\"\", \"Hey\", \".\\\"\", \" \\\"\", \"Are\", \" you\", \" okay\", \"?\\\"\", \" \\\"\", \"Come\", \" here\", \".\\\"\", \" \\\"\", \"What\", \"'s\", \" up\", \"?\\\"\", \" \\\"\", \"Hey\", \"\\n\"], \"activations\": [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-2.0503997802734375e-05]], [[-1.33514404296875e-05]], [[-0.3803873062133789]], [[-0.10036206245422363]], [[-0.00850069522857666]], [[-0.006082057952880859]], [[-0.0004507824778556824]], [[-0.018917977809906006]], [[0.0021149367094039917]], [[-0.004905521869659424]], [[-0.054018497467041016]], [[-0.00914907455444336]], [[-0.012520372867584229]], [[0.009621858596801758]], [[-0.0015999067109078169]], [[-0.008449077606201172]], [[-0.0026821941137313843]], [[0.019440650939941406]], [[-0.023143649101257324]], [[-0.0011413395404815674]], [[-0.041852712631225586]], [[-0.00021304236724972725]], [[-0.0054017603397369385]], [[-0.00024075806140899658]], [[0.00023066997528076172]], [[-0.06888389587402344]], [[-0.002605915069580078]], [[0.0016136765480041504]], [[-0.00121307373046875]], [[-0.009222269058227539]], [[0.0013314485549926758]], [[-0.004117488861083984]], [[0.014838457107543945]], [[0.0005209743976593018]], [[0.015053272247314453]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-2.0503997802734375e-05]], [[-1.33514404296875e-05]], [[-0.3803873062133789]], [[-0.10036206245422363]], [[-0.00850069522857666]], [[-0.006082057952880859]], [[-0.0004507824778556824]], [[-0.018917977809906006]], [[0.0021149367094039917]], [[-0.004905521869659424]], [[-0.054018497467041016]], [[-0.00914907455444336]], [[-0.012520372867584229]], [[0.009621858596801758]], [[-0.0015999067109078169]], [[-0.008449077606201172]], [[-0.0026821941137313843]], [[0.019440650939941406]], [[-0.023143649101257324]], [[-0.0011413395404815674]], [[-0.041852712631225586]], [[-0.00021304236724972725]], [[-0.0054017603397369385]], [[-0.00024075806140899658]], [[0.00023066997528076172]], [[-0.06888389587402344]], [[-0.002605915069580078]], [[0.0016136765480041504]], [[-0.00121307373046875]], [[-0.009222269058227539]], [[0.0013314485549926758]], [[-0.004117488861083984]], [[0.014838457107543945]], [[0.0005209743976593018]], [[0.015053272247314453]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-2.0503997802734375e-05]], [[-1.33514404296875e-05]], [[-0.3803873062133789]], [[-0.10036206245422363]], [[-0.00850069522857666]], [[-0.006082057952880859]], [[-0.0004507824778556824]], [[-0.018917977809906006]], [[0.0021149367094039917]], [[-0.004905521869659424]], [[-0.054018497467041016]], [[-0.00914907455444336]], [[-0.012520372867584229]], [[0.009621858596801758]], [[-0.0015999067109078169]], [[-0.008449077606201172]], [[-0.0026821941137313843]], [[0.019440650939941406]], [[-0.023143649101257324]], [[-0.0011413395404815674]], [[-0.041852712631225586]], [[-0.00021304236724972725]], [[-0.0054017603397369385]], [[-0.00024075806140899658]], [[0.00023066997528076172]], [[-0.06888389587402344]], [[-0.002605915069580078]], [[0.0016136765480041504]], [[-0.00121307373046875]], [[-0.009222269058227539]], [[0.0013314485549926758]], [[-0.004117488861083984]], [[0.014838457107543945]], [[0.0005209743976593018]], [[0.015053272247314453]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.0011682510375976562]], [[0.002749919891357422]], [[-0.018245458602905273]], [[-0.20589494705200195]], [[0.1837749481201172]], [[0.03972339630126953]], [[0.03421974182128906]], [[-0.029599249362945557]], [[-0.03502511978149414]], [[0.017911434173583984]], [[-0.006805300712585449]], [[-0.016474246978759766]], [[0.00748780369758606]], [[-0.009021490812301636]], [[-0.07474374771118164]], [[0.15714073181152344]], [[-0.02212238311767578]], [[0.008006095886230469]], [[0.013143062591552734]], [[0.0008051693439483643]], [[0.01562786102294922]], [[0.059238433837890625]], [[-0.015196800231933594]], [[0.0017902553081512451]], [[0.16194915771484375]], [[0.014051437377929688]], [[0.043902695178985596]], [[0.028180360794067383]], [[-0.00012421607971191406]], [[0.0027229785919189453]], [[0.06579971313476562]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-2.0503997802734375e-05]], [[-1.33514404296875e-05]], [[-0.3803873062133789]], [[-0.10036206245422363]], [[-0.00850069522857666]], [[-0.006082057952880859]], [[-0.0004507824778556824]], [[-0.018917977809906006]], [[0.0021149367094039917]], [[-0.004905521869659424]], [[-0.054018497467041016]], [[-0.00914907455444336]], [[-0.012520372867584229]], [[0.009621858596801758]], [[-0.0015999067109078169]], [[-0.008449077606201172]], [[-0.0026821941137313843]], [[0.019440650939941406]], [[-0.023143649101257324]], [[-0.0011413395404815674]], [[-0.041852712631225586]], [[-0.00021304236724972725]], [[-0.0054017603397369385]], [[-0.00024075806140899658]], [[0.00023066997528076172]], [[-0.06888389587402344]], [[-0.002605915069580078]], [[0.0016136765480041504]], [[-0.00121307373046875]], [[-0.009222269058227539]], [[0.0013314485549926758]], [[-0.004117488861083984]], [[0.014838457107543945]], [[0.0005209743976593018]], [[0.015053272247314453]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fc7b55e7490>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_feature_direction_display(full_text, best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_feature = torch.tensor([ 2.4080e-02, 2.4359e-02, 2.5915e-03, 4.9120e-02, 1.2658e-01,\n",
    "         3.2408e-02, -2.5182e-02, 4.3675e-02, -5.4410e-02, 1.6136e-02,\n",
    "        -2.0048e-02, -2.2420e-02, 3.3210e-02, 3.4793e-02, -2.8834e-02,\n",
    "         7.4147e-02, 3.7202e-02, 5.3582e-02, 1.1046e-03, 1.2104e-02,\n",
    "         5.3141e-03, 1.5514e-02, -3.4517e-02, -1.2846e-02, -1.4674e-02,\n",
    "         8.6960e-03, -1.5789e-02, 9.3915e-04, 5.9387e-04, -6.1752e-02,\n",
    "         4.1706e-02, -6.9348e-02, 6.0245e-02, -1.5278e-02, 4.6114e-03,\n",
    "        -6.0599e-02, 4.6384e-02, 8.7855e-03, 9.8222e-02, -1.4912e-02,\n",
    "        -2.0680e-02, 8.0620e-04, 2.1009e-02, -1.8937e-02, 1.9966e-02,\n",
    "         1.8603e-02, 9.0589e-02, -5.7756e-03, -4.1959e-02, 5.0267e-03,\n",
    "         2.3697e-02, -5.8151e-02, -7.7805e-02, -4.9728e-02, -4.8614e-03,\n",
    "        -3.9631e-02, -4.0052e-02, 3.9487e-02, 6.3542e-03, 2.7683e-02,\n",
    "        -3.4077e-02, -2.9967e-02, 3.2453e-03, -8.4002e-02, -3.5077e-02,\n",
    "        -9.1061e-03, -8.3716e-04, 7.6448e-03, -7.9082e-03, 3.9118e-02,\n",
    "        -3.9306e-02, -2.0184e-02, -1.7360e-02, -9.5160e-03, 1.3632e-02,\n",
    "        -1.1137e-01, -3.2181e-02, -5.6427e-02, -2.3615e-02, 9.5962e-03,\n",
    "         5.5335e-02, -1.8662e-02, 3.4204e-02, -5.0086e-02, -7.4954e-02,\n",
    "         8.4810e-03, 5.8262e-02, 1.7019e-02, 3.1432e-03, 1.1476e-02,\n",
    "         6.3471e-03, -4.1524e-02, 1.8465e-02, 7.5723e-02, 1.5079e-02,\n",
    "         1.9857e-02, 1.1886e-02, 9.8358e-03, -5.3220e-02, 5.9651e-02,\n",
    "         2.2428e-02, 3.4533e-02, -1.7907e-02, 1.0397e-02, 4.1672e-02,\n",
    "        -1.8936e-02, 2.1871e-02, 2.5337e-03, 2.3077e-03, 3.9737e-02,\n",
    "        -3.9214e-02, 9.2625e-03, -3.8041e-02, -1.2577e-02, -3.1696e-03,\n",
    "        -2.7372e-02, -5.1618e-02, 4.4042e-02, 2.4820e-02, 2.7953e-02,\n",
    "         1.5850e-02, -1.6006e-03, 5.3238e-02, 9.8043e-03, 3.8326e-02,\n",
    "        -4.1484e-02, 3.6432e-02, 2.2653e-02, 1.8522e-02, -3.7113e-02,\n",
    "         1.7174e-02, -8.3303e-03, 2.8099e-03, 1.0931e-01, -4.4335e-02,\n",
    "         1.1882e-02, -6.4499e-03, 3.7061e-02, -9.4151e-02, -5.1065e-02,\n",
    "         2.7060e-02, -6.5621e-02, -3.0455e-02, -1.6427e-02, 3.9223e-02,\n",
    "        -3.9643e-02, 6.4269e-04, -1.2907e-03, -5.0777e-03, -5.1587e-02,\n",
    "        -3.4985e-02, 3.7856e-02, -9.9967e-02, -6.5395e-03, -4.6955e-02,\n",
    "         2.4562e-02, 1.5419e-02, -2.1492e-02, -8.9394e-03, 4.2825e-02,\n",
    "        -4.5467e-02, -1.2693e-02, -4.9931e-02, 1.9798e-03, -3.1977e-02,\n",
    "         6.7696e-03, -3.7578e-02, -3.1094e-02, -3.4964e-02, 3.0003e-02,\n",
    "         3.0392e-02, 2.8398e-02, 7.5477e-04, 2.7859e-02, 8.7245e-03,\n",
    "         1.9231e-02, -3.1447e-02, -3.8160e-02, 3.6587e-02, -1.2608e-02,\n",
    "         6.7020e-02, 9.5656e-02, 2.0806e-02, -1.0801e-02, -1.6442e-02,\n",
    "         2.9674e-02, -4.6152e-02, -6.7173e-02, 5.4613e-02, -7.5615e-03,\n",
    "        -1.2474e-05, -9.5788e-03, 6.4168e-03, 1.7756e-02, -1.0295e-02,\n",
    "        -2.1090e-02, -3.4596e-02, -1.4731e-02, 1.0119e-02, 5.8010e-03,\n",
    "        -5.4254e-03, -4.6099e-02, 6.3387e-02, -1.7798e-02, -3.1989e-02,\n",
    "        -2.7206e-02, -7.4612e-02, 3.3296e-02, 9.3995e-03, 3.7320e-02,\n",
    "        -8.7339e-02, 2.0072e-02, -3.8689e-02, -9.5642e-03, -2.8851e-03,\n",
    "         3.4954e-03, -3.7127e-03, -3.8476e-03, 1.9904e-02, -4.4326e-03,\n",
    "         2.4047e-02, 2.1409e-02, -5.3637e-04, -1.3460e-02, -2.5007e-02,\n",
    "        -3.6522e-02, -6.4226e-02, 6.0937e-03, -4.9409e-03, -5.5151e-02,\n",
    "         1.1245e-02, -5.9511e-02, 4.5356e-02, 2.3629e-02, -3.4198e-03,\n",
    "         2.6451e-02, 5.8297e-02, -1.5115e-02, 3.8943e-02, -1.3371e-02,\n",
    "        -2.6044e-02, -5.6735e-02, 6.8021e-02, -3.7823e-02, 7.3421e-02,\n",
    "        -2.4523e-02, -6.3215e-03, -8.1932e-03, 5.6012e-02, 4.7597e-04,\n",
    "        -4.0288e-02, -1.3732e-03, -3.2098e-02, -9.2334e-03, 5.5161e-03,\n",
    "         2.5030e-02, 1.5095e-02, -2.9644e-02, 5.2908e-02, -2.3363e-02,\n",
    "         5.3523e-03, 3.9384e-03, 2.1839e-02, 1.2031e-02, 2.4092e-02,\n",
    "         2.3921e-02, -7.7738e-02, -1.1835e-01, -5.1954e-02, -2.1009e-02,\n",
    "         2.5704e-02, -2.4611e-02, 3.3695e-02, 2.6925e-02, 2.6932e-02,\n",
    "         1.2319e-02, -8.9244e-02, -8.6162e-03, 3.5292e-02, -3.8614e-02,\n",
    "        -3.9250e-02, 1.6301e-02, -3.1443e-02, 1.9028e-03, 5.7968e-02,\n",
    "         3.9234e-03, -2.0115e-02, -7.6918e-03, 4.2788e-02, 3.0034e-02,\n",
    "         9.1978e-02, -5.9110e-02, 2.3647e-02, 2.0807e-02, -1.2634e-02,\n",
    "        -7.6869e-03, 4.4716e-02, -1.8892e-02, 2.7425e-02, -9.9979e-03,\n",
    "         1.9796e-02, 1.0973e-02, -1.6451e-03, -4.3213e-02, -3.5061e-03,\n",
    "         2.9969e-03, -7.1300e-02, 6.3207e-03, 8.0630e-03, -3.5077e-02,\n",
    "        -9.7324e-03, -5.2640e-02, -5.5317e-02, -2.2824e-02, 2.7998e-02,\n",
    "        -7.8537e-02, 4.3458e-02, -1.4984e-02, -7.7363e-02, 3.7290e-02,\n",
    "         7.7163e-02, -3.3954e-03, 1.3120e-02, 5.7814e-02, -1.7183e-02,\n",
    "         2.4303e-03, 3.1352e-02, 7.0760e-02, -5.9879e-03, 6.1438e-02,\n",
    "        -9.8398e-03, 1.6338e-02, 2.8400e-02, 5.7705e-02, -2.2048e-03,\n",
    "        -4.5825e-03, -1.2012e-02, -1.3619e-03, 3.8692e-02, -1.8441e-02,\n",
    "        -1.1080e-02, 3.3503e-03, 1.1516e-02, 5.0336e-02, 2.0678e-03,\n",
    "        -2.6509e-02, 4.7976e-03, -4.7704e-03, -3.4007e-02, -5.1153e-02,\n",
    "        -1.9541e-02, -1.5282e-02, -3.3280e-02, 2.1600e-02, -6.8638e-02,\n",
    "         7.2270e-03, -4.8205e-02, 6.4255e-02, -3.0913e-02, 3.3795e-02,\n",
    "         3.1021e-02, 1.7689e-02, 7.8526e-03, 4.4164e-02, -2.6782e-03,\n",
    "         2.9056e-02, 3.4432e-02, 3.8272e-02, 7.4780e-03, 5.0119e-02,\n",
    "        -1.8974e-02, -2.9729e-02, 4.4389e-02, -2.5922e-02, -6.9515e-02,\n",
    "        -6.1480e-02, -1.2153e-02, -5.7087e-02, 8.2086e-02, 3.9201e-02,\n",
    "         2.0275e-02, 8.8203e-03, -4.9722e-02, 6.9982e-02, -7.2797e-03,\n",
    "         4.0989e-02, 4.1517e-03, 8.9593e-03, 2.5157e-02, -4.8101e-03,\n",
    "        -9.6375e-03, -2.2509e-02, 5.1393e-02, 7.2553e-03, 1.3507e-02,\n",
    "         4.3849e-02, 6.2116e-02, 3.8052e-02, 1.5074e-02, 1.4775e-02,\n",
    "         2.6600e-02, 2.7580e-02, -6.2622e-03, -2.5771e-02, 1.7867e-02,\n",
    "        -1.4621e-02, 1.3103e-02, 1.5070e-02, -4.5592e-02, 6.9849e-06,\n",
    "         5.1731e-03, -2.9146e-02, -1.2707e-02, 2.8848e-02, 8.5701e-02,\n",
    "        -1.1278e-02, 2.7468e-02, -4.3419e-03, -2.8725e-02, -3.2829e-02,\n",
    "        -1.2745e-02, 3.3975e-02, -1.1140e-02, -3.2737e-02, -3.7541e-02,\n",
    "        -1.2454e-02, -1.5200e-02, -2.8173e-02, -1.0102e-01, -1.6749e-02,\n",
    "         2.8634e-02, -1.3546e-02, -1.8982e-02, 9.3449e-02, 4.1330e-02,\n",
    "        -1.3391e-02, -2.9870e-02, -1.0827e-02, -4.5005e-02, 1.5958e-02,\n",
    "        -2.7183e-03, -3.2368e-02, 5.6117e-02, -4.7420e-02, -2.1395e-02,\n",
    "        -4.4957e-02, -5.9798e-03, 2.2991e-02, 7.0553e-02, -9.5782e-03,\n",
    "         9.5198e-03, 5.8040e-03, -3.0258e-02, -5.3331e-02, 8.5738e-03,\n",
    "         5.9829e-02, 4.9407e-02, -3.9949e-02, -1.5012e-02, -5.7299e-02,\n",
    "         3.3791e-02, 2.6755e-02, 1.6138e-02, 1.5216e-02, -1.4221e-02,\n",
    "        -5.5148e-02, -6.4813e-03, -4.5133e-02, 2.5805e-02, 1.9024e-02,\n",
    "         2.3914e-03, 5.3716e-03, -5.0496e-02, -3.6670e-04, -2.6395e-02,\n",
    "         5.3805e-02, -1.9281e-02, 2.9166e-02, 1.8902e-02, 6.9283e-03,\n",
    "        -8.6916e-03, 1.3865e-01, 4.3540e-02, 7.9599e-03, -1.1489e-02,\n",
    "        -1.9561e-02, -3.3223e-02, 4.2447e-02, 2.4892e-02, 7.6215e-03,\n",
    "        -5.5037e-02, -4.0666e-03, -4.7167e-03, 3.1368e-02, 2.2559e-02,\n",
    "        -9.4491e-03, -3.7170e-02, -4.0265e-02, -2.2772e-04, -6.9743e-03,\n",
    "        -7.5886e-03, 3.6595e-02, -1.0402e-02, -3.0940e-02, -1.4825e-02,\n",
    "         1.4237e-02, 4.5008e-02, 2.5084e-02, 1.0162e-02, 2.5703e-02,\n",
    "        -1.3544e-02, -1.1389e-01, -4.0357e-02, -4.7644e-02, -3.7380e-02,\n",
    "        -1.4030e-02, 5.7597e-02, 1.7919e-04, 1.8142e-02, -1.6253e-02,\n",
    "        -7.6142e-02, 3.8851e-02, -2.1893e-02, -1.5224e-02, 2.1425e-02,\n",
    "         1.6085e-02, -2.6741e-02, -2.4140e-02, -1.4206e-02, 4.1798e-02,\n",
    "        -3.2894e-02, 4.9439e-02, -9.9219e-03, -7.2214e-02, -4.4329e-03,\n",
    "         2.9387e-02, -3.9025e-02, 1.9442e-02, 3.4890e-02, 1.3546e-02,\n",
    "         6.8964e-04, -2.7797e-02, -6.8082e-02, 9.9170e-03, 2.3642e-02,\n",
    "        -6.8385e-02, 1.0770e-02, -5.6083e-03, 1.7623e-02, -3.4506e-02,\n",
    "        -4.2243e-02, 7.4690e-02, -2.4971e-02, -5.2503e-02, -1.4595e-02,\n",
    "         5.1033e-02, 6.1160e-02, 3.7497e-03, -3.8879e-02, -4.1647e-03,\n",
    "         2.6918e-02, -1.4865e-02, 9.0000e-03, -1.4608e-02, -2.1336e-02,\n",
    "        -5.9530e-03, -1.6575e-03, -4.7094e-02, 2.3869e-02, 1.4982e-02,\n",
    "         4.9038e-02, -4.5014e-02, 4.8011e-02, -1.5510e-02, -1.6457e-02,\n",
    "         1.2145e-02, 4.9655e-03, -4.4219e-02, 2.6135e-02, 1.6504e-02,\n",
    "         3.7103e-03, 3.4081e-02, -8.6893e-03, -9.9807e-03, 1.2927e-02,\n",
    "         3.5594e-02, 2.4592e-02, 3.7850e-02, -1.1348e-02, -1.1096e-03,\n",
    "        -4.4439e-02, 2.7691e-02, -6.9026e-02, 5.7734e-02, 2.9289e-02,\n",
    "         3.4821e-02, -5.2970e-03, 3.7610e-02, -1.7178e-02, -5.0140e-02,\n",
    "        -8.3218e-02, 4.2783e-02, -1.2670e-02, 1.1850e-02, 3.1992e-02,\n",
    "        -4.4622e-04, 3.7421e-02, -2.3873e-02, -1.9229e-02, 1.4420e-02,\n",
    "         1.5459e-02, 2.4360e-02, -1.4355e-03, 3.8322e-02, -4.1234e-02,\n",
    "        -4.1331e-02, -2.9026e-02, -1.7661e-02, 5.0412e-02, -5.7450e-02,\n",
    "        -2.2180e-02, 1.4419e-02, -1.6419e-02, -2.6536e-02, -6.5096e-02,\n",
    "        -8.5083e-03, -5.8017e-03, 4.6651e-02, 3.4101e-02, -1.8907e-02,\n",
    "         2.7087e-02, 2.5500e-02, 1.1684e-03, 6.8219e-02, -3.2993e-02,\n",
    "        -2.3292e-02, 1.5120e-03, -2.1995e-02, 6.2556e-02, 4.9651e-02,\n",
    "         1.6080e-02, -1.3513e-02, 3.5774e-02, -4.4417e-02, 4.9697e-03,\n",
    "         4.9093e-02, 1.3976e-02, 2.6455e-02, 3.7071e-02, -4.3469e-02,\n",
    "         1.3540e-02, 5.2918e-02, 3.4559e-02, -3.1488e-02, -1.9801e-02,\n",
    "        -3.4259e-02, -1.0953e-02, -3.2256e-02, -3.9682e-02, 9.6360e-03,\n",
    "        -9.6176e-03, 1.2003e-03, 4.2134e-02, -5.7197e-02, -4.2081e-02,\n",
    "        -4.6472e-03, 2.6133e-02, 3.7587e-02, 9.8670e-03, -3.4046e-02,\n",
    "        -3.2811e-03, -1.5316e-02, -4.8647e-03, 1.9632e-02, 1.1838e-02,\n",
    "         1.5452e-02, -6.3881e-02, 1.2259e-02, 1.2232e-03, -4.3000e-02,\n",
    "        -6.8827e-02, 4.1810e-02, 7.1543e-03, -5.1488e-02, 2.4518e-02,\n",
    "        -1.0627e-03, 1.4221e-02, -5.3517e-02, -4.3952e-02, -3.0068e-02,\n",
    "        -1.9294e-03, -1.0837e-02, -1.0782e-02, 1.1658e-02, -7.7354e-03,\n",
    "        -9.4467e-03, 5.8047e-02, 6.2752e-03, 1.7554e-02, 5.2714e-04,\n",
    "         1.2364e-02, 4.7268e-02, -3.3143e-02, -2.9131e-02, -7.5221e-03,\n",
    "        -1.3250e-02, -1.0116e-02, 1.5731e-02, 1.2194e-03, 5.5533e-02,\n",
    "        -2.4715e-02, 3.5104e-04, 7.7462e-02, -4.2483e-02, 9.3196e-03,\n",
    "         3.5436e-04, 3.0903e-02, -6.8819e-02, 1.9523e-02, 2.2681e-04,\n",
    "        -2.1906e-02, -3.0358e-03, 1.9632e-02, 1.0104e-02, -4.5632e-03,\n",
    "         2.3078e-02, -2.9149e-02, -4.9732e-02, 1.2652e-05, 4.3399e-03,\n",
    "         3.1472e-02, 1.0199e-02, -3.4592e-04, -3.0710e-02, 8.5242e-03,\n",
    "        -6.5155e-03, -3.7067e-02, -6.3603e-03, -1.0648e-02, 4.0477e-02,\n",
    "        -1.5365e-02, 2.0180e-02, 8.3195e-03, 1.8911e-02, -3.3727e-02,\n",
    "        -3.8646e-02, -3.2142e-02, -1.6740e-02, 2.0304e-02, 3.7467e-02,\n",
    "         2.5757e-02, -9.1715e-02, 6.6637e-02, -2.6891e-02, 3.7948e-02,\n",
    "        -2.8087e-02, -1.2200e-02, 2.7008e-02, -6.5081e-03, 7.5711e-02,\n",
    "         1.4658e-02, -1.6642e-02, 4.5490e-02, 1.1131e-02, 4.4595e-02,\n",
    "        -5.6698e-02, 1.6837e-02, -7.4032e-03])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ournals', 'upiter', 'igsaw', 'unction', 'itsu', 'ealous', 'acket', 'ansen', 'ordan', 'avascript', 'ungle', 'oint', 'umper', 'okers', 'umbo', 'azeera', 'ansson', 'utsu', 'ihad', 'ensen']\n",
      "tensor([1.3623, 1.2798, 1.2214, 1.1859, 1.1594, 1.1505, 1.1266, 1.1224, 1.0344,\n",
      "        1.0249, 1.0240, 1.0180, 1.0163, 1.0099, 1.0037, 0.9904, 0.9864, 0.9702,\n",
      "        0.9624, 0.9618])\n"
     ]
    }
   ],
   "source": [
    "logit_lens(model,best_feature, smaller_dict, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-1ac8e7b3-9504\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-1ac8e7b3-9504\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"e\", \"-\", \"t\", \"ika\", \"\\u306e\", \"\\u30b5\", \"\\u30f3\", \"\\u30d7\", \"\\u30eb\", \"\\n\", \"\\ufffd\", \"\\ufffd\", \"\\u4e2a\", \"\\u4eba\", \"\\u90fd\", \"\\u6709\", \"\\u4ed6\", \"\\u7684\", \"\\u4f5c\", \"\\ufffd\", \"\\ufffd\", \"\\ufffd\", \"\\ufffd\", \"\\ufffd\", \"\\ufffd\", \"\\uff0c\", \"\\u76f4\", \"\\u5230\", \"\\ufffd\", \"\\ufffd\", \"\\u4e0a\", \"\\u4e2d\", \"\\u4e86\", \"\\u4e00\", \"\\ufffd\", \"\\ufffd\", \"\\u3002\", \"\\n\", \"\\u8fd9\", \"\\u662f\", \"\\u6211\", \"\\u5e74\", \"\\ufffd\", \"\\ufffd\", \"\\u65f6\", \"\\ufffd\", \"\\ufffd\", \"\\ufffd\", \"\\ufffd\", \"\\u7684\", \"\\ufffd\", \"\\ufffd\", \"\\u5b50\", \"\\n\"], \"activations\": [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.8140134811401367]], [[0.5921033620834351]], [[0.31352877616882324]], [[0.019249677658081055]], [[0.2526233196258545]], [[0.0]], [[0.0]], [[0.0]], [[0.3025623559951782]], [[0.0]], [[0.40284645557403564]], [[0.46507275104522705]], [[0.0]], [[0.2929190397262573]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.10586249828338623]], [[0.13855719566345215]], [[0.4243839979171753]], [[0.0]], [[0.0]], [[0.0]], [[0.29841840267181396]], [[0.0]], [[0.0]], [[0.014042854309082031]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.3846317529678345]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.3778529167175293]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.5222042798995972]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f1adc0614b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_text = [\n",
    "    \"e-tikaのサンプル\",\n",
    "    \n",
    "    \"每个人都有他的作战策略，直到脸上中了一拳。\",\n",
    "    \"这是我年轻时候住的房子\",\n",
    "]\n",
    "visualize_text(custom_text, best_feature, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Centric Viewpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-b3f2704e-8a27\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-b3f2704e-8a27\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\", \"It\", \" is\", \" done\", \",\", \" and\", \" submitted\", \".\", \" You\", \" can\", \" play\", \" \\u201c\", \"Sur\", \"vival\", \" of\", \" the\", \" T\", \"ast\", \"iest\", \"\\u201d\", \" on\", \" Android\", \",\", \" and\", \" on\", \" the\", \"\\n\"], \"activations\": [[[82.7564926147461]], [[0.41646838188171387]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[149.81748962402344]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[62.884986877441406]], [[0.0]], [[0.4040207862854004]], [[0.0]], [[0.0]], [[0.0]], [[99.5608139038086]], [[0.5513043403625488]], [[0.0]], [[1.0399408340454102]], [[1.425760269165039]], [[4.947237968444824]], [[1.7392220497131348]], [[0.0]], [[0.0]], [[4.0198774337768555]], [[0.17562437057495117]], [[0.0]], [[0.0]], [[0.0]], [[3.941493034362793]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[17.318439483642578]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.9275326728820801]], [[0.6468110084533691]], [[0.10458612442016602]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.11562681198120117]], [[1.100588321685791]], [[1.7711853981018066]], [[1.5439908504486084]], [[0.3038226366043091]], [[0.3253086805343628]], [[0.6628274917602539]], [[0.5560286045074463]], [[0.3502471446990967]], [[0.4706670045852661]], [[0.0]], [[0.8721731901168823]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.8246186971664429]], [[0.4927572011947632]], [[0.3002433776855469]], [[0.4912317991256714]], [[0.18886053562164307]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.7436568737030029]], [[1.5422230958938599]], [[1.4640122652053833]], [[1.782070279121399]], [[0.8627933263778687]], [[0.32637345790863037]], [[0.0]], [[0.30792057514190674]], [[0.15409982204437256]], [[0.10886752605438232]], [[0.06799399852752686]], [[0.40450000762939453]], [[0.0]], [[0.37047338485717773]], [[0.009954333305358887]], [[0.0]], [[0.0619814395904541]], [[0.20380747318267822]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.4360116720199585]], [[0.0]], [[0.557902455329895]], [[1.4583653211593628]], [[0.36010468006134033]], [[0.2150031328201294]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.47024083137512207]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.3076235055923462]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.3168461322784424]], [[0.1124265193939209]], [[3.23787784576416]], [[1.5314109325408936]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fb6601fad10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through datapoints & see if the features that activate on them make sense.\n",
    "d_point = 0\n",
    "# text = tokens_dataset[d_point]\n",
    "data_ind, sequence_pos = np.unravel_index(d_point, (datapoints, token_amount))\n",
    "feature_val, feature_ind = dictionary_activations[d_point].topk(10)\n",
    "data_ind = int(data_ind)\n",
    "sequence_pos = int(sequence_pos)\n",
    "full_tok = torch.tensor(dataset[data_ind][\"input_ids\"])\n",
    "full_text = []\n",
    "full_text.append(model.tokenizer.decode(full_tok))\n",
    "visualize_text(full_text, feature_ind, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the neuron/residual basis\n",
    "When we look at the weights of a feature, we are seeing the literal dimensions from the residual stream/neurons being read from the feature. \n",
    "\n",
    "Here I'm visualizing the weight values for the residual stream. If there are outliers, then it's mainly reading from that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check features non-zero weights in decoder\n",
    "# Plot a histogram of the weights\n",
    "max_activation = dictionary_activations[:, best_feature].max()\n",
    "weights = smaller_dict[best_feature]\n",
    "plt.hist(weights, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.topk(\n",
       " values=tensor([0.4587, 0.4407, 0.4183, 0.4015, 0.3814, 0.3496, 0.3330, 0.3156, 0.2968,\n",
       "         0.2948, 0.2846, 0.2781, 0.2736, 0.2714, 0.2680, 0.2593, 0.2587, 0.2563,\n",
       "         0.2554, 0.2505]),\n",
       " indices=tensor([478, 436,  98, 321,  87, 458, 230, 464, 129,  31, 137, 377, 263, 401,\n",
       "         291,  92, 132,  56, 109, 246])),\n",
       " tensor([-0.3796, -0.3700, -0.3456, -0.3286, -0.3197, -0.3164, -0.3107, -0.3015,\n",
       "         -0.3011, -0.3000, -0.2976, -0.2964, -0.2894, -0.2886, -0.2828, -0.2822,\n",
       "         -0.2763, -0.2675, -0.2606, -0.2588]),\n",
       " tensor(39))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weights*max_activation).topk(20), (weights*max_activation).topk(20, largest=False).values, (weights*max_activation > 0.2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepend/Append tokens\n",
    "We can iterate over all tokens to check which ones activate a feature a lot to more rigorously test a hypothesis on what a feature means.\n",
    "\n",
    "Note: I'm literately running the model through all 50k tokens prepended to the text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[token]\n",
      "Top-20 increasing: ['に', 'を', 'でも', 'が', 'には', 'も', 'ことが', 'は', 'で', 'の', 'では', 'って', 'して', 'から', 'と', 'ると', 'て', 'という', 'によ', 'ی']\n",
      "Top-20 increasing: ['3.60', '3.33', '3.11', '3.08', '3.07', '3.00', '2.96', '2.85', '2.72', '2.69', '2.54', '2.43', '2.40', '2.33', '2.32', '2.32', '2.18', '2.14', '2.00', '1.97']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 49992\n",
      "に[token]\n",
      "Top-20 increasing: ['には', 'を', 'に', 'でも', 'ことが', 'が', 'という', 'も', 'は', 'では', 'で', 'って', 'の', 'ると', 'から', 'と', 'にな', 'して', 'その', 'として']\n",
      "Top-20 increasing: ['3.71', '3.67', '3.60', '3.30', '3.30', '3.24', '3.23', '3.22', '3.11', '3.04', '3.03', '2.99', '2.90', '2.83', '2.78', '2.70', '2.65', '2.61', '2.48', '2.44']\n",
      "Top-20 decreasing: ['1', ')', '#', '\"', '+', \"'\", '2', '3', '*', '$', '.', ',', '<|padding|>', '0', '<|endoftext|>', '(', '4', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 47200\n",
      "にには[token]\n",
      "Top-20 increasing: ['に', 'を', 'でも', 'ことが', 'には', 'が', 'で', 'も', 'って', 'の', 'は', 'では', 'から', 'して', 'と', 'ると', 'という', 'にな', 'て', 'として']\n",
      "Top-20 increasing: ['4.04', '3.93', '3.64', '3.55', '3.49', '3.48', '3.42', '3.37', '3.30', '3.24', '3.21', '3.17', '3.13', '3.10', '2.97', '2.94', '2.89', '2.73', '2.72', '2.54']\n",
      "Top-20 decreasing: ['1', ')', '#', '\"', '+', \"'\", '2', '6', '*', '5', '.', '4', '<|padding|>', '0', '3', '(', '<', '9', '8', '7']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 44239\n"
     ]
    }
   ],
   "source": [
    "def prepend_all_tokens_and_get_feature_activation(model, minimal_activating_example, feature, setting=\"prepend\"):\n",
    "    tokens = model.to_tokens(minimal_activating_example, prepend_bos=False)\n",
    "\n",
    "    # Run through every number up to vocab size\n",
    "    vocab_size = model.cfg.d_vocab\n",
    "    batch_size = 256*2 # Define your desired batch size\n",
    "\n",
    "    dollar_feature_activations = torch.zeros(vocab_size)\n",
    "    for start in range(0, vocab_size, batch_size):\n",
    "        end = min(start + batch_size, vocab_size)\n",
    "\n",
    "        token_prep = torch.arange(start, end).to(device)\n",
    "        token_prep = token_prep.unsqueeze(1)  # Add a dimension for concatenation\n",
    "\n",
    "        # 1. Prepend to the tokens\n",
    "        if setting == \"prepend\":\n",
    "            tokens_catted = torch.cat((token_prep, tokens.repeat(end - start, 1)), dim=1).long()\n",
    "        elif setting == \"append\":\n",
    "            tokens_catted = torch.cat((tokens.repeat(end - start, 1), token_prep), dim=1).long()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown setting: {setting}\")\n",
    "\n",
    "        # 2. Run through the model\n",
    "        with torch.no_grad():\n",
    "            _, cache = model.run_with_cache(tokens_catted.to(device))\n",
    "            neuron_act_batch = cache[cache_name]\n",
    "            _, act = smaller_auto_encoder(neuron_act_batch)\n",
    "\n",
    "        # 3. Get the feature\n",
    "        dollar_feature_activations[start:end] = act[:, -1, feature].cpu().squeeze()\n",
    "\n",
    "    k = 20\n",
    "    k_increasing_val, k_increasing_ind = dollar_feature_activations.topk(k)\n",
    "    k_decreasing_val, k_decreasing_ind = dollar_feature_activations.topk(k, largest=False)\n",
    "    if(setting == \"prepend\"):\n",
    "        print(f\"[token]{minimal_activating_example}\")\n",
    "    elif(setting == \"append\"):\n",
    "        print(f\"{minimal_activating_example}[token]\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown setting: {setting}\")\n",
    "    # Print indices converted to tokens\n",
    "    print(f\"Top-{k} increasing: {model.to_str_tokens(k_increasing_ind)}\")\n",
    "    # Print values\n",
    "    print(f\"Top-{k} increasing: {[f'{val:.2f}' for val in k_increasing_val]}\")\n",
    "    print(f\"Top-{k} decreasing: {model.to_str_tokens(k_decreasing_ind)}\")\n",
    "    print(f\"Top-{k} decreasing: {[f'{val:.2f}' for val in k_decreasing_val]}\")\n",
    "    print(f\"Number of 0 activations: {torch.sum(dollar_feature_activations == 0)}\")\n",
    "    if(setting == \"prepend\"):\n",
    "        best_text = \"\".join(model.to_str_tokens(dollar_feature_activations.argmax()) + [minimal_activating_example])\n",
    "    else:\n",
    "        best_text = \"\".join([minimal_activating_example] + model.to_str_tokens(dollar_feature_activations.argmax()))\n",
    "    return best_text\n",
    "\n",
    "best_text = \"\"\n",
    "for x in range(3):\n",
    "    # best_text = prepend_all_tokens_and_get_feature_activation(model, best_text, best_feature, setting=\"prepend\")\n",
    "    best_text = prepend_all_tokens_and_get_feature_activation(model, best_text, best_feature, setting=\"append\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" for all $\", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" tree\", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" tree\", best_feature, setting=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[token]\n",
      "Top-20 increasing: ['に', 'を', 'でも', 'が', 'には', 'も', 'ことが', 'は', 'で', 'の', 'では', 'って', 'して', 'から', 'と', 'ると', 'て', 'という', 'によ', 'ی']\n",
      "Top-20 increasing: ['3.60', '3.33', '3.11', '3.08', '3.07', '3.00', '2.96', '2.85', '2.72', '2.69', '2.54', '2.43', '2.40', '2.33', '2.32', '2.32', '2.18', '2.14', '2.00', '1.97']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 49992\n",
      "[token]に\n",
      "Top-20 increasing: ['Chief', '\\\\!\\\\!\\\\!\\\\!', 'DLT', ' 1866', '0101', '1101', 'ht', 'DT', 'FIX', 'varn', 'AGT', ' 1945', 'ähler', 'GTT', ' 1865', 'DH', 'ITC', 'ogon', 'andem', ' Hodge']\n",
      "Top-20 increasing: ['4.61', '4.51', '4.51', '4.51', '4.50', '4.50', '4.50', '4.49', '4.47', '4.47', '4.46', '4.46', '4.46', '4.45', '4.45', '4.45', '4.44', '4.44', '4.44', '4.43']\n",
      "Top-20 decreasing: [' trier', ' Pref', ' abbrev', ' [(\\\\[', 'amsbsy', ' Prov', 'Determine', 'Choose', '[]{', 'Use', ' <!--', ' �', '_{{\\\\', '_{{{\\\\', ' (\\\\[', ' acqu', ' $({\\\\', '$.[]{', '(#', '({{\\\\']\n",
      "Top-20 decreasing: ['1.38', '1.47', '1.48', '1.66', '1.67', '1.70', '1.75', '1.78', '1.83', '1.84', '1.84', '1.85', '1.85', '1.86', '1.86', '1.86', '1.87', '1.87', '1.88', '1.89']\n",
      "Number of 0 activations: 0\n",
      "[token]Chiefに\n",
      "Top-20 increasing: ['�', 'HN', 'HD', 'en', 'chle', '4', 'QT', 'hä', 'ą', 'emi', ' Arctic', 'GTT', 'hei', ' GT', 'iatric', ' Oak', 'LET', ' CU', ' EIGEN', 'UH']\n",
      "Top-20 increasing: ['4.76', '4.72', '4.72', '4.72', '4.69', '4.69', '4.68', '4.68', '4.67', '4.67', '4.67', '4.66', '4.66', '4.65', '4.65', '4.65', '4.64', '4.64', '4.64', '4.63']\n",
      "Top-20 decreasing: [' trier', '$.[]{', ' [(\\\\[', ' abbrev', ' <!--', '{(\\\\', '[]{', ' Redistributions', '_{{{\\\\', 'amsbsy', ' \"@', ' $({\\\\', ' �', ' Copyright', '{%', ':{\\\\', ' Prov', '({{\\\\', ' []{', 'Leg']\n",
      "Top-20 decreasing: ['1.56', '2.01', '2.01', '2.04', '2.12', '2.12', '2.14', '2.18', '2.19', '2.20', '2.21', '2.21', '2.25', '2.25', '2.26', '2.27', '2.27', '2.29', '2.30', '2.31']\n",
      "Number of 0 activations: 0\n"
     ]
    }
   ],
   "source": [
    "best_text = \"\"\n",
    "for x in range(3):\n",
    "    best_text = prepend_all_tokens_and_get_feature_activation(model, best_text, best_feature, setting=\"prepend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[token] for all $\n",
      "Top-20 increasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 increasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Top-20 decreasing: ['1', ')', '#', '/', '+', \"'\", '2', '<|padding|>', '*', '$', '.', ',', '&', '0', '\"', '(', '<|endoftext|>', '!', '%', '-']\n",
      "Top-20 decreasing: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Number of 0 activations: 50304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|endoftext|> for all $'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepend_all_tokens_and_get_feature_activation(model, \" \", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \"The\", best_feature, setting=\"append\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" tree\", best_feature, setting=\"append\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
