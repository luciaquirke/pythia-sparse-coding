{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mchorse/miniconda3/envs/logan/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 9.999999747378752e-05, 0.00019306977628730237, 0.000372759357560426, 0.0007196856895461679, 0.0013894954463467002, 0.0026826958637684584, 0.005179474595934153, 0.009999999776482582]\n",
      "{'dict_size': 3072, 'l1_alpha': 0.0013894954463467002}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_id = \"Elriggs/pythia-70m-deduped-layer-2\"\n",
    "ae_download_location = hf_hub_download(repo_id=model_id, filename=\"learned_dicts.pt\")\n",
    "all_autoencoders = torch.load(ae_download_location)\n",
    "num_l1s = len(all_autoencoders)\n",
    "all_l1s = [hyperparams[\"l1_alpha\"] for autoencoder, hyperparams in all_autoencoders]\n",
    "print(all_l1s)\n",
    "autoencoder, hyperparams = all_autoencoders[5]\n",
    "print(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "layer = 2\n",
    "setting = \"residual\"\n",
    "model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HookedTransformer.from_pretrained(model_name, device=device)\n",
    "\n",
    "if setting == \"residual\":\n",
    "    cache_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "    neurons = model.cfg.d_model\n",
    "elif setting == \"mlp\":\n",
    "    cache_name = f\"blocks.{layer}.mlp.hook_post\"\n",
    "    neurons = model.cfg.d_mlp\n",
    "elif setting == \"attention\":\n",
    "    cache_name = f\"blocks.{layer}.hook_attn_out\"\n",
    "    neurons = model.cfg.d_model\n",
    "elif setting == \"mlp_out\":\n",
    "    cache_name = f\"blocks.{layer}.hook_mlp_out\"\n",
    "    neurons = model.cfg.d_model\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downnload dataset\n",
    "from datasets import Dataset, load_dataset\n",
    "dataset_name = \"NeelNanda/pile-10k\"\n",
    "token_amount= 40\n",
    "#TODO: change train[:1000] to train if you want whole dataset\n",
    "dataset = load_dataset(dataset_name, split=\"train[:1000]\").map(\n",
    "    lambda x: model.tokenizer(x['text']),\n",
    "    batched=True,\n",
    ").filter(\n",
    "    lambda x: len(x['input_ids']) > token_amount\n",
    ").map(\n",
    "    lambda x: {'input_ids': x['input_ids'][:token_amount]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Dictionary Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 42.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the model to get the activations\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange\n",
    "num_features, d_model = autoencoder.encoder.shape\n",
    "datapoints = dataset.num_rows\n",
    "batch_size = 32\n",
    "neuron_activations = torch.zeros((datapoints*token_amount, d_model))\n",
    "dictionary_activations = torch.zeros((datapoints*token_amount, num_features))\n",
    "smaller_auto_encoder = autoencoder\n",
    "smaller_auto_encoder.to_device(device)\n",
    "\n",
    "with torch.no_grad(), dataset.formatted_as(\"pt\"):\n",
    "    dl = DataLoader(dataset[\"input_ids\"], batch_size=batch_size)\n",
    "    for i, batch in enumerate(tqdm(dl)):\n",
    "        _, cache = model.run_with_cache(batch.to(device))\n",
    "        batched_neuron_activations = rearrange(cache[cache_name], \"b s n -> (b s) n\" )\n",
    "        neuron_activations[i*batch_size*token_amount:(i+1)*batch_size*token_amount,:] = batched_neuron_activations.cpu()\n",
    "        batched_dictionary_activations = smaller_auto_encoder.encode(batched_neuron_activations)\n",
    "        dictionary_activations[i*batch_size*token_amount:(i+1)*batch_size*token_amount,:] = batched_dictionary_activations.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Interp\n",
    "Investigate the example sentences the activate this feature.\n",
    "\n",
    "Max: show max activating (tokens,contexts)\n",
    "\n",
    "Uniform: Show range of activations from each bin (e.g. sample an example from 1-2, 2-3, etc). \n",
    "[Note: if a feature is monosemantic, then the full range of activations should be that feature, not just max-activating ones]\n",
    "\n",
    "Full_text: shows the full text example\n",
    "\n",
    "Text_list: shows up to the most activating example (try w/ max activating on a couple of examples to see)\n",
    "\n",
    "ablate_text: remove the context one token at a time, and show the decrease/increase in activation of that feature\n",
    "\n",
    "ablate_feature_direction: removes feature direction from model's activation mid-inference, showing the logit diff in the output for every token.\n",
    "\n",
    "logit_lens: show the logit lens for that feature. If matches ablate_feature_direction, then the computation path is through the residual stream, else, it's through future layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interp_utils import *\n",
    "best_feature = 1\n",
    "text_list, full_text, token_list, full_token_list = get_feature_datapoints(best_feature, dictionary_activations, model.tokenizer, token_amount, dataset, setting=\"uniform\")\n",
    "# text_list, full_text, token_list, full_token_list = get_feature_datapoints(best_feature, dictionary_activations, dataset, setting=\"max\")\n",
    "# visualize_text(full_text, best_feature, model, autoencoder, layer)\n",
    "visualize_text(text_list, best_feature, model, autoencoder, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-fe79afdd-fbab\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-fe79afdd-fbab\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"At\", \" our\", \" best\", \",\", \" we\", \" motivate\", \" ourselves\", \" every\", \" day\", \" to\", \" get\", \" dressed\", \" and\", \" go\", \" to\", \" work\", \" or\", \"\\n\", \"Save\", \" on\", \"\\\\newline\", \"\\\\newline\", \"the\", \" full\", \" suite\", \"\\\\newline\", \"\\\\newline\", \"65\", \"%\", \" discount\", \" 10\", \" engines\", \" 22\", \" expansions\", \"\\\\newline\", \"\\\\newline\", \"Arm\", \" yourself\", \" with\", \" the\", \" full\", \" arsenal\", \".\", \" Buy\", \" or\", \"\\n\", \"---\", \"\\\\newline\", \"abstract\", \":\", \" '\", \"The\", \" aim\", \" of\", \" this\", \" paper\", \" is\", \" to\", \" establish\", \" a\", \" global\", \" asymptotic\", \" equivalence\", \" between\", \" the\", \" experiments\", \" generated\", \" by\", \" the\", \" discrete\", \" (\", \"high\", \" frequency\", \")\", \" or\", \"\\n\", \"H\", \"ab\", \"erk\", \"ip\", \"College\", \" or\", \" work\", \"?\", \" Gap\", \" year\", \" or\", \"\\n\", \"Most\", \" normal\", \" human\", \" cells\", \" undergo\", \" a\", \" limited\", \" number\", \" of\", \" cell\", \" divisions\", \",\", \" eventually\", \" entering\", \" an\", \" irre\", \"vers\", \"ibly\", \" arrested\", \" state\", \",\", \" through\", \" either\", \" senescence\", \" or\", \"\\n\", \"4\", \"?\", \"\\\\newline\", \"False\", \"\\\\newline\", \"Is\", \" -\", \"0\", \".\", \"1\", \" equal\", \" to\", \" 0\", \".\", \"234\", \"?\", \"\\\\newline\", \"False\", \"\\\\newline\", \"Is\", \" -\", \"1\", \"/\", \"155\", \"!=\", \" 14\", \"?\", \"\\\\newline\", \"True\", \"\\\\newline\", \"Which\", \" is\", \" smaller\", \":\", \" 0\", \".\", \"8\", \" or\", \"\\n\", \"<?\", \"php\", \"\\\\newline\", \"/*\", \"\\\\newline\", \" *\", \" THIS\", \" SOFTWARE\", \" IS\", \" PROVIDED\", \" BY\", \" THE\", \" COPYRIGHT\", \" HOLDERS\", \" AND\", \" CONTRIBUTORS\", \"\\\\newline\", \" *\", \" \\\"\", \"AS\", \" IS\", \"\\\"\", \" AND\", \" ANY\", \" EXPRESS\", \" OR\", \"\\n\", \"/*\", \"\\\\newline\", \" *\", \" Copyright\", \" (\", \"c\", \")\", \" 2017\", \",\", \" 2019\", \",\", \" Oracle\", \" and\", \"/\", \"or\", \" its\", \" affiliates\", \".\", \" All\", \" rights\", \" reserved\", \".\", \"\\\\newline\", \" *\", \" DO\", \" NOT\", \" AL\", \"TER\", \" OR\", \" REM\", \"OVE\", \" COPYRIGHT\", \" NOT\", \"ICES\", \" OR\", \"\\n\", \"j\", \"OO\", \"Q\", \" on\", \" The\", \" OR\", \"\\n\", \"Your\", \" inner\", \" Ch\", \"imp\", \" can\", \" be\", \" your\", \" best\", \" friend\", \" or\", \" your\", \"\\n\"], \"activations\": [[[0.01796245574951172]], [[-0.08954048156738281]], [[0.014575004577636719]], [[-0.29509568214416504]], [[-0.006485939025878906]], [[0.019212722778320312]], [[-0.032660484313964844]], [[0.01992034912109375]], [[-0.007334709167480469]], [[-0.054566383361816406]], [[0.18168354034423828]], [[-0.033148765563964844]], [[-0.14638519287109375]], [[0.006815910339355469]], [[0.03503131866455078]], [[-0.2736532688140869]], [[-4.194690704345703]], [[0.0]], [[-0.022955894470214844]], [[-0.04245185852050781]], [[0.007706642150878906]], [[0.007706642150878906]], [[0.01971912384033203]], [[0.010410308837890625]], [[-0.030108928680419922]], [[0.01600027084350586]], [[0.01600027084350586]], [[0.022186756134033203]], [[0.048064231872558594]], [[0.09827232360839844]], [[0.036787986755371094]], [[-0.05732440948486328]], [[0.02037811279296875]], [[0.0040416717529296875]], [[-0.03944206237792969]], [[-0.03944206237792969]], [[-0.035490989685058594]], [[-0.03985881805419922]], [[-0.0018477439880371094]], [[-0.038002967834472656]], [[-0.02214956283569336]], [[-0.022386550903320312]], [[-0.14581871032714844]], [[0.26636481285095215]], [[-3.7856523990631104]], [[0.0]], [[0.01587200164794922]], [[-0.014319419860839844]], [[0.047832489013671875]], [[-0.008662223815917969]], [[-0.028048038482666016]], [[-0.050537109375]], [[-0.0029969215393066406]], [[-0.04166603088378906]], [[-0.007050514221191406]], [[-0.00240325927734375]], [[-0.024997234344482422]], [[0.010929584503173828]], [[0.007901191711425781]], [[0.017522335052490234]], [[0.005176544189453125]], [[-0.01255035400390625]], [[-0.0324549674987793]], [[0.01602315902709961]], [[0.01647472381591797]], [[-0.02615833282470703]], [[0.1035470962524414]], [[-0.037906646728515625]], [[0.005385398864746094]], [[0.03368568420410156]], [[-0.304872989654541]], [[0.07572317123413086]], [[0.04692983627319336]], [[0.6763706207275391]], [[-3.2404987812042236]], [[0.0]], [[-0.06571722030639648]], [[0.0029611587524414062]], [[0.008912086486816406]], [[0.009551048278808594]], [[0.09498023986816406]], [[0.04731178283691406]], [[-0.046942710876464844]], [[0.049367427825927734]], [[-0.035134315490722656]], [[0.16265010833740234]], [[-2.8385164737701416]], [[0.0]], [[-0.0063190460205078125]], [[0.011750221252441406]], [[-0.006142616271972656]], [[0.04236125946044922]], [[0.03235626220703125]], [[-0.00696563720703125]], [[0.011274337768554688]], [[0.023319244384765625]], [[0.017524242401123047]], [[0.040740966796875]], [[-0.04268932342529297]], [[-0.009152412414550781]], [[0.0074481964111328125]], [[-0.01256561279296875]], [[-0.02376079559326172]], [[-0.06952476501464844]], [[-0.0026197433471679688]], [[-0.027163028717041016]], [[-0.02590465545654297]], [[0.03430032730102539]], [[-0.08219575881958008]], [[-0.1506485939025879]], [[1.0315895080566406]], [[0.48508644104003906]], [[-2.5944130420684814]], [[0.0]], [[0.013019084930419922]], [[-0.006476402282714844]], [[-0.0017499923706054688]], [[-0.0103912353515625]], [[-0.00015544891357421875]], [[0.002861499786376953]], [[0.03156423568725586]], [[-0.0009069442749023438]], [[-0.016133785247802734]], [[-0.0008378028869628906]], [[0.005062103271484375]], [[-0.0028095245361328125]], [[0.010191917419433594]], [[-0.007841110229492188]], [[0.0054264068603515625]], [[-0.0022873878479003906]], [[0.022497177124023438]], [[0.030743122100830078]], [[-0.013543128967285156]], [[0.016539573669433594]], [[0.02010345458984375]], [[0.013504505157470703]], [[0.0028471946716308594]], [[0.0204925537109375]], [[-0.013979434967041016]], [[0.014101982116699219]], [[0.008884429931640625]], [[0.023831844329833984]], [[0.08341789245605469]], [[-0.05674433708190918]], [[0.13748979568481445]], [[-0.0859212875366211]], [[-0.05055427551269531]], [[-0.0412137508392334]], [[0.12281608581542969]], [[-0.1250619888305664]], [[0.13166236877441406]], [[-2.2238943576812744]], [[0.0]], [[-0.02829456329345703]], [[-0.041074514389038086]], [[-0.024047374725341797]], [[0.08501815795898438]], [[-0.023417949676513672]], [[0.02949976921081543]], [[-0.0024323463439941406]], [[0.29454946517944336]], [[0.0013031959533691406]], [[0.13499832153320312]], [[-0.002749204635620117]], [[-0.16657781600952148]], [[0.050084590911865234]], [[-0.1678485870361328]], [[0.015045166015625]], [[0.12009429931640625]], [[0.03323554992675781]], [[-0.0019922256469726562]], [[-0.05301475524902344]], [[0.005378246307373047]], [[-0.04471397399902344]], [[-0.027913331985473633]], [[0.03596353530883789]], [[0.029612302780151367]], [[-0.19498062133789062]], [[-1.5436885356903076]], [[0.0]], [[0.017325878143310547]], [[0.019719600677490234]], [[-0.0012950897216796875]], [[0.045290470123291016]], [[0.0004215240478515625]], [[0.0008113384246826172]], [[0.025447845458984375]], [[0.009523391723632812]], [[-0.0009765625]], [[0.010780811309814453]], [[-0.00033283233642578125]], [[0.022932052612304688]], [[-0.0015888214111328125]], [[0.01304483413696289]], [[0.011806011199951172]], [[0.014468193054199219]], [[0.0686807632446289]], [[0.01610422134399414]], [[0.006665229797363281]], [[0.01738262176513672]], [[-0.0321507453918457]], [[0.027101993560791016]], [[0.04529595375061035]], [[-0.003922939300537109]], [[-0.019436120986938477]], [[-0.045365333557128906]], [[0.017723798751831055]], [[-0.012696504592895508]], [[-0.05872702598571777]], [[0.024997234344482422]], [[0.08264017105102539]], [[0.6850371360778809]], [[-0.015893936157226562]], [[0.15342998504638672]], [[-1.1339337825775146]], [[0.0]], [[-0.028086185455322266]], [[-0.08502840995788574]], [[0.3004469871520996]], [[-0.16100072860717773]], [[0.25238609313964844]], [[-0.8589999675750732]], [[0.0]], [[-0.05675244331359863]], [[0.059316158294677734]], [[-0.035475850105285645]], [[0.027377724647521973]], [[0.13530170917510986]], [[-0.05675244331359863]], [[-0.05675244331359863]], [[0.12169623374938965]], [[0.05689370632171631]], [[-0.05675244331359863]], [[3.8346729278564453]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fdcb2141720>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_text(text_list, best_feature, model, autoencoder, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-58a2063a-fad3\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-58a2063a-fad3\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\" our\", \" best\", \",\", \" we\", \" motivate\", \" ourselves\", \" every\", \" day\", \" to\", \" get\", \" dressed\", \" and\", \" go\", \" to\", \" work\", \" or\", \" school\", \".\", \" Although\", \" there\", \" are\", \" larger\", \" incentives\", \" at\", \" work\", \",\", \" it\", \"'s\", \" our\", \" own\", \" vol\", \"ition\", \" that\", \" powers\", \" us\", \" through\", \" our\", \" inn\", \"umerable\", \"\\n\", \" on\", \"\\\\newline\", \"\\\\newline\", \"the\", \" full\", \" suite\", \"\\\\newline\", \"\\\\newline\", \"65\", \"%\", \" discount\", \" 10\", \" engines\", \" 22\", \" expansions\", \"\\\\newline\", \"\\\\newline\", \"Arm\", \" yourself\", \" with\", \" the\", \" full\", \" arsenal\", \".\", \" Buy\", \" or\", \" upgrade\", \" to\", \" all\", \" of\", \" our\", \" non\", \"-\", \"sub\", \"scription\", \" engines\", \",\", \" effects\", \",\", \"\\n\", \"\\\\newline\", \"abstract\", \":\", \" '\", \"The\", \" aim\", \" of\", \" this\", \" paper\", \" is\", \" to\", \" establish\", \" a\", \" global\", \" asymptotic\", \" equivalence\", \" between\", \" the\", \" experiments\", \" generated\", \" by\", \" the\", \" discrete\", \" (\", \"high\", \" frequency\", \")\", \" or\", \" continuous\", \" observation\", \" of\", \" a\", \" path\", \" of\", \" a\", \" L\\u00e9\", \"vy\", \" process\", \" and\", \"\\n\", \"ab\", \"erk\", \"ip\", \"College\", \" or\", \" work\", \"?\", \" Gap\", \" year\", \" or\", \" victory\", \" lap\", \"?\", \" And\", \" how\", \" should\", \" a\", \" young\", \" person\", \" choose\", \" among\", \" the\", \" multitude\", \" of\", \" programs\", \" offered\", \" through\", \" universities\", \",\", \" colleges\", \" or\", \" a\", \" combination\", \" of\", \" both\", \"?\", \"Those\", \" are\", \" just\", \"\\n\", \" normal\", \" human\", \" cells\", \" undergo\", \" a\", \" limited\", \" number\", \" of\", \" cell\", \" divisions\", \",\", \" eventually\", \" entering\", \" an\", \" irre\", \"vers\", \"ibly\", \" arrested\", \" state\", \",\", \" through\", \" either\", \" senescence\", \" or\", \" differentiation\", \".\", \" Both\", \" processes\", \" have\", \" major\", \" implications\", \" for\", \" human\", \" health\", \";\", \" between\", \" them\", \" impacting\", \" birth\", \"\\n\", \"?\", \"\\\\newline\", \"False\", \"\\\\newline\", \"Is\", \" -\", \"0\", \".\", \"1\", \" equal\", \" to\", \" 0\", \".\", \"234\", \"?\", \"\\\\newline\", \"False\", \"\\\\newline\", \"Is\", \" -\", \"1\", \"/\", \"155\", \"!=\", \" 14\", \"?\", \"\\\\newline\", \"True\", \"\\\\newline\", \"Which\", \" is\", \" smaller\", \":\", \" 0\", \".\", \"8\", \" or\", \" -\", \"0\", \"\\n\", \"php\", \"\\\\newline\", \"/*\", \"\\\\newline\", \" *\", \" THIS\", \" SOFTWARE\", \" IS\", \" PROVIDED\", \" BY\", \" THE\", \" COPYRIGHT\", \" HOLDERS\", \" AND\", \" CONTRIBUTORS\", \"\\\\newline\", \" *\", \" \\\"\", \"AS\", \" IS\", \"\\\"\", \" AND\", \" ANY\", \" EXPRESS\", \" OR\", \" IMPLIED\", \" WARRANTIES\", \",\", \" INCLUDING\", \",\", \" BUT\", \" NOT\", \"\\\\newline\", \" *\", \" LIMITED\", \" TO\", \",\", \" THE\", \" IMPLIED\", \"\\n\", \"\\\\newline\", \" *\", \" Copyright\", \" (\", \"c\", \")\", \" 2017\", \",\", \" 2019\", \",\", \" Oracle\", \" and\", \"/\", \"or\", \" its\", \" affiliates\", \".\", \" All\", \" rights\", \" reserved\", \".\", \"\\\\newline\", \" *\", \" DO\", \" NOT\", \" AL\", \"TER\", \" OR\", \" REM\", \"OVE\", \" COPYRIGHT\", \" NOT\", \"ICES\", \" OR\", \" THIS\", \" FILE\", \" HEAD\", \"ER\", \".\", \"\\n\", \"OO\", \"Q\", \" on\", \" The\", \" OR\", \"M\", \" Foundation\", \"?\", \"\\\\newline\", \"\\\\newline\", \"I\", \" am\", \" the\", \" developer\", \" of\", \" j\", \"OO\", \"Q\", \",\", \" a\", \" Java\", \" database\", \" abstraction\", \" framework\", \".\", \" I\", \" was\", \" wondering\", \" whether\", \" j\", \"OO\", \"Q\", \" might\", \" be\", \" an\", \" interesting\", \" tool\", \" for\", \" discussion\", \"\\n\", \" inner\", \" Ch\", \"imp\", \" can\", \" be\", \" your\", \" best\", \" friend\", \" or\", \" your\", \" worst\", \" enemy\", \"...\", \"this\", \" is\", \" the\", \" Ch\", \"imp\", \" Parad\", \"ox\", \"\\\\newline\", \"\\\\newline\", \"Do\", \" you\", \" sabot\", \"age\", \" your\", \" own\", \" happiness\", \" and\", \" success\", \"?\", \" Are\", \" you\", \" struggling\", \" to\", \" make\", \" sense\", \" of\", \"\\n\"], \"activations\": [[[0.0]], [[0.0]], [[-0.0015864372253417969]], [[0.0006734132766723633]], [[-0.00019168853759765625]], [[-0.0002576112747192383]], [[-0.0002040863037109375]], [[0.00015491247177124023]], [[0.0001925826072692871]], [[-0.0014166831970214844]], [[-0.00283050537109375]], [[6.127357482910156e-05]], [[0.0009267330169677734]], [[8.71419906616211e-05]], [[0.01726377010345459]], [[-0.00019931793212890625]], [[-0.5752291679382324]], [[0.008181631565093994]], [[-0.015760421752929688]], [[0.029036998748779297]], [[0.001488327980041504]], [[-0.012989997863769531]], [[0.012876510620117188]], [[-0.011909008026123047]], [[-0.0705229640007019]], [[-0.010540366172790527]], [[0.0004858970642089844]], [[0.003174304962158203]], [[-0.0010466575622558594]], [[-0.004266262054443359]], [[0.0020198822021484375]], [[9.47713851928711e-06]], [[0.00176239013671875]], [[-0.014432907104492188]], [[-0.02241694927215576]], [[0.0066547393798828125]], [[-0.009240388870239258]], [[-0.04122781753540039]], [[0.016965508460998535]], [[0.0]], [[0.0]], [[-0.00018548965454101562]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.00022649765014648438]], [[4.591047763824463e-05]], [[0.0039119720458984375]], [[0.0]], [[0.0]], [[0.003032684326171875]], [[0.0020914077758789062]], [[0.000644683837890625]], [[-0.003928184509277344]], [[0.00528264045715332]], [[-4.149973392486572e-05]], [[-0.0008697509765625]], [[0.0]], [[0.0]], [[-0.00034248828887939453]], [[-0.0031785964965820312]], [[-2.765655517578125e-05]], [[-0.0010752677917480469]], [[-0.00014448165893554688]], [[0.0005407333374023438]], [[-0.09730982780456543]], [[-0.19505846500396729]], [[0.2790818214416504]], [[0.05826401710510254]], [[0.034921884536743164]], [[-0.010519027709960938]], [[0.000517919659614563]], [[-0.03711843490600586]], [[0.005410909652709961]], [[0.02293682098388672]], [[0.025864601135253906]], [[0.01820659637451172]], [[0.0022902488708496094]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.00026535987854003906]], [[0.0002951622009277344]], [[0.0]], [[-0.0001709461212158203]], [[-0.0010886192321777344]], [[-2.078711986541748e-06]], [[4.721805453300476e-07]], [[1.9073486328125e-06]], [[-8.940696716308594e-06]], [[0.0]], [[-7.152557373046875e-06]], [[4.76837158203125e-07]], [[1.7881393432617188e-07]], [[0.0002988576889038086]], [[0.0021543502807617188]], [[-0.0041103363037109375]], [[0.0]], [[3.921985626220703e-05]], [[0.004824161529541016]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.6154906749725342]], [[0.07853269577026367]], [[-0.06367027759552002]], [[-0.13707256317138672]], [[-0.0451664924621582]], [[0.007264852523803711]], [[-0.03282809257507324]], [[0.034759521484375]], [[5.188537761569023e-05]], [[0.0033652782440185547]], [[0.034293174743652344]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0005817413330078125]], [[-0.06926822662353516]], [[-0.747687816619873]], [[-0.0059604644775390625]], [[0.00020313262939453125]], [[-0.03158855438232422]], [[-1.0336275100708008]], [[0.8465738296508789]], [[-0.6184279918670654]], [[0.0014238357543945312]], [[0.016539573669433594]], [[-0.010132789611816406]], [[0.0015845298767089844]], [[0.010855674743652344]], [[-0.015867948532104492]], [[0.12619686126708984]], [[-0.004091739654541016]], [[0.0031806230545043945]], [[-0.014995574951171875]], [[0.00013392791152000427]], [[-0.00774383544921875]], [[-0.0018677711486816406]], [[0.0016598701477050781]], [[0.1592550277709961]], [[-0.002218484878540039]], [[-0.023323774337768555]], [[-0.10982871055603027]], [[-0.9735817909240723]], [[-0.16839361190795898]], [[0.002513669431209564]], [[0.0194854736328125]], [[0.0003781616687774658]], [[3.910064697265625e-05]], [[0.003818988800048828]], [[-0.003960132598876953]], [[0.0]], [[0.0]], [[0.0007143020629882812]], [[0.0]], [[0.000614166259765625]], [[-0.00018715858459472656]], [[-0.0007839202880859375]], [[0.0]], [[2.4334527552127838e-05]], [[-1.9073486328125e-06]], [[-2.7418136596679688e-05]], [[6.985664367675781e-05]], [[0.0023641586303710938]], [[-0.0017728805541992188]], [[-0.0004611015319824219]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.00018453598022460938]], [[-0.0006046295166015625]], [[-0.007970333099365234]], [[0.03035259246826172]], [[-0.0022960901260375977]], [[0.4574146270751953]], [[0.13190054893493652]], [[0.0025415420532226562]], [[0.0026350021362304688]], [[0.010767459869384766]], [[0.002391338348388672]], [[0.010141134262084961]], [[0.00437164306640625]], [[0.0011014938354492188]], [[-0.008319377899169922]], [[-0.013020038604736328]], [[-0.003516674041748047]], [[-0.003928184509277344]], [[-0.0037508010864257812]], [[0.04439735412597656]], [[0.0]], [[0.0]], [[4.029273986816406e-05]], [[-0.0006957054138183594]], [[4.762550815939903e-07]], [[-3.5762786865234375e-06]], [[0.0]], [[0.0]], [[0.0]], [[0.00016987323760986328]], [[0.000362396240234375]], [[7.286667823791504e-06]], [[-2.384185791015625e-07]], [[2.1457672119140625e-06]], [[0.0]], [[-2.384185791015625e-07]], [[-1.1918164091184735e-06]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-1.7879283404909074e-06]], [[0.0]], [[7.863622158765793e-06]], [[0.0]], [[-0.0016843900084495544]], [[-0.0049915313720703125]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.00160139799118042]], [[-0.04594063758850098]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0023475289344787598]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[3.5762673178396653e-07]], [[-2.2289197659119964e-05]], [[7.316443952731788e-05]], [[-0.0003423194866627455]], [[-3.7370715290308e-05]], [[3.2183233997784555e-06]], [[-8.699425961822271e-06]], [[6.375135853886604e-05]], [[-1.1920838005607948e-07]], [[1.4304496289696544e-06]], [[4.767425707541406e-06]], [[2.3841721485950984e-07]], [[1.1920274118892848e-06]], [[3.576169547159225e-07]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-3.6946628824807703e-05]], [[-0.02452864870429039]], [[0.0003697737120091915]], [[-0.00023651123046875]], [[-0.0014699101448059082]], [[0.0005973055958747864]], [[6.519374437630177e-05]], [[1.082767266780138e-05]], [[0.0005153864622116089]], [[3.6209821701049805e-05]], [[0.0038073062896728516]], [[0.0]], [[-4.7254376113414764e-05]], [[1.1920838005607948e-07]], [[-1.1915108188986778e-07]], [[-0.012223978526890278]], [[-0.003207053290680051]], [[3.5762673178396653e-07]], [[2.7652131393551826e-05]], [[6.80088996887207e-05]], [[-0.00020369142293930054]], [[0.0007958437781780958]], [[-0.008479486219584942]], [[-0.001294427551329136]], [[-1.1920883480343036e-07]], [[-5.959009286016226e-07]], [[0.0]], [[0.0]], [[0.0]], [[0.00012254714965820312]], [[-1.9073486328125e-05]], [[0.0046329498291015625]], [[0.03153872489929199]], [[0.008284568786621094]], [[-0.027204036712646484]], [[0.00122755765914917]], [[0.0007286667823791504]], [[-0.0012631416320800781]], [[-0.0004425048828125]], [[0.0009407997131347656]], [[-0.018383502960205078]], [[2.816319465637207e-05]], [[-0.1627812385559082]], [[0.015760421752929688]], [[-0.0022867023944854736]], [[0.0068988800048828125]], [[0.0033686161041259766]], [[-0.03584575653076172]], [[-0.0029420852661132812]], [[0.007053852081298828]], [[-0.003066539764404297]], [[-0.0008480548858642578]], [[0.0025246143341064453]], [[0.0001366138458251953]], [[-0.0008234977722167969]], [[-0.0003161430358886719]], [[0.0007686614990234375]], [[-1.2460164725780487e-05]], [[-1.696869730949402e-05]], [[0.00013685226440429688]], [[-8.64267349243164e-06]], [[0.0014467239379882812]], [[0.012614965438842773]], [[0.004543781280517578]], [[0.0002963542938232422]], [[0.0006227493286132812]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0006208419799804688]], [[-0.00031435489654541016]], [[0.0005164146423339844]], [[-0.0005624294281005859]], [[0.0]], [[-7.62939453125e-05]], [[-0.10890817642211914]], [[0.07658910751342773]], [[0.15937435626983643]], [[-0.21389532089233398]], [[0.0003056526184082031]], [[-0.002677440643310547]], [[0.004209160804748535]], [[-0.015080451965332031]], [[-0.0043370723724365234]], [[0.005321502685546875]], [[0.006902158260345459]], [[0.010984420776367188]], [[0.0009887218475341797]], [[-0.004189968109130859]], [[9.47117805480957e-05]], [[-0.041510581970214844]], [[-2.7311034500598907e-06]], [[0.030246257781982422]], [[0.020496845245361328]], [[0.02453327178955078]], [[-0.004569292068481445]], [[0.006190299987792969]], [[0.008085250854492188]], [[-0.00611567497253418]], [[-6.856024265289307e-05]], [[0.00324249267578125]], [[0.01908707618713379]], [[-0.007734537124633789]], [[-0.0018258094787597656]], [[0.0007687583565711975]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fdcb2143fa0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_feature_direction_display(full_text, autoencoder, model, layer, features=best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['naments', 'chid', 'ifice', 'bital', ' equivalently', ' otherwise', ' else', 'Else', 'deal', 'iginally', 'leans', ' alternatively', 'anges', 'acles', ' something', 'chard', 'lando', 'phe', 'phan', 'acular']\n",
      "tensor([3.6303, 2.8674, 2.5978, 2.5794, 2.5119, 2.4721, 2.4593, 2.2616, 2.1686,\n",
      "        2.1448, 2.1189, 2.1073, 2.0916, 2.0746, 2.0506, 2.0402, 1.9394, 1.9391,\n",
      "        1.8440, 1.8397])\n"
     ]
    }
   ],
   "source": [
    "logit_lens(model, best_feature, autoencoder.get_learned_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
